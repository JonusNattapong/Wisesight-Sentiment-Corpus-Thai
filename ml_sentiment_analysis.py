#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Advanced Thai Sentiment Analysis with Machine Learning Models
‡∏£‡∏∞‡∏ö‡∏ö sentiment analysis ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏ö‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏î‡πâ‡∏ß‡∏¢ ML models
"""

import os
import re
import json
import pickle
import numpy as np
import warnings
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime

# Fix encoding issues on Windows
if sys.platform.startswith('win'):
    import locale
    try:
        # Set UTF-8 for stdout/stderr
        if hasattr(sys.stdout, 'reconfigure'):
            sys.stdout.reconfigure(encoding='utf-8', errors='replace')
            sys.stderr.reconfigure(encoding='utf-8', errors='replace')
        else:
            # Fallback for older Python versions
            import codecs
            sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, errors='replace')
            sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, errors='replace')
        
        # Set locale to UTF-8 if possible
        try:
            locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
        except:
            try:
                locale.setlocale(locale.LC_ALL, 'C.UTF-8')
            except:
                pass  # Use system default
    except Exception as e:
        print(f"Warning: Could not set UTF-8 encoding: {e}")

# Suppress warnings
warnings.filterwarnings('ignore')

# --- ML Libraries ---
try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.linear_model import LogisticRegression
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.svm import SVC
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import classification_report, accuracy_score
    from sklearn.pipeline import Pipeline
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

# --- Deep Learning Libraries ---
try:
    import torch
    import torch.nn as nn
    from transformers import (
        AutoTokenizer, AutoModelForSequenceClassification,
        pipeline, Trainer, TrainingArguments
    )
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

# --- Thai NLP Libraries ---
try:
    from pythainlp import word_tokenize
    from pythainlp.corpus import thai_stopwords
    PYTHAINLP_AVAILABLE = True
except ImportError:
    PYTHAINLP_AVAILABLE = False

def safe_print(text: str, encoding: str = 'utf-8', errors: str = 'replace'):
    """Safe printing function that handles encoding issues"""
    try:
        if isinstance(text, bytes):
            text = text.decode(encoding, errors=errors)
        elif isinstance(text, str):
            # Clean surrogate characters
            text = text.encode(encoding, errors=errors).decode(encoding, errors=errors)
        print(text)
    except Exception as e:
        # Fallback: print with ASCII only
        try:
            clean_text = text.encode('ascii', errors='ignore').decode('ascii')
            print(f"[ENCODING_ISSUE] {clean_text}")
        except:
            print("[ENCODING_ERROR] Unable to display text")

def clean_unicode_text(text: str) -> str:
    """Clean text from problematic Unicode characters"""
    if not isinstance(text, str):
        return str(text)
    
    try:
        # Remove surrogate characters
        text = text.encode('utf-8', errors='ignore').decode('utf-8', errors='ignore')
        
        # Remove or replace problematic characters
        text = re.sub(r'[\udce6\udce7\udce8\udce9]', '', text)  # Remove common surrogates
        text = re.sub(r'[\u0000-\u001f\u007f-\u009f]', '', text)  # Remove control characters
        
        # Normalize whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    except Exception:
        # Fallback: keep only ASCII
        return re.sub(r'[^\x00-\x7F]+', ' ', text).strip()

class ThaiTextPreprocessor:
    """‡∏ï‡∏±‡∏ß‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤"""
    
    def __init__(self):
        self.stop_words = set()
        if PYTHAINLP_AVAILABLE:
            # Convert frozenset to set to allow updates
            stopwords_from_pythainlp = thai_stopwords()
            if isinstance(stopwords_from_pythainlp, frozenset):
                self.stop_words = set(stopwords_from_pythainlp)
            else:
                self.stop_words = set(stopwords_from_pythainlp) if stopwords_from_pythainlp else set()
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° stopwords ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
        additional_stops = {
            '‡∏Ñ‡∏£‡∏±‡∏ö', '‡∏Ñ‡πà‡∏∞', '‡∏Ñ‡∏∞', '‡∏à‡πâ‡∏≤', '‡πÄ‡∏•‡∏¢', '‡πÅ‡∏•‡πâ‡∏ß', '‡∏ó‡∏µ‡πà', '‡∏ô‡∏∞', '‡∏ô‡∏µ‡πà',
            '‡∏ô‡∏±‡πà‡∏ô', '‡∏ô‡∏±‡πâ‡∏ô', '‡∏≠‡∏∞', '‡πÄ‡∏≠‡πà‡∏≠', '‡∏≠‡∏∑‡∏°', '‡πÄ‡∏≠', '‡πÅ‡∏´‡∏∞', '‡πÇ‡∏≠‡πâ', '‡∏ß‡πâ‡∏≤‡∏ß'
        }
        self.stop_words.update(additional_stops)
    
    def clean_text(self, text: str) -> str:
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        if not text:
            return ""
        
        # Clean unicode first
        text = clean_unicode_text(text)
        
        # ‡∏•‡∏ö URLs
        text = re.sub(r'https?://\S+', '', text)
        text = re.sub(r'www\.\S+', '', text)
        
        # ‡∏•‡∏ö HTML tags
        text = re.sub(r'<.*?>', '', text)
        
        # ‡∏•‡∏ö‡∏≠‡∏µ‡πÇ‡∏°‡∏à‡∏¥‡πÅ‡∏•‡∏∞‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏û‡∏¥‡πÄ‡∏®‡∏© (‡πÄ‡∏Å‡πá‡∏ö‡∏ö‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç)
        text = re.sub(r'[^\u0E00-\u0E7Fa-zA-Z0-9\s\.\!\?\,\:\;\-\(\)]', ' ', text)
        
        # ‡∏•‡∏ö‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£, etc.)
        text = re.sub(r'\d{8,}', '', text)
        
        # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏Å‡∏¥‡∏ô
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def tokenize(self, text: str) -> List[str]:
        """‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"""
        text = self.clean_text(text)
        
        if PYTHAINLP_AVAILABLE:
            tokens = word_tokenize(text, engine='newmm')
        else:
            # Fallback: split by spaces
            tokens = text.split()
        
        # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        filtered_tokens = []
        for token in tokens:
            token = token.strip()
            if (len(token) > 1 and 
                token not in self.stop_words and 
                not token.isdigit() and
                not re.match(r'^[^\u0E00-\u0E7Fa-zA-Z]+$', token)):
                filtered_tokens.append(token)
        
        return filtered_tokens
    
    def preprocess(self, text: str) -> str:
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ML"""
        tokens = self.tokenize(text)
        return ' '.join(tokens)

class ThaiSentimentMLModel:
    """Thai Sentiment Analysis ML Model"""
    
    def __init__(self, model_type: str = "logistic"):
        self.model_type = model_type
        self.preprocessor = ThaiTextPreprocessor()
        self.pipeline = None
        self.model = None
        self.vectorizer = None
        self.label_mapping = {
            'negative': 0,
            'neutral': 1, 
            'positive': 2
        }
        self.reverse_label_mapping = {v: k for k, v in self.label_mapping.items()}
        
    def create_model(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á ML model"""
        if not SKLEARN_AVAILABLE:
            raise ImportError("sklearn is required for ML models")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á vectorizer
        self.vectorizer = TfidfVectorizer(
            max_features=5000,
            ngram_range=(1, 2),
            min_df=2,
            max_df=0.8
        )
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model ‡∏ï‡∏≤‡∏° type
        if self.model_type == "logistic":
            self.model = LogisticRegression(
                random_state=42,
                max_iter=1000,
                class_weight='balanced'
            )
        elif self.model_type == "random_forest":
            self.model = RandomForestClassifier(
                n_estimators=100,
                random_state=42,
                class_weight='balanced'
            )
        elif self.model_type == "svm":
            self.model = SVC(
                kernel='rbf',
                random_state=42,
                class_weight='balanced',
                probability=True
            )
        else:
            raise ValueError(f"Unsupported model type: {self.model_type}")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á pipeline
        self.pipeline = Pipeline([
            ('vectorizer', self.vectorizer),
            ('classifier', self.model)
        ])
    
    def prepare_training_data(self, comments: List[Dict[str, Any]]) -> Tuple[List[str], List[str]]:
        """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô"""
        texts = []
        labels = []
        
        for comment in comments:
            text = comment.get('text', '')
            if not text:
                continue
            
            # ‡πÉ‡∏ä‡πâ rule-based sentiment ‡πÄ‡∏õ‡πá‡∏ô label ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
            sentiment_score = comment.get('sentiment_score', 0)
            emotion = comment.get('emotion', 'neutral')
            
            # ‡πÅ‡∏õ‡∏•‡∏á sentiment ‡πÄ‡∏õ‡πá‡∏ô label
            if sentiment_score > 0.2:
                label = 'positive'
            elif sentiment_score < -0.2:
                label = 'negative'
            else:
                label = 'neutral'
            
            # ‡∏õ‡∏£‡∏±‡∏ö label ‡∏ï‡∏≤‡∏° emotion
            if emotion in ['anger', 'sadness', 'fear']:
                label = 'negative'
            elif emotion in ['joy', 'excited']:
                label = 'positive'
            
            # ‡∏õ‡∏£‡∏±‡∏ö label ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö complaint/problem contexts
            text_lower = text.lower()
            complaint_indicators = ['‡∏õ‡∏±‡∏ç‡∏´‡∏≤', '‡∏•‡πà‡∏°', '‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ', '‡∏´‡∏≤‡∏¢', '‡πÄ‡∏î‡∏∑‡∏≠‡∏î‡∏£‡πâ‡∏≠‡∏ô', '‡∏•‡∏≥‡∏ö‡∏≤‡∏Å', '‡πÅ‡∏¢‡πà']
            if any(indicator in text_lower for indicator in complaint_indicators):
                label = 'negative'
            
            processed_text = self.preprocessor.preprocess(text)
            if len(processed_text.strip()) > 5:  # ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏û‡∏≠‡∏™‡∏°‡∏Ñ‡∏ß‡∏£
                texts.append(processed_text)
                labels.append(label)
        
        return texts, labels
    
    def train(self, comments: List[Dict[str, Any]], test_size: float = 0.2):
        """‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô model"""
        if self.pipeline is None:
            self.create_model()
          # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        texts, labels = self.prepare_training_data(comments)
        
        if len(texts) < 10:
            raise ValueError("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ (‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 10 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)")
        
        safe_print(f"[INFO] ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô: {len(texts)} ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á")
        
        # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• train/test
        X_train, X_test, y_train, y_test = train_test_split(
            texts, labels, test_size=test_size, random_state=42, stratify=labels
        )
        
        safe_print(f"[INFO] Train: {len(X_train)}, Test: {len(X_test)}")
        
        # ‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô
        safe_print(f"[INFO] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô {self.model_type} model...")
        self.pipeline.fit(X_train, y_train)
        
        # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•
        train_score = self.pipeline.score(X_train, y_train)
        test_score = self.pipeline.score(X_test, y_test)
        
        safe_print(f"[INFO] Train Accuracy: {train_score:.3f}")
        safe_print(f"[INFO] Test Accuracy: {test_score:.3f}")
        
        # Detailed evaluation
        y_pred = self.pipeline.predict(X_test)
        safe_print("\n[INFO] Detailed Classification Report:")
        safe_print(classification_report(y_test, y_pred))
        
        return {
            'train_accuracy': train_score,
            'test_accuracy': test_score,
            'model_type': self.model_type
        }
    
    def predict_sentiment(self, text: str) -> Dict[str, Any]:
        """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ sentiment"""
        if self.pipeline is None:
            raise ValueError("Model ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô")
        
        processed_text = self.preprocessor.preprocess(text)
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
        prediction = self.pipeline.predict([processed_text])[0]
        probabilities = self.pipeline.predict_proba([processed_text])[0]
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        sentiment = prediction
        confidence = max(probabilities)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á score
        prob_dict = dict(zip(self.pipeline.classes_, probabilities))
        sentiment_score = (
            prob_dict.get('positive', 0) - prob_dict.get('negative', 0)
        )
        
        return {
            'sentiment': sentiment,
            'confidence': confidence,
            'sentiment_score': sentiment_score,
            'probabilities': {
                'positive': prob_dict.get('positive', 0),
                'neutral': prob_dict.get('neutral', 0), 
                'negative': prob_dict.get('negative', 0)
            },
            'model_type': 'ml_' + self.model_type
        }
    def save_model(self, filepath: str):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å model"""
        model_data = {
            'pipeline': self.pipeline,
            'model_type': self.model_type,
            'label_mapping': self.label_mapping
        }
        
        try:
            with open(filepath, 'wb') as f:
                pickle.dump(model_data, f)
            safe_print(f"[INFO] ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å model ‡∏ó‡∏µ‡πà: {filepath}")
        except Exception as e:
            safe_print(f"[ERROR] ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å model: {e}")
    
    def load_model(self, filepath: str):
        """‡πÇ‡∏´‡∏•‡∏î model"""
        try:
            with open(filepath, 'rb') as f:
                model_data = pickle.load(f)
            
            self.pipeline = model_data['pipeline']
            self.model_type = model_data['model_type']
            self.label_mapping = model_data['label_mapping']
            
            safe_print(f"[INFO] ‡πÇ‡∏´‡∏•‡∏î model ‡∏à‡∏≤‡∏Å: {filepath}")
        except Exception as e:
            safe_print(f"[ERROR] ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î model: {e}")

class ThaiTransformerModel:
    """Thai Sentiment Analysis with Transformer Models from Hugging Face"""
    
    def __init__(self, model_name: str = "twitter-roberta"):        # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô public ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ authentication
        self.available_models = {
            # Multilingual sentiment models (public)
            "twitter-roberta": "cardiffnlp/twitter-roberta-base-sentiment-latest",
            "multilingual-bert": "nlptown/bert-base-multilingual-uncased-sentiment",
            "distilbert-sentiment": "distilbert-base-uncased-finetuned-sst-2-english",
            
            # Basic BERT models (public)
            "bert-base": "bert-base-uncased",
            "bert-multilingual": "bert-base-multilingual-uncased",
            "distilbert": "distilbert-base-uncased",
            
            # XLM models (public)
            "xlm-roberta-base": "xlm-roberta-base",
            "xlm-roberta-large": "xlm-roberta-large",
        }
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ
        self.model_name = self.available_models.get(model_name, model_name)
        self.model_key = model_name
        self.tokenizer = None
        self.model = None
        self.pipeline = None
        self.preprocessor = ThaiTextPreprocessor()        
        self.fallback_models = [
            "cardiffnlp/twitter-roberta-base-sentiment-latest",  # Public Twitter sentiment model
            "nlptown/bert-base-multilingual-uncased-sentiment",  # Public multilingual sentiment
            "distilbert-base-uncased-finetuned-sst-2-english",  # Known working English model
        ]
    
    def initialize(self):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô transformer model ‡∏û‡∏£‡πâ‡∏≠‡∏° fallback"""
        if not TRANSFORMERS_AVAILABLE:
            raise ImportError("transformers library is required")
        
        success = False
        models_to_try = [self.model_name] + self.fallback_models
        
        for model_path in models_to_try:
            try:
                print(f"[INFO] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î {model_path}...")
                
                # ‡πÇ‡∏´‡∏•‡∏î tokenizer ‡πÅ‡∏•‡∏∞ model
                self.tokenizer = AutoTokenizer.from_pretrained(
                    model_path,
                    trust_remote_code=True,
                    use_fast=False  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
                )
                
                # ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î sentiment classification model
                try:
                    self.model = AutoModelForSequenceClassification.from_pretrained(
                        model_path,
                        num_labels=3,  # negative, neutral, positive
                        trust_remote_code=True
                    )
                    
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á pipeline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sentiment analysis
                    self.pipeline = pipeline(
                        "sentiment-analysis",
                        model=self.model,
                        tokenizer=self.tokenizer,
                        return_all_scores=True,
                        device=-1  # ‡πÉ‡∏ä‡πâ CPU (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô 0 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPU)
                    )
                    
                except Exception:
                    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ classification head ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô feature extractor + custom classifier
                    from transformers import AutoModel
                    self.model = AutoModel.from_pretrained(
                        model_path,
                        trust_remote_code=True
                    )
                    
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á custom pipeline
                    self.pipeline = self._create_custom_pipeline()
                
                print(f"[INFO] ‡πÇ‡∏´‡∏•‡∏î {model_path} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                self.model_name = model_path
                success = True
                break
                
            except Exception as e:
                print(f"[WARNING] ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î {model_path}: {e}")
                continue
        
        if not success:
            print("[ERROR] ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î Transformer model ‡πÉ‡∏î‡πÜ ‡πÑ‡∏î‡πâ")
            # ‡πÉ‡∏ä‡πâ basic sentiment pipeline ‡πÅ‡∏ó‡∏ô
            try:
                self.pipeline = pipeline("sentiment-analysis", return_all_scores=True)
                print("[INFO] ‡πÉ‡∏ä‡πâ basic sentiment pipeline")
                success = True
            except Exception as e:
                raise Exception(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô transformer model ‡πÑ‡∏î‡πâ: {e}")
    
    def _create_custom_pipeline(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á custom pipeline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ classification head"""
        import torch
        import torch.nn.functional as F
        
        class CustomSentimentPipeline:
            def __init__(self, model, tokenizer):
                self.model = model
                self.tokenizer = tokenizer
                self.device = torch.device('cpu')
                
                # Simple classification layer
                self.classifier = torch.nn.Linear(
                    self.model.config.hidden_size, 3
                ).to(self.device)
                
                # Initialize weights
                torch.nn.init.xavier_uniform_(self.classifier.weight)
            
            def __call__(self, text):
                inputs = self.tokenizer(
                    text, 
                    return_tensors="pt", 
                    truncation=True, 
                    max_length=512,
                    padding=True
                ).to(self.device)
                
                with torch.no_grad():
                    outputs = self.model(**inputs)
                    # ‡πÉ‡∏ä‡πâ [CLS] token ‡∏´‡∏£‡∏∑‡∏≠ pooled output
                    if hasattr(outputs, 'pooler_output') and outputs.pooler_output is not None:
                        features = outputs.pooler_output
                    else:
                        features = outputs.last_hidden_state[:, 0, :]  # [CLS] token
                    
                    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ sentiment
                    logits = self.classifier(features)
                    probs = F.softmax(logits, dim=-1)
                    
                    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô format ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
                    labels = ['NEGATIVE', 'NEUTRAL', 'POSITIVE']
                    results = []
                    for i, (label, prob) in enumerate(zip(labels, probs[0])):
                        results.append({
                            'label': label,
                            'score': float(prob)
                        })
                    
                    return results
        
        return CustomSentimentPipeline(self.model, self.tokenizer)
    
    def predict_sentiment(self, text: str) -> Dict[str, Any]:
        """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ sentiment ‡∏î‡πâ‡∏ß‡∏¢ transformer"""
        if self.pipeline is None:
            self.initialize()
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        processed_text = self.preprocessor.clean_text(text)
        
        try:
            # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
            results = self.pipeline(processed_text)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            if isinstance(results[0], list):
                results = results[0]  # unwrap if nested
            
            # ‡∏´‡∏≤ sentiment ‡∏ó‡∏µ‡πà‡∏°‡∏µ confidence ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
            best_result = max(results, key=lambda x: x['score'])
            sentiment = best_result['label'].lower()
            confidence = best_result['score']
            
            # ‡πÅ‡∏õ‡∏•‡∏á label ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
            label_mapping = {
                'negative': 'negative', 'neg': 'negative', 'label_0': 'negative',
                'neutral': 'neutral', 'neu': 'neutral', 'label_1': 'neutral', 
                'positive': 'positive', 'pos': 'positive', 'label_2': 'positive'
            }
            sentiment = label_mapping.get(sentiment, 'neutral')
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì sentiment score
            sentiment_score = 0.0
            for result in results:
                label = label_mapping.get(result['label'].lower(), 'neutral')
                if label == 'positive':
                    sentiment_score += result['score']
                elif label == 'negative':
                    sentiment_score -= result['score']
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á probabilities dict
            probabilities = {'positive': 0.0, 'neutral': 0.0, 'negative': 0.0}
            for result in results:
                label = label_mapping.get(result['label'].lower(), 'neutral')
                probabilities[label] = result['score']
            
            return {
                'sentiment': sentiment,
                'confidence': confidence,
                'sentiment_score': sentiment_score,
                'probabilities': probabilities,
                'model_type': 'transformer'
            }
            
        except Exception as e:
            print(f"[ERROR] Transformer prediction failed: {e}")
            # Fallback to neutral
            return {
                'sentiment': 'neutral',
                'confidence': 0.5,
                'sentiment_score': 0.0,
                'probabilities': {'positive': 0.33, 'neutral': 0.34, 'negative': 0.33},
                'model_type': 'transformer_fallback'
            }

class EnsembleSentimentModel:
    """‡∏£‡∏ß‡∏° multiple models ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î"""
    def __init__(self):
        self.models = {}
        self.weights = {}
        
    def add_model(self, name: str, model, weight: float = 1.0):
        """‡πÄ‡∏û‡∏¥‡πà‡∏° model ‡πÄ‡∏Ç‡πâ‡∏≤ ensemble"""
        self.models[name] = model
        self.weights[name] = weight
        safe_print(f"[INFO] ‡πÄ‡∏û‡∏¥‡πà‡∏° {name} model ‡πÄ‡∏Ç‡πâ‡∏≤ ensemble (weight: {weight})")
    
    def predict_sentiment(self, text: str) -> Dict[str, Any]:
        """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ sentiment ‡∏î‡πâ‡∏ß‡∏¢ ensemble"""
        if not self.models:
            raise ValueError("‡πÑ‡∏°‡πà‡∏°‡∏µ model ‡πÉ‡∏ô ensemble")
        
        predictions = {}
        total_weight = 0
        weighted_scores = {'positive': 0, 'neutral': 0, 'negative': 0}
        weighted_sentiment_score = 0
        
        # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å model
        for name, model in self.models.items():
            try:
                result = model.predict_sentiment(text)
                predictions[name] = result
                
                weight = self.weights[name]
                total_weight += weight
                
                # ‡∏£‡∏ß‡∏° probabilities ‡πÅ‡∏ö‡∏ö‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å
                for sentiment, prob in result['probabilities'].items():
                    weighted_scores[sentiment] += prob * weight
                
                # ‡∏£‡∏ß‡∏° sentiment score
                weighted_sentiment_score += result['sentiment_score'] * weight
                
            except Exception as e:
                safe_print(f"[WARNING] {name} model failed: {e}")
                continue
        
        if total_weight == 0:
            raise ValueError("‡πÑ‡∏°‡πà‡∏°‡∏µ model ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ")
        
        # normalize weights
        for sentiment in weighted_scores:
            weighted_scores[sentiment] /= total_weight
        weighted_sentiment_score /= total_weight
        
        # ‡∏´‡∏≤ final sentiment
        final_sentiment = max(weighted_scores, key=weighted_scores.get)
        final_confidence = weighted_scores[final_sentiment]
        
        return {
            'sentiment': final_sentiment,
            'confidence': final_confidence,
            'sentiment_score': weighted_sentiment_score,
            'probabilities': weighted_scores,
            'model_type': 'ensemble',
            'individual_predictions': predictions
        }

def create_ml_enhanced_sentiment_analyzer(training_data: Optional[List[Dict[str, Any]]] = None) -> EnsembleSentimentModel:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á ML-enhanced sentiment analyzer ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• HF ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"""
    
    print("üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Advanced Thai Sentiment Analyzer...")
    print("üì± ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö: Social Media, ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ")
    
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á ensemble
    use_multi_hf_models = True  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô False ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏¥‡∏°
    
    if use_multi_hf_models:
        print("ü§ñ ‡πÉ‡∏ä‡πâ Multi-Model Hugging Face Ensemble")
        ensemble = create_multi_model_ensemble()
    else:
        print("üîß ‡πÉ‡∏ä‡πâ Traditional + Single HF Model")
        ensemble = EnsembleSentimentModel()
        
        # 1. Traditional ML Model (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô)
        if training_data and len(training_data) >= 20 and SKLEARN_AVAILABLE:
            print("[INFO] ‡∏™‡∏£‡πâ‡∏≤‡∏á Traditional ML model...")
            try:
                ml_model = ThaiSentimentMLModel(model_type="logistic")
                ml_results = ml_model.train(training_data)
                
                if ml_results['test_accuracy'] > 0.6:
                    ensemble.add_model("traditional_ml", ml_model, weight=0.3)
                else:
                    print("[WARNING] Traditional ML accuracy ‡∏ï‡πà‡∏≥, ‡∏Ç‡πâ‡∏≤‡∏° model ‡∏ô‡∏µ‡πâ")
                    
            except Exception as e:
                print(f"[WARNING] Traditional ML model failed: {e}")
        
        # 2. Best Thai Transformer Model
        if TRANSFORMERS_AVAILABLE:
            print("[INFO] ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å Hugging Face...")
            try:
                # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sentiment analysis
                transformer_model = ThaiTransformerModel("wisesight-sentiment")
                transformer_model.initialize()
                ensemble.add_model("hf_thai_sentiment", transformer_model, weight=0.5)
            except Exception as e:
                print(f"[WARNING] Thai HF model failed: {e}")
                
                # Fallback ‡πÑ‡∏õ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô
                try:
                    transformer_model = ThaiTransformerModel("xlm-roberta-sentiment")
                    transformer_model.initialize() 
                    ensemble.add_model("hf_multilingual", transformer_model, weight=0.4)
                except Exception as e2:
                    print(f"[WARNING] Fallback HF model failed: {e2}")
        
        # 3. Enhanced Rule-based (‡∏à‡∏≤‡∏Å original code)
        print("[INFO] ‡πÄ‡∏û‡∏¥‡πà‡∏° Enhanced Rule-based model...")
        class RuleBasedModel:
            def predict_sentiment(self, text):
                from social_media_utils import advanced_thai_sentiment_analysis
                result = advanced_thai_sentiment_analysis(text)
                
                emotion_to_sentiment = {
                    'joy': 'positive', 'excited': 'positive',
                    'anger': 'negative', 'sadness': 'negative', 'fear': 'negative',
                    'neutral': 'neutral'
                }
                
                sentiment = emotion_to_sentiment.get(result['emotion'], 'neutral')
                confidence = 0.7 if result['intensity'] == 'high' else 0.5
                
                if sentiment == 'positive':
                    probs = {'positive': 0.7, 'neutral': 0.2, 'negative': 0.1}
                elif sentiment == 'negative':
                    probs = {'positive': 0.1, 'neutral': 0.2, 'negative': 0.7}
                else:
                    probs = {'positive': 0.25, 'neutral': 0.5, 'negative': 0.25}
                
                return {
                    'sentiment': sentiment,
                    'confidence': confidence,
                    'sentiment_score': result['sentiment_score'],
                    'probabilities': probs,
                    'model_type': 'rule_based'
                }
        
        rule_model = RuleBasedModel()
        weight = 0.2 if ensemble.models else 1.0
        ensemble.add_model("rule_based", rule_model, weight=weight)
    
    print(f"‚úÖ Ensemble Sentiment Analyzer ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ({len(ensemble.models)} models)")
    print("üéØ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö: ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á, ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á, Auto Review")
    
    return ensemble

# --- Auto Review ‡πÅ‡∏•‡∏∞ Quality Control ---

class SentimentQualityReviewer:
    """‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û sentiment analysis ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥"""
    
    def __init__(self, confidence_threshold: float = 0.7, review_threshold: float = 0.5):
        self.confidence_threshold = confidence_threshold
        self.review_threshold = review_threshold
        
        # ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á
        self.political_keywords = {
            'negative': [
                '‡πÇ‡∏á‡πà', '‡∏´‡∏•‡∏≠‡∏Å', '‡∏ó‡∏∏‡∏à‡∏£‡∏¥‡∏ï', '‡∏â‡πâ‡∏≠‡πÇ‡∏Å‡∏á', '‡∏î‡πà‡∏≤', '‡∏ï‡∏≥‡∏´‡∏ô‡∏¥', '‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå', '‡πÅ‡∏¢‡πà', '‡∏ú‡∏¥‡∏î',
                '‡∏•‡∏≤‡∏≠‡∏≠‡∏Å', '‡πÑ‡∏•‡πà‡∏≠‡∏≠‡∏Å', '‡∏¢‡∏∏‡∏ö', '‡πÇ‡∏Å‡∏´‡∏Å', '‡∏´‡∏•‡∏≠‡∏Å‡∏•‡∏ß‡∏á', '‡∏Ñ‡∏≠‡∏£‡∏±‡∏õ‡∏ä‡∏±‡πà‡∏ô', '‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ',
                '‡∏õ‡∏±‡∏ç‡∏´‡∏≤', '‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß', '‡∏û‡∏±‡∏á', '‡πÄ‡∏™‡∏µ‡∏¢', '‡∏´‡πà‡∏ß‡∏¢', '‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô', '‡πÇ‡∏Å‡∏£‡∏ò', '‡∏â‡∏¥‡∏ö‡∏´‡∏≤‡∏¢'
            ],
            'positive': [
                '‡∏î‡∏µ', '‡πÄ‡∏Å‡πà‡∏á', '‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°', '‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î', '‡∏ä‡∏≠‡∏ö', '‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô', '‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢', 
                '‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á', '‡∏ä‡∏∑‡πà‡∏ô‡∏ä‡∏°', '‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à', '‡∏î‡∏µ‡πÉ‡∏à', '‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏à', '‡∏´‡∏ß‡∏±‡∏á', '‡πÄ‡∏ä‡∏¥‡∏î‡∏ä‡∏π'
            ],
            'criticism_words': [
                '‡πÑ‡∏°‡πà‡πÄ‡∏≠‡∏≤', '‡∏≠‡∏¢‡πà‡∏≤', '‡∏´‡∏¢‡∏∏‡∏î', '‡πÄ‡∏•‡∏¥‡∏Å', '‡∏õ‡∏è‡∏¥‡πÄ‡∏™‡∏ò', '‡∏Ñ‡∏±‡∏î‡∏Ñ‡πâ‡∏≤‡∏ô', '‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢',
                '‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î', '‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å', '‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£', '‡πÑ‡∏°‡πà‡∏î‡∏µ', '‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà', '‡∏ï‡∏≥‡∏´‡∏ô‡∏¥'
            ]
        }
        
        # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
        self.emotion_patterns = {
            'strong_negative': [
                r'[!]{2,}', r'[?]{2,}', r'‡∏´‡∏≤{2,}‡∏¢', r'‡πÅ‡∏¢‡πà{2,}', r'‡πÇ‡∏á‡πà{2,}',
                r'‡∏â‡∏¥‡∏ö+‡∏´‡∏≤‡∏¢', r'‡∏´‡πà‡∏ß‡∏¢+', r'‡πÄ‡∏Æ‡πâ‡∏¢+', r'‡πÄ‡∏ä‡∏µ‡πà‡∏¢+'
            ],
            'strong_positive': [
                r'‡∏î‡∏µ{2,}', r'‡πÄ‡∏Å‡πà‡∏á{2,}', r'‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î+', r'‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°+', r'‡∏ß‡∏≤‡∏ß+', r'‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°+'
            ],
            'sarcasm': [
                r'‡πÄ‡∏Å‡πà‡∏á‡∏à‡∏±‡∏á', r'‡∏î‡∏µ‡∏à‡∏±‡∏á', r'‡πÄ‡∏Å‡πà‡∏á‡∏°‡∏≤‡∏Å', r'‡∏î‡∏µ‡∏°‡∏≤‡∏Å.*‡πÑ‡∏°‡πà', r'‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß.*‡πÑ‡∏°‡πà',
                r'‡πÉ‡∏ä‡πà.*‡πÑ‡∏°‡πà', r'‡∏á‡∏±‡πâ‡∏ô‡∏´‡∏£‡∏≠', r'‡∏à‡∏£‡∏¥‡∏á‡πÜ.*‡πÄ‡∏´‡∏£‡∏≠', r'‡∏≠‡∏∑‡∏°.*‡πÉ‡∏ä‡πà'
            ]
        }

    def analyze_political_context(self, text: str) -> Dict[str, Any]:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        text_lower = text.lower()
        
        # ‡∏ô‡∏±‡∏ö‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå negative/positive
        neg_count = sum(1 for word in self.political_keywords['negative'] if word in text_lower)
        pos_count = sum(1 for word in self.political_keywords['positive'] if word in text_lower)
        crit_count = sum(1 for word in self.political_keywords['criticism_words'] if word in text_lower)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏û‡∏≤‡∏Å‡∏©‡πå‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå
        is_criticism = crit_count > 0 or neg_count > pos_count
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ/‡∏õ‡∏£‡∏∞‡∏ä‡∏î
        sarcasm_detected = any(re.search(pattern, text_lower) for pattern in self.emotion_patterns['sarcasm'])
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á
        strong_emotion = any(re.search(pattern, text_lower) for pattern in 
                           self.emotion_patterns['strong_negative'] + self.emotion_patterns['strong_positive'])
        
        return {
            'is_political': neg_count + pos_count + crit_count > 0,
            'neg_word_count': neg_count,
            'pos_word_count': pos_count,
            'criticism_count': crit_count,
            'is_criticism': is_criticism,
            'sarcasm_detected': sarcasm_detected,
            'strong_emotion': strong_emotion,
            'adjusted_sentiment': self._calculate_adjusted_sentiment(neg_count, pos_count, crit_count, sarcasm_detected)
        }

    def _calculate_adjusted_sentiment(self, neg_count: int, pos_count: int, crit_count: int, sarcasm: bool) -> str:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì sentiment ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏≤‡∏°‡∏ö‡∏£‡∏¥‡∏ö‡∏ó"""
        total_negative = neg_count + crit_count
        
        if sarcasm:
            return 'negative'  # ‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ‡∏°‡∏±‡∏Å‡πÄ‡∏õ‡πá‡∏ô negative
        
        if total_negative > pos_count * 2:  # ‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å negative ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤
            return 'negative'
        elif pos_count > total_negative:
            return 'positive'
        else:
            return 'neutral'

    def review_prediction(self, text: str, prediction: Dict[str, Any]) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ prediction"""
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á
        political_analysis = self.analyze_political_context(text)
        
        original_sentiment = prediction['sentiment']
        original_confidence = prediction['confidence']
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á review result
        review_result = prediction.copy()
        review_result.update({
            'original_sentiment': original_sentiment,
            'original_confidence': original_confidence,
            'political_context': political_analysis,
            'review_applied': False,
            'review_reason': '',
            'confidence_adjusted': False
        })
        
        # ‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ
        adjustments_made = []
        
        # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö confidence ‡∏ï‡πà‡∏≥
        if original_confidence < self.review_threshold:
            # ‡πÉ‡∏ä‡πâ political context ‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
            if political_analysis['is_political']:
                adjusted_sentiment = political_analysis['adjusted_sentiment']
                if adjusted_sentiment != original_sentiment:
                    review_result['sentiment'] = adjusted_sentiment
                    review_result['confidence'] = min(0.75, original_confidence + 0.2)
                    adjustments_made.append(f"political_context_override: {original_sentiment} -> {adjusted_sentiment}")
        
        # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ/‡∏õ‡∏£‡∏∞‡∏ä‡∏î
        if political_analysis['sarcasm_detected'] and original_sentiment != 'negative':
            review_result['sentiment'] = 'negative'
            review_result['confidence'] = max(0.7, original_confidence)
            adjustments_made.append("sarcasm_detected: forced negative")
        
        # 3. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á
        if (political_analysis['neg_word_count'] >= 2 and 
            original_sentiment == 'neutral'):
            review_result['sentiment'] = 'negative'
            review_result['confidence'] = max(0.65, original_confidence)
            adjustments_made.append("strong_criticism: neutral -> negative")
        
        # 4. ‡∏õ‡∏£‡∏±‡∏ö confidence ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ï‡πà‡∏≥‡πÅ‡∏ï‡πà‡∏°‡∏µ context ‡∏ä‡∏±‡∏î
        if (original_confidence < 0.6 and 
            (political_analysis['strong_emotion'] or political_analysis['criticism_count'] > 0)):
            review_result['confidence'] = min(0.8, original_confidence + 0.15)
            review_result['confidence_adjusted'] = True
            adjustments_made.append("confidence_boost: strong_emotion/criticism detected")
        
        # 5. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á sentiment ‡πÅ‡∏•‡∏∞ context
        if (original_sentiment == 'positive' and 
            political_analysis['neg_word_count'] > political_analysis['pos_word_count']):
            review_result['sentiment'] = 'negative'
            adjustments_made.append("contradiction_fix: positive with negative words -> negative")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ
        if adjustments_made:
            review_result['review_applied'] = True
            review_result['review_reason'] = '; '.join(adjustments_made)
            
            # ‡∏õ‡∏£‡∏±‡∏ö probabilities ‡πÉ‡∏´‡∏°‡πà
            if review_result['sentiment'] == 'negative':
                review_result['probabilities'] = {'negative': 0.7, 'neutral': 0.2, 'positive': 0.1}
                review_result['sentiment_score'] = -0.6
            elif review_result['sentiment'] == 'positive':
                review_result['probabilities'] = {'positive': 0.7, 'neutral': 0.2, 'negative': 0.1}
                review_result['sentiment_score'] = 0.6
            else:
                review_result['probabilities'] = {'neutral': 0.6, 'positive': 0.2, 'negative': 0.2}
                review_result['sentiment_score'] = 0.0
        
        return review_result

    def batch_review(self, predictions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö predictions ‡πÅ‡∏ö‡∏ö batch"""
        reviewed_predictions = []
        
        stats = {
            'total': len(predictions),
            'reviewed': 0,
            'sentiment_changed': 0,
            'confidence_adjusted': 0,
            'low_confidence_count': 0
        }
        
        for pred in predictions:
            text = pred.get('text', '')
            
            # Count low confidence
            if pred.get('ml_confidence', 1.0) < self.review_threshold:
                stats['low_confidence_count'] += 1
            
            # Review prediction
            reviewed = self.review_prediction(text, {
                'sentiment': pred.get('sentiment', 'neutral'),
                'confidence': pred.get('ml_confidence', 0.5),
                'sentiment_score': pred.get('sentiment_score', 0.0),
                'probabilities': pred.get('ml_probabilities', {'positive': 0.33, 'neutral': 0.34, 'negative': 0.33})
            })
            
            # Update original prediction with review results
            pred.update(reviewed)
            
            # Count changes
            if reviewed['review_applied']:
                stats['reviewed'] += 1
                if reviewed['sentiment'] != reviewed['original_sentiment']:
                    stats['sentiment_changed'] += 1
                if reviewed['confidence_adjusted']:
                    stats['confidence_adjusted'] += 1
            
            reviewed_predictions.append(pred)
          # Print review statistics
        safe_print(f"\nüìä Auto Review Statistics:")
        safe_print(f"  Total predictions: {stats['total']}")
        safe_print(f"  Low confidence (< {self.review_threshold}): {stats['low_confidence_count']}")
        safe_print(f"  Predictions reviewed: {stats['reviewed']}")
        safe_print(f"  Sentiment changed: {stats['sentiment_changed']}")
        safe_print(f"  Confidence adjusted: {stats['confidence_adjusted']}")
        
        return reviewed_predictions

class AdvancedThaiSentimentAnalyzer:
    """‡∏£‡∏∞‡∏ö‡∏ö sentiment analysis ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ auto review"""
    
    def __init__(self, confidence_threshold: float = 0.7):
        self.ensemble_model = None
        self.reviewer = SentimentQualityReviewer(confidence_threshold=confidence_threshold)
        self.training_data = []
        
    def initialize(self, training_data: Optional[List[Dict[str, Any]]] = None):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"""
        safe_print("üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Advanced Thai Sentiment Analyzer...")
        
        if training_data:
            self.training_data = training_data
            safe_print(f"üìö ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô: {len(training_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á ensemble model
        self.ensemble_model = create_ml_enhanced_sentiment_analyzer(training_data)
        safe_print("‚úÖ ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    
    def analyze_with_review(self, text: str) -> Dict[str, Any]:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡∏û‡∏£‡πâ‡∏≠‡∏° auto review"""
        if not self.ensemble_model:
            raise ValueError("‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏Å initialize() ‡∏Å‡πà‡∏≠‡∏ô")
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ sentiment
        prediction = self.ensemble_model.predict_sentiment(text)
        
        # Auto review
        reviewed_prediction = self.reviewer.review_prediction(text, prediction)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡∏¥‡∏°
        reviewed_prediction.update({
            'text': text,
            'analysis_timestamp': datetime.now().isoformat(),
            'analyzer_version': 'advanced_v2.0'
        })
        
        return reviewed_prediction
    def batch_analyze_with_review(self, texts: List[str]) -> List[Dict[str, Any]]:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå batch ‡∏û‡∏£‡πâ‡∏≠‡∏° auto review"""
        safe_print(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {len(texts)} ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°...")
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        predictions = []
        for i, text in enumerate(texts):
            if i % 50 == 0 and i > 0:
                safe_print(f"   ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡πâ‡∏ß: {i}/{len(texts)}")
            
            try:
                result = self.analyze_with_review(text)
                predictions.append(result)
            except Exception as e:
                safe_print(f"[WARNING] ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà {i+1} ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏î‡πâ: {e}")
                continue
        
        safe_print(f"‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {len(predictions)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        return predictions
    def update_training_data(self, new_data: List[Dict[str, Any]]):
        """‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
        self.training_data.extend(new_data)
        safe_print(f"üìà ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô: +{len(new_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏£‡∏ß‡∏°: {len(self.training_data)})")
        
        # ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠
        if len(self.training_data) >= 50:
            safe_print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà...")
            self.ensemble_model = create_ml_enhanced_sentiment_analyzer(self.training_data)
            safe_print("‚úÖ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")

# Example usage and testing
def test_ml_sentiment_analysis():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö ML sentiment analysis"""
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    test_texts = [
        "‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ ‡∏ä‡∏≠‡∏ö‡∏°‡∏≤‡∏Å",  # positive
        "‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å ‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡πÄ‡∏•‡∏¢",      # negative  
        "‡πÇ‡∏≠‡πÄ‡∏Ñ ‡∏õ‡∏Å‡∏ï‡∏¥‡∏î‡∏µ",           # neutral
        "‡∏•‡πà‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏ß‡∏±‡∏ô ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢", # negative
        "‡∏î‡∏µ‡πÉ‡∏à‡∏°‡∏≤‡∏Å‡∏Ñ‡πà‡∏∞ ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì"       # positive
    ]
    
    safe_print("=== ‡∏ó‡∏î‡∏™‡∏≠‡∏ö ML Sentiment Analysis ===")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á ensemble model
    ensemble = create_ml_enhanced_sentiment_analyzer()
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    for i, text in enumerate(test_texts):
        safe_print(f"\n{i+1}. \"{text}\"")
        try:
            result = ensemble.predict_sentiment(text)
            safe_print(f"   Sentiment: {result['sentiment']}")
            safe_print(f"   Confidence: {result['confidence']:.3f}")
            safe_print(f"   Score: {result['sentiment_score']:.3f}")
            safe_print(f"   Models: {len(result.get('individual_predictions', {}))}")
        except Exception as e:
            safe_print(f"   Error: {e}")

if __name__ == "__main__":
    test_ml_sentiment_analysis()

def get_best_thai_sentiment_model():
    """‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sentiment analysis"""
    
    # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏ó‡∏¢‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
    recommended_models = [
        {
            'name': 'wisesight-sentiment',
            'path': 'pythainlp/wangchanberta-base-att-spm-uncased-wisesight-sentiment',
            'description': 'WangchanBERTa fine-tuned ‡∏ö‡∏ô Wisesight dataset',
            'strengths': ['‡πÑ‡∏ó‡∏¢', 'social media', 'sentiment'],
            'size': 'base'
        },
        {
            'name': 'thai-sentiment',
            'path': 'airesearch/wangchanberta-base-att-spm-uncased-thai-sentiment',
            'description': 'WangchanBERTa ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sentiment analysis ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ',
            'strengths': ['‡πÑ‡∏ó‡∏¢', 'general sentiment'],
            'size': 'base'
        },
        {
            'name': 'phayathai-sentiment',
            'path': 'clicknext/phayathai_sentiment',
            'description': 'PhayaThaiBERT ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sentiment classification',
            'strengths': ['‡πÑ‡∏ó‡∏¢', 'sentiment', 'classification'],
            'size': 'base'
        },
        {
            'name': 'wangchanberta-base',
            'path': 'airesearch/wangchanberta-base-att-spm-uncased',
            'description': 'WangchanBERTa ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (‡∏ï‡πâ‡∏≠‡∏á fine-tune)',
            'strengths': ['‡πÑ‡∏ó‡∏¢', 'general purpose'],
            'size': 'base'
        },
        {
            'name': 'xlm-roberta-sentiment',
            'path': 'cardiffnlp/twitter-xlm-roberta-base-sentiment',
            'description': 'XLM-RoBERTa ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Twitter sentiment (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ó‡∏¢)',
            'strengths': ['multilingual', 'twitter', 'sentiment'],
            'size': 'base'
        }
    ]
    
    return recommended_models

def create_multi_model_ensemble():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á ensemble ‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• HF ‡∏ó‡∏µ‡πà‡∏î‡∏µ"""
    ensemble = EnsembleSentimentModel()
    
    # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏£‡∏ß‡∏°‡πÉ‡∏ô ensemble
    models_to_try = [
        ('wisesight', 'wisesight-sentiment', 0.4),  # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î - ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö social media
        ('phayathai', 'phayathai-sentiment', 0.3),  # ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏ó‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞
        ('xlm-roberta', 'xlm-roberta-sentiment', 0.2),  # multilingual backup
        ('wangchanberta', 'wangchanberta-base', 0.1)  # ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
    ]
    
    print("ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Multi-Model Ensemble ‡∏à‡∏≤‡∏Å Hugging Face...")
    
    successful_models = 0
    for model_name, model_key, weight in models_to_try:
        try:
            print(f"[INFO] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î {model_name}...")
            transformer_model = ThaiTransformerModel(model_key)
            transformer_model.initialize()
            ensemble.add_model(model_name, transformer_model, weight=weight)
            successful_models += 1
            print(f"‚úÖ {model_name} ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (weight: {weight})")
        except Exception as e:
            print(f"‚ùå {model_name} ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
            continue
    
    if successful_models == 0:
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• HF ‡πÑ‡∏î‡πâ ‡∏à‡∏∞‡πÉ‡∏ä‡πâ rule-based ‡πÅ‡∏ó‡∏ô")
        # Fallback to rule-based
        class RuleBasedModel:
            def predict_sentiment(self, text):
                from social_media_utils import advanced_thai_sentiment_analysis
                result = advanced_thai_sentiment_analysis(text)
                
                emotion_to_sentiment = {
                    'joy': 'positive', 'excited': 'positive',
                    'anger': 'negative', 'sadness': 'negative', 'fear': 'negative',
                    'neutral': 'neutral'
                }
                
                sentiment = emotion_to_sentiment.get(result['emotion'], 'neutral')
                confidence = 0.7 if result['intensity'] == 'high' else 0.5
                
                if sentiment == 'positive':
                    probs = {'positive': 0.7, 'neutral': 0.2, 'negative': 0.1}
                elif sentiment == 'negative':
                    probs = {'positive': 0.1, 'neutral': 0.2, 'negative': 0.7}
                else:
                    probs = {'positive': 0.25, 'neutral': 0.5, 'negative': 0.25}
                
                return {
                    'sentiment': sentiment,
                    'confidence': confidence,
                    'sentiment_score': result['sentiment_score'],
                    'probabilities': probs,
                    'model_type': 'rule_based_fallback'
                }
        
        ensemble.add_model("rule_based_fallback", RuleBasedModel(), weight=1.0)
    
    print(f"üéØ Ensemble ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô: {len(ensemble.models)} models")
    return ensemble

def test_huggingface_models():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• Hugging Face ‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
    
    test_texts = [
        # Thai political comments (from our dataset)
        "‡∏ô‡∏≤‡∏¢‡∏Å‡πÇ‡∏á‡πà‡πÑ‡∏°‡πà‡∏ó‡∏±‡∏ô‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏Ç‡∏≠‡∏á‡∏Æ‡∏∏‡∏ô‡πÄ‡∏ã‡∏ô ‡∏ó‡∏∏‡∏Å‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡∏Ñ‡∏¥‡∏î‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏ô‡∏≤‡∏¢‡∏Å",  # negative
        "‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡πà‡∏∞‡∏ó‡∏´‡∏≤‡∏£‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏à‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞",  # neutral/positive
        "‡∏≠‡∏¢‡πà‡∏≤‡πÄ‡∏≠‡∏≤‡∏ó‡∏´‡∏≤‡∏£‡∏°‡∏≤‡∏¢‡∏∏‡πà‡∏á‡∏î‡∏µ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πá‡∏î‡πÄ‡∏´‡∏£‡∏≠‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏™‡∏†‡∏≤‡πÄ‡∏ñ‡∏≠‡∏∞",  # negative/sarcasm
        
        # General sentiment
        "‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ ‡∏ä‡∏≠‡∏ö‡∏°‡∏≤‡∏Å",  # positive
        "‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å ‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡πÄ‡∏•‡∏¢",      # negative  
        "‡πÇ‡∏≠‡πÄ‡∏Ñ ‡∏õ‡∏Å‡∏ï‡∏¥‡∏î‡∏µ",           # neutral
        
        # Social media style
        "‡∏ß‡πâ‡∏≤‡∏ß‡∏ß‡∏ß‡∏ß ‡πÄ‡∏Å‡πà‡∏á‡∏°‡∏≤‡∏Å‡∏à‡∏£‡∏¥‡∏á‡πÜ 555",  # positive
        "‡πÄ‡∏Æ‡πâ‡∏¢!! ‡∏°‡∏±‡∏ô‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏ô‡∏µ‡πà‡∏¢",     # negative
        "‡∏≠‡∏∑‡∏°‡∏°... ‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏ô‡∏∞",          # neutral
    ]
    
    print("üß™ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• Hugging Face ‡∏ï‡πà‡∏≤‡∏á‡πÜ...")
    print("=" * 80)
    
    # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    models_to_test = [
        ("wisesight-sentiment", "WangchanBERTa + Wisesight"),
        ("phayathai-sentiment", "PhayaThaiBERT Sentiment"),
        ("xlm-roberta-sentiment", "XLM-RoBERTa Multilingual"),
        ("wangchanberta-base", "WangchanBERTa Base"),
    ]
    
    results = {}
    
    for model_key, model_desc in models_to_test:
        print(f"\nü§ñ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö: {model_desc}")
        print("-" * 50)
        
        try:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•
            model = ThaiTransformerModel(model_key)
            model.initialize()
            
            model_results = []
            for i, text in enumerate(test_texts):
                try:
                    result = model.predict_sentiment(text)
                    model_results.append(result)
                    
                    print(f"{i+1:2d}. \"{text[:50]}...\"")
                    print(f"    ‚Üí {result['sentiment']} ({result['confidence']:.3f})")
                    
                except Exception as e:
                    print(f"{i+1:2d}. Error: {e}")
                    model_results.append(None)
            
            results[model_key] = {
                'description': model_desc,
                'results': model_results,
                'success': True
            }
            
        except Exception as e:
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î {model_desc}: {e}")
            results[model_key] = {
                'description': model_desc,
                'results': None,
                'success': False,
                'error': str(e)
            }
    
    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    print("\n" + "=" * 80)
    print("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö:")
    
    successful_models = [k for k, v in results.items() if v['success']]
    failed_models = [k for k, v in results.items() if not v['success']]
    
    print(f"‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ: {len(successful_models)}/{len(models_to_test)}")
    for model in successful_models:
        print(f"   - {results[model]['description']}")
    
    if failed_models:
        print(f"‚ùå ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {len(failed_models)}")
        for model in failed_models:
            print(f"   - {results[model]['description']}: {results[model]['error']}")
    
    # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    if successful_models:
        print(f"\nüí° ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡πÉ‡∏ä‡πâ {results[successful_models[0]]['description']} ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å")
        if len(successful_models) > 1:
            print(f"üîÑ Ensemble: ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö {results[successful_models[1]]['description']} ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô")
    
    return results

def benchmark_sentiment_models():
    """‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
    
    print("‚ö° ‡∏Å‡∏≥‡∏•‡∏±‡∏á Benchmark ‡πÇ‡∏°‡πÄ‡∏î‡∏• Sentiment Analysis...")
    
    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏µ ground truth
    test_cases = [
        {"text": "‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ ‡∏ä‡∏≠‡∏ö‡∏°‡∏≤‡∏Å", "expected": "positive"},
        {"text": "‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å ‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡πÄ‡∏•‡∏¢", "expected": "negative"},
        {"text": "‡πÇ‡∏≠‡πÄ‡∏Ñ ‡∏õ‡∏Å‡∏ï‡∏¥‡∏î‡∏µ", "expected": "neutral"},
        {"text": "‡πÇ‡∏á‡πà‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏´‡πà‡∏ß‡∏¢‡πÅ‡∏ï‡∏Å", "expected": "negative"},
        {"text": "‡∏î‡∏µ‡πÉ‡∏à‡∏°‡∏≤‡∏Å‡∏Ñ‡πà‡∏∞ ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì", "expected": "positive"},
        {"text": "‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô", "expected": "neutral"},
        {"text": "‡πÄ‡∏Å‡πà‡∏á‡∏°‡∏≤‡∏Å‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÄ‡∏•‡∏¥‡∏ü", "expected": "positive"},
        {"text": "‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏¢‡∏≠‡∏∞‡∏°‡∏≤‡∏Å ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ", "expected": "negative"},
        # ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á
        {"text": "‡∏ô‡∏≤‡∏¢‡∏Å‡πÄ‡∏Å‡πà‡∏á‡∏°‡∏≤‡∏Å ‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô", "expected": "positive"},
        {"text": "‡∏•‡∏≤‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ‡πÄ‡∏•‡∏¢ ‡πÑ‡∏°‡πà‡πÑ‡∏´‡∏ß", "expected": "negative"},
    ]
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö ensemble model
    try:
        print("üéØ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Advanced Ensemble Model...")
        ensemble = create_ml_enhanced_sentiment_analyzer()
        
        correct = 0
        total = len(test_cases)
        
        for case in test_cases:
            result = ensemble.predict_sentiment(case['text'])
            predicted = result['sentiment']
            expected = case['expected']
            
            is_correct = predicted == expected
            if is_correct:
                correct += 1
            
            print(f"‚úì" if is_correct else "‚úó", end=" ")
            print(f"\"{case['text'][:40]}...\" ‚Üí {predicted} (expected: {expected})")
        
        accuracy = correct / total * 100
        print(f"\nüìà Accuracy: {accuracy:.1f}% ({correct}/{total})")
        
        if accuracy >= 80:
            print("üéâ ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°!")
        elif accuracy >= 60:
            print("üëç ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏î‡∏µ")
        else:
            print("‚ö†Ô∏è ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•")
            
    except Exception as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏î‡∏™‡∏≠‡∏ö ensemble ‡πÑ‡∏î‡πâ: {e}")
