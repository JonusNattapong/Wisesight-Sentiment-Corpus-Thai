#!/usr/bin/env python3
"""
‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Multiple URLs/Queries Extraction
"""

import sys
from pathlib import Path

# Add the current directory to Python path
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from social_media_utils import extract_social_media_comments, save_comments_for_training

def example_multiple_youtube_videos():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å YouTube ‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠"""
    print("=== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: YouTube ‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ===")
    
    youtube_urls = [
        "https://www.youtube.com/watch?v=K150FJzooLM",  # ‡∏´‡∏•‡∏ß‡∏á‡∏û‡πà‡∏≠‡πÅ‡∏¢‡πâ‡∏°
        "K150FJzooLM",  # Same video, different format
        "https://www.youtube.com/watch?v=dQw4w9WgXcQ"   # Rick Roll (example)
    ]
    
    comments = extract_social_media_comments(
        platform="youtube",
        query=youtube_urls,
        max_results=50,
        include_advanced_sentiment=True,
        silent=False
    )
    
    print(f"\n‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö {len(comments)} comments ‡∏à‡∏≤‡∏Å {len(youtube_urls)} ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
    for i, comment in enumerate(comments[:3]):
        print(f"\n[{i+1}] {comment.get('text', '')[:100]}...")
        print(f"    Source: {comment.get('source_query', 'Unknown')}")
        if 'emotion' in comment:
            print(f"    Emotion: {comment['emotion']}")
        if 'intensity' in comment:
            print(f"    Intensity: {comment['intensity']}")
    
    return comments

def example_multiple_pantip_topics():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å Pantip ‡∏´‡∏•‡∏≤‡∏¢‡∏Å‡∏£‡∏∞‡∏ó‡∏π‡πâ"""
    print("\n=== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: Pantip ‡∏´‡∏•‡∏≤‡∏¢‡∏Å‡∏£‡∏∞‡∏ó‡∏π‡πâ ===")
    
    pantip_topics = [
        "43494778",  # ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏ô‡πá‡∏ï TRUE
        "https://pantip.com/topic/43494778",  # Same topic, different format
        "43123456"   # Example topic (may not exist)
    ]
    
    comments = extract_social_media_comments(
        platform="pantip",
        query=pantip_topics,
        max_results=30,
        include_sentiment=True,
        silent=False
    )
    
    print(f"\n‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö {len(comments)} comments ‡∏à‡∏≤‡∏Å {len(pantip_topics)} ‡∏Å‡∏£‡∏∞‡∏ó‡∏π‡πâ")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
    for i, comment in enumerate(comments[:3]):
        print(f"\n[{i+1}] {comment.get('text', '')[:100]}...")
        print(f"    Source: {comment.get('source_query', 'Unknown')}")
        print(f"    Sentiment: {comment.get('sentiment', 'Unknown')}")
    
    return comments

def example_multiple_files():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå"""
    print("\n=== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå ===")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
    test_files = []
    
    # ‡πÑ‡∏ü‡∏•‡πå 1
    file1 = Path("test_comments_1.jsonl")
    with open(file1, "w", encoding="utf-8") as f:
        f.write('{"text": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå 1", "platform": "test"}\n')
        f.write('{"text": "‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå 1", "platform": "test"}\n')
    test_files.append(str(file1))
    
    # ‡πÑ‡∏ü‡∏•‡πå 2  
    file2 = Path("test_comments_2.jsonl")
    with open(file2, "w", encoding="utf-8") as f:
        f.write('{"text": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå 2", "platform": "test"}\n')
        f.write('{"text": "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á", "platform": "test"}\n')
    test_files.append(str(file2))
    
    try:
        comments = extract_social_media_comments(
            platform="file",
            query=test_files,
            max_results=50,
            include_advanced_sentiment=True,
            silent=False
        )
        
        print(f"\n‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö {len(comments)} comments ‡∏à‡∏≤‡∏Å {len(test_files)} ‡πÑ‡∏ü‡∏•‡πå")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
        for i, comment in enumerate(comments):
            print(f"\n[{i+1}] {comment.get('text', '')}")
            print(f"    Source: {comment.get('source_query', 'Unknown')}")
            if 'emotion' in comment:
                print(f"    Emotion: {comment['emotion']}")
        
        return comments
        
    finally:
        # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏î‡∏™‡∏≠‡∏ö
        for file_path in test_files:
            try:
                Path(file_path).unlink()
            except:
                pass

def example_save_multiple_results():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ sources"""
    print("\n=== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ Sources ===")
    
    # ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ sources
    youtube_urls = [
        "K150FJzooLM",  # ‡∏´‡∏•‡∏ß‡∏á‡∏û‡πà‡∏≠‡πÅ‡∏¢‡πâ‡∏°
        "dQw4w9WgXcQ"   # Rick Roll
    ]
    
    comments = extract_social_media_comments(
        platform="youtube",
        query=youtube_urls,
        max_results=20,
        include_advanced_sentiment=True,
        silent=False
    )
    
    if comments:
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ
        output_dir = Path("data")
        output_dir.mkdir(exist_ok=True)
        
        # JSONL
        jsonl_path = save_comments_for_training(
            comments, 
            str(output_dir / "multiple_sources_example.jsonl"),
            "jsonl",
            exclude_spam=True
        )
        
        # CSV
        csv_path = save_comments_for_training(
            comments, 
            str(output_dir / "multiple_sources_example.csv"),
            "csv",
            exclude_spam=True
        )
        
        print(f"\n‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à:")
        print(f"- JSONL: {jsonl_path}")
        print(f"- CSV: {csv_path}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
        source_counts = {}
        for comment in comments:
            source = comment.get("source_query", "unknown")
            source_counts[source] = source_counts.get(source, 0) + 1
        
        print(f"\n‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° source:")
        for source, count in source_counts.items():
            print(f"  {source}: {count} comments")

def main():
    """‡∏£‡∏±‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    print("üî• ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Multiple URLs/Queries Extraction üî•")
    print("=" * 60)
    
    try:
        # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 1: YouTube ‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
        youtube_comments = example_multiple_youtube_videos()
        
        # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 2: Pantip ‡∏´‡∏•‡∏≤‡∏¢‡∏Å‡∏£‡∏∞‡∏ó‡∏π‡πâ  
        pantip_comments = example_multiple_pantip_topics()
        
        # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 3: ‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå
        file_comments = example_multiple_files()
        
        # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 4: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        example_save_multiple_results()
        
        print("\n" + "=" * 60)
        print("‚úÖ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
        print("üí° ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ CLI ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:")
        print("   python get_comments.py youtube URL1 URL2 URL3 --include_advanced_sentiment")
        print("   python get_comments.py pantip TOPIC1 TOPIC2 --max_results 100")
        print("   python get_comments.py file file1.jsonl file2.jsonl --format csv")
        
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")

if __name__ == "__main__":
    main()
