#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Integration module for Detailed Thai Sentiment Analysis
à¹‚à¸¡à¸”à¸¹à¸¥à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸£à¸°à¸šà¸š sentiment analysis à¹ƒà¸«à¸¡à¹ˆà¸à¸±à¸šà¸£à¸°à¸šà¸šà¹€à¸”à¸´à¸¡
"""

from typing import Dict, List, Any, Optional, Union
from detailed_thai_sentiment import DetailedThaiSentimentAnalyzer, EMOTION_GROUPS
import json

# à¸ªà¸£à¹‰à¸²à¸‡ global analyzer instance
_detailed_analyzer = None

def get_detailed_analyzer() -> DetailedThaiSentimentAnalyzer:
    """à¹„à¸”à¹‰à¸£à¸±à¸š analyzer instance (singleton pattern)"""
    global _detailed_analyzer
    if _detailed_analyzer is None:
        _detailed_analyzer = DetailedThaiSentimentAnalyzer()
    return _detailed_analyzer

def analyze_detailed_sentiment(
    text: str, 
    mode: str = "single",  # "single" à¸«à¸£à¸·à¸­ "multi"
    threshold: float = 0.3,
    include_scores: bool = False
) -> Dict[str, Any]:
    """
    à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ sentiment à¹à¸šà¸šà¸¥à¸°à¹€à¸­à¸µà¸¢à¸”
    
    Args:
        text: à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ
        mode: "single" à¸ªà¸³à¸«à¸£à¸±à¸š single-label, "multi" à¸ªà¸³à¸«à¸£à¸±à¸š multi-label
        threshold: threshold à¸ªà¸³à¸«à¸£à¸±à¸š multi-label (default: 0.3)
        include_scores: à¸£à¸§à¸¡à¸„à¸°à¹à¸™à¸™à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    
    Returns:
        Dict à¸—à¸µà¹ˆà¸¡à¸µà¸œà¸¥à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ
    """
    # Check for sarcasm first using the enhanced detection
    try:
        from app import analyze_sarcasm, analyze_sentiment_builtin
        sarcasm_result = analyze_sarcasm(text)
        
        # If sarcasm is detected, use the builtin analysis with sarcasm handling
        if sarcasm_result.get('is_sarcastic', False):
            result = analyze_sentiment_builtin(text, mode=mode, threshold=threshold)
            formatted_result = {
                "text": text,
                "sentiment": result["sentiment"],
                "confidence": result["confidence"],
                "sentiment_score": result.get("sentiment_score", _sentiment_to_score(result["sentiment"])),
                "detailed_emotion": result.get("detailed_emotion", "à¹€à¸‰à¸¢ à¹†"),
                "emotion_group": result.get("emotion_group", "Neutral"),
                "context": result.get("context", {}),
                "sarcasm_detected": True,
                "sarcasm_reason": sarcasm_result.get('reason', ''),
                "analysis_mode": mode,
                "model_used": "builtin_with_sarcasm"
            }
            if mode == "multi":
                formatted_result["detailed_emotions"] = result.get("detailed_emotions", [result.get("detailed_emotion", "à¹€à¸‰à¸¢ à¹†")])
                formatted_result["emotion_groups"] = result.get("emotion_groups", [result.get("emotion_group", "Neutral")])
                formatted_result["primary_emotion"] = result.get("detailed_emotions", [result.get("detailed_emotion", "à¹€à¸‰à¸¢ à¹†")])[0]
                formatted_result["threshold"] = threshold
            if include_scores:
                formatted_result["all_scores"] = result.get("scores", {})
            return formatted_result
    except ImportError:
        pass  # Fall back to original detailed analysis
    except Exception as e:
        print(f"Warning: Sarcasm detection failed: {e}")
    
    # Original detailed analysis for non-sarcastic text
    analyzer = get_detailed_analyzer()
    try:
        if mode == "single":
            result = analyzer.analyze_single_label(text)
            formatted_result = {
                "text": text,
                "sentiment": _map_emotion_to_sentiment(result.get("label", "à¹€à¸‰à¸¢ à¹†")),
                "detailed_emotion": result.get("label", "à¹€à¸‰à¸¢ à¹†"),
                "emotion_group": result.get("group", "Neutral"),
                "confidence": result.get("confidence", 0.0),
                "context": result.get("context", {}),
                "analysis_mode": "single_label",
                "model_used": "detailed_analyzer"
            }
            if include_scores:
                formatted_result["all_scores"] = result.get("scores", {})
        elif mode == "multi":
            result = analyzer.analyze_multi_label(text, threshold=threshold)
            labels = result.get("labels", [])
            primary_emotion = labels[0] if labels else "à¹€à¸‰à¸¢ à¹†"
            formatted_result = {
                "text": text,
                "sentiment": _map_emotion_to_sentiment(primary_emotion),
                "detailed_emotions": labels,
                "emotion_groups": result.get("groups", []),
                "primary_emotion": primary_emotion,
                "context": result.get("context", {}),
                "threshold": threshold,
                "analysis_mode": "multi_label",
                "model_used": "detailed_analyzer"
            }
            if include_scores:
                formatted_result["all_scores"] = result.get("scores", {})
        else:
            raise ValueError(f"Invalid mode: {mode}. Use 'single' or 'multi'")
        return formatted_result
    except Exception as e:
        # à¸à¸£à¸“à¸µà¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸” à¹ƒà¸«à¹‰à¸„à¸·à¸™à¸„à¹ˆà¸² default à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸—à¸³à¹ƒà¸«à¹‰à¸£à¸°à¸šà¸šà¸¥à¹ˆà¸¡
        if mode == "single":
            return {
                "text": text,
                "sentiment": "neutral",
                "detailed_emotion": "à¹€à¸‰à¸¢ à¹†",
                "emotion_group": "Neutral",
                "confidence": 0.0,
                "context": {},
                "analysis_mode": "single_label",
                "error": str(e)
            }
        else:
            return {
                "text": text,
                "sentiment": "neutral",
                "detailed_emotions": ["à¹€à¸‰à¸¢ à¹†"],
                "emotion_groups": ["Neutral"],
                "primary_emotion": "à¹€à¸‰à¸¢ à¹†",
                "context": {},
                "threshold": threshold,
                "analysis_mode": "multi_label",
                "error": str(e)
            }

def _map_emotion_to_sentiment(emotion: str) -> str:
    """à¹à¸›à¸¥à¸‡à¸­à¸²à¸£à¸¡à¸“à¹Œà¹€à¸›à¹‡à¸™ sentiment à¹à¸šà¸šà¹€à¸”à¸´à¸¡ (positive/negative/neutral)"""
    group = EMOTION_GROUPS.get(emotion)
    if not group:
        # à¸«à¸²à¸à¹„à¸¡à¹ˆà¸à¸šà¹ƒà¸™ group à¹ƒà¸«à¹‰à¸”à¸¹à¸ˆà¸²à¸ EMOTION_GROUPS
        for group_name, emotions in EMOTION_GROUPS.items():
            if emotion in emotions:
                group = group_name
                break
    
    if group == "Positive":
        return "positive"
    elif group == "Negative":
        return "negative"
    elif group == "Neutral":
        return "neutral"
    elif group == "Others":
        # à¸ªà¸³à¸«à¸£à¸±à¸š Others à¹ƒà¸«à¹‰à¸”à¸¹à¸ˆà¸²à¸à¸­à¸²à¸£à¸¡à¸“à¹Œà¹€à¸‰à¸à¸²à¸°
        if emotion in ["à¸‚à¸³à¸‚à¸±à¸™"]:
            return "positive"
        elif emotion in ["à¸›à¸£à¸°à¸Šà¸”", "à¹€à¸ªà¸µà¸¢à¸”à¸ªà¸µ"]:
            return "negative"
        else:
            return "neutral"
    else:
        return "neutral"

def batch_analyze_detailed_sentiment(
    texts: List[str],
    mode: str = "single",
    threshold: float = 0.3,
    include_scores: bool = False,
    show_progress: bool = False
) -> List[Dict[str, Any]]:
    """à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ sentiment à¹à¸šà¸š batch"""
    results = []
    
    if show_progress:
        try:
            from tqdm import tqdm
            iterator = tqdm(texts, desc="Analyzing sentiment")
        except ImportError:
            iterator = texts
    else:
        iterator = texts
    
    for text in iterator:
        result = analyze_detailed_sentiment(text, mode, threshold, include_scores)
        results.append(result)
    
    return results

def analyze_comment_sentiment(
    comment_data: Dict[str, Any],
    text_field: str = "text",
    mode: str = "single",
    threshold: float = 0.3
) -> Dict[str, Any]:
    """
    à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ sentiment à¸ªà¸³à¸«à¸£à¸±à¸š comment data
    à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ social media
    """
    if text_field not in comment_data:
        return comment_data
    
    text = comment_data[text_field]
    if not text or not text.strip():
        return comment_data
    
    # à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ sentiment
    sentiment_result = analyze_detailed_sentiment(text, mode, threshold, include_scores=True)
    
    # à¹€à¸à¸´à¹ˆà¸¡à¸œà¸¥à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹€à¸‚à¹‰à¸²à¹„à¸›à¹ƒà¸™ comment data
    enhanced_comment = comment_data.copy()
    enhanced_comment.update({
        "sentiment_analysis": sentiment_result,
        "sentiment": sentiment_result["sentiment"],  # à¹€à¸à¸·à¹ˆà¸­ backward compatibility
        "detailed_sentiment_enabled": True
    })
    
    return enhanced_comment

def analyze_social_media_batch(
    comments: List[Dict[str, Any]],
    text_field: str = "text",
    mode: str = "single",
    threshold: float = 0.3,
    show_progress: bool = True
) -> List[Dict[str, Any]]:
    """à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ sentiment à¸ªà¸³à¸«à¸£à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ social media à¹à¸šà¸š batch"""
    results = []
    
    if show_progress:
        try:
            from tqdm import tqdm
            iterator = tqdm(comments, desc="Analyzing social media sentiment")
        except ImportError:
            iterator = comments
    else:
        iterator = comments
    
    for comment in iterator:
        analyzed_comment = analyze_comment_sentiment(comment, text_field, mode, threshold)
        results.append(analyzed_comment)
    
    return results

def get_sentiment_statistics(
    analyzed_comments: List[Dict[str, Any]],
    detailed: bool = True
) -> Dict[str, Any]:
    """à¸„à¸³à¸™à¸§à¸“à¸ªà¸–à¸´à¸•à¸´à¸‚à¸­à¸‡ sentiment à¸ˆà¸²à¸à¸œà¸¥à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ"""
    if not analyzed_comments:
        return {}
    
    stats = {
        "total_comments": len(analyzed_comments),
        "sentiment_counts": {"positive": 0, "negative": 0, "neutral": 0},
        "analysis_mode": "unknown"
    }
    
    if detailed:
        stats["detailed_emotion_counts"] = {}
        stats["emotion_group_counts"] = {}
        stats["context_counts"] = {}
    
    for comment in analyzed_comments:
        sentiment_data = comment.get("sentiment_analysis", {})
        
        if not sentiment_data:
            continue
        
        # à¸™à¸±à¸š basic sentiment
        sentiment = sentiment_data.get("sentiment", "neutral")
        if sentiment in stats["sentiment_counts"]:
            stats["sentiment_counts"][sentiment] += 1
        
        # à¸à¸³à¸«à¸™à¸” analysis mode
        if "analysis_mode" in sentiment_data:
            stats["analysis_mode"] = sentiment_data["analysis_mode"]
        
        if detailed:
            # à¸™à¸±à¸š detailed emotions
            if sentiment_data.get("analysis_mode") == "single_label":
                emotion = sentiment_data.get("detailed_emotion")
                if emotion:
                    stats["detailed_emotion_counts"][emotion] = stats["detailed_emotion_counts"].get(emotion, 0) + 1
                
                group = sentiment_data.get("emotion_group")
                if group:
                    stats["emotion_group_counts"][group] = stats["emotion_group_counts"].get(group, 0) + 1
            
            elif sentiment_data.get("analysis_mode") == "multi_label":
                emotions = sentiment_data.get("detailed_emotions", [])
                for emotion in emotions:
                    stats["detailed_emotion_counts"][emotion] = stats["detailed_emotion_counts"].get(emotion, 0) + 1
                
                groups = sentiment_data.get("emotion_groups", [])
                for group in groups:
                    stats["emotion_group_counts"][group] = stats["emotion_group_counts"].get(group, 0) + 1
            
            # à¸™à¸±à¸š context (serialize dict à¹€à¸›à¹‡à¸™ string à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸Šà¹‰à¹€à¸›à¹‡à¸™ key)
            context = sentiment_data.get("context")
            if context:
                if isinstance(context, dict):
                    context_key = json.dumps(context, ensure_ascii=False, sort_keys=True)
                else:
                    context_key = str(context)
                stats["context_counts"][context_key] = stats["context_counts"].get(context_key, 0) + 1
    
    return stats

def export_detailed_sentiment_results(
    analyzed_comments: List[Dict[str, Any]],
    output_path: str,
    format: str = "jsonl",
    include_original: bool = True
) -> str:
    """à¸ªà¹ˆà¸‡à¸­à¸­à¸à¸œà¸¥à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ sentiment à¹à¸šà¸šà¸¥à¸°à¹€à¸­à¸µà¸¢à¸”"""
    
    # à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¹ˆà¸‡à¸­à¸­à¸
    export_data = []
    
    for comment in analyzed_comments:
        if include_original:
            export_item = comment.copy()
        else:
            # à¸ªà¹ˆà¸‡à¸­à¸­à¸à¹€à¸‰à¸à¸²à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ sentiment
            export_item = {
                "text": comment.get("text", ""),
                "sentiment_analysis": comment.get("sentiment_analysis", {})
            }
            
            # à¹€à¸à¸´à¹ˆà¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸·à¹‰à¸™à¸à¸²à¸™à¸–à¹‰à¸²à¸¡à¸µ
            for field in ["author", "timestamp", "platform", "comment_id"]:
                if field in comment:
                    export_item[field] = comment[field]
        
        export_data.append(export_item)
    
    # à¸šà¸±à¸™à¸—à¸¶à¸à¹„à¸Ÿà¸¥à¹Œ
    if format.lower() == "jsonl":
        with open(output_path, 'w', encoding='utf-8') as f:
            for item in export_data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    elif format.lower() == "json":
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
    
    else:
        raise ValueError(f"Unsupported format: {format}")
    
    return output_path

# === BACKWARD COMPATIBILITY ===

def enhanced_analyze_sentiment(text: str) -> Dict[str, Any]:
    """
    à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸š backward compatibility à¸à¸±à¸šà¸£à¸°à¸šà¸šà¹€à¸”à¸´à¸¡
    à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸›à¹‡à¸™à¹ƒà¸Šà¹‰ AI Model à¸ˆà¸£à¸´à¸‡ (detailed sentiment analyzer) à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
    à¹à¸•à¹ˆà¹€à¸à¸´à¹ˆà¸¡ fallback à¹„à¸›à¸¢à¸±à¸‡ builtin analysis à¸—à¸µà¹ˆà¸¡à¸µ sarcasm detection
    """
    try:
        # Try detailed analysis first
        result = analyze_detailed_sentiment(
            text,
            mode="single",
            threshold=0.3,
            include_scores=False
        )
        return {
            "text": text,
            "sentiment": result["sentiment"],
            "confidence": result["confidence"],
            "sentiment_score": _sentiment_to_score(result["sentiment"]),
            "detailed_emotion": result.get("detailed_emotion", result.get("label", "")),
            "emotion_group": result.get("emotion_group", result.get("group", "")),
            "context": result.get("context", {})
        }
    except Exception as e:
        # Fallback to builtin analysis with enhanced sarcasm detection
        try:
            from app import analyze_sentiment_builtin
            result = analyze_sentiment_builtin(text, mode='single')
            return {
                "text": text,
                "sentiment": result["sentiment"],
                "confidence": result["confidence"],
                "sentiment_score": result["sentiment_score"],
                "detailed_emotion": result.get("detailed_emotion", "à¹€à¸‰à¸¢ à¹†"),
                "emotion_group": result.get("emotion_group", "Neutral"),
                "context": result.get("context", {}),
                "fallback_used": True,
                "error": str(e)
            }
        except Exception as e2:
            # Final fallback
            return {
                "text": text,
                "sentiment": "neutral",
                "confidence": 0.0,
                "sentiment_score": 0.0,
                "detailed_emotion": "à¹€à¸‰à¸¢ à¹†",
                "emotion_group": "Neutral",
                "context": {},
                "error": str(e2)
            }

def _sentiment_to_score(sentiment: str) -> float:
    """à¹à¸›à¸¥à¸‡ sentiment à¹€à¸›à¹‡à¸™ score à¹€à¸à¸·à¹ˆà¸­ compatibility"""
    if sentiment == "positive":
        return 0.7
    elif sentiment == "negative":
        return -0.7
    else:
        return 0.0

# === DEMO FUNCTION ===

def demo_integration():
    """Demo à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ integration module"""
    print("ğŸ”— Detailed Thai Sentiment Integration Demo")
    print("=" * 50)
    
    # à¸—à¸”à¸ªà¸­à¸šà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸•à¹ˆà¸²à¸‡à¹†
    test_texts = [
        # Original examples
        "à¹‚à¸à¸£à¸˜à¸ˆà¸™à¸‚à¸³à¸­à¸°! à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¸¡à¸²à¹à¸šà¸šà¸™à¸µà¹‰à¸”à¹‰à¸§à¸¢ 555 ğŸ˜¡ğŸ˜‚",  # Mixed anger/laughter
        "à¸”à¸µà¹ƒà¸ˆà¸¡à¸²à¸à¹€à¸¥à¸¢ à¸£à¸±à¸à¹€à¸˜à¸­à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¹€à¸¥à¸¢ â¤ï¸ğŸ˜",  # Clear positive
        "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¹ˆà¸²à¸§à¸ªà¸²à¸£à¸›à¸£à¸°à¸ˆà¸³à¸§à¸±à¸™à¸„à¸£à¸±à¸š à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œà¸›à¸à¸•à¸´à¸”à¸µ",  # Neutral news
        "à¸­à¹ˆà¸­... à¹€à¸¢à¸µà¹ˆà¸¢à¸¡à¸ˆà¸£à¸´à¸‡à¹† à¹€à¸™à¸­à¸° à¸šà¸£à¸´à¸à¸²à¸£à¸”à¸µà¸¡à¸²à¸à¹€à¸¥à¸¢ ğŸ™„",  # Sarcastic positive
        "à¸•à¸­à¸™à¹à¸£à¸à¸à¹‡à¸„à¸´à¸”à¸§à¹ˆà¸²à¸”à¸µà¸™à¸° à¹à¸•à¹ˆà¸à¸­à¹ƒà¸Šà¹‰à¹„à¸›à¹ƒà¸Šà¹‰à¸¡à¸²à¸„à¸·à¸­à¹à¸šà¸š... à¹„à¸¡à¹ˆà¹„à¸«à¸§à¸­à¸° à¸«à¹ˆà¸§à¸¢à¹à¸•à¸à¸ªà¸´à¹‰à¸™à¸”à¸µ",  # Negative with progression
        
        # New challenging additions from user feedback
        "à¸‡à¸²à¸™à¸™à¸µà¹‰à¸ªà¸¸à¸”à¸¢à¸­à¸”à¸„à¸£à¸±à¸š... à¸–à¹‰à¸²à¸Šà¸­à¸šà¸„à¸§à¸²à¸¡à¸¥à¹‰à¸¡à¹€à¸«à¸¥à¸§",  # Ironic praise
        "à¸›à¸£à¸°à¹€à¸—à¸¨à¹„à¸—à¸¢à¸ˆà¸°à¹„à¸¡à¹ˆà¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡... à¹à¸¢à¹ˆà¸¥à¸‡à¸—à¸¸à¸à¸§à¸±à¸™",  # Negative with political nuance
        "à¸‚à¸­à¸šà¸„à¸¸à¸“à¸™à¸°à¸„à¸°à¸—à¸µà¹ˆà¸—à¸³à¹ƒà¸«à¹‰à¸§à¸±à¸™à¸™à¸µà¹‰à¹€à¸›à¹‡à¸™à¸§à¸±à¸™à¸—à¸µà¹ˆà¹à¸¢à¹ˆà¸—à¸µà¹ˆà¸ªà¸¸à¸”à¹ƒà¸™à¸Šà¸µà¸§à¸´à¸• ğŸ˜Š",  # Positive words, negative meaning
        "à¸„à¸´à¸”à¸–à¸¶à¸‡à¸ªà¸¡à¸±à¸¢à¸à¹ˆà¸­à¸™à¸ˆà¸±à¸‡... à¹€à¸¡à¸·à¹ˆà¸­à¸›à¸£à¸°à¹€à¸—à¸¨à¸¢à¸±à¸‡à¸¡à¸µà¸­à¸™à¸²à¸„à¸•",  # Nostalgic + political critique
        "à¸šà¸£à¸´à¸à¸²à¸£à¸£à¸°à¸”à¸±à¸šà¸«à¹‰à¸²à¸”à¸²à¸§... à¹ƒà¸™à¹‚à¸¥à¸à¸„à¸¹à¹ˆà¸‚à¸™à¸²à¸™",  # Sarcastic comparison
        "à¸—à¸³à¸”à¸µà¹à¸¥à¹‰à¸§à¸„à¸£à¸±à¸š... à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸™à¸—à¸µà¹ˆà¸¡à¸²à¸•à¸£à¸à¸²à¸™à¸•à¹ˆà¸³à¸¡à¸²à¸",  # Backhanded compliment
        "à¸ à¸¹à¸¡à¸´à¹ƒà¸ˆà¹ƒà¸™à¸•à¸±à¸§à¸„à¸¸à¸“... à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¸•à¹‰à¸™à¹€à¸«à¸•à¸¸à¸‚à¸­à¸‡à¸›à¸±à¸à¸«à¸²à¸—à¸¸à¸à¸­à¸¢à¹ˆà¸²à¸‡",  # False praise
        "à¸­à¸™à¸²à¸„à¸•à¸ªà¸”à¹ƒà¸ªà¹à¸™à¹ˆà¸™à¸­à¸™... à¸–à¹‰à¸²à¸¢à¸±à¸‡à¸—à¸³à¹à¸šà¸šà¸™à¸µà¹‰à¸•à¹ˆà¸­à¹„à¸›",  # Negative prediction disguised as positive
        "à¸™à¹‚à¸¢à¸šà¸²à¸¢à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸£à¸£à¸„à¹Œà¸¡à¸²à¸... à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸™à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸­à¸¢à¸²à¸à¹ƒà¸«à¹‰à¸›à¸£à¸°à¹€à¸—à¸¨à¸à¸±à¸’à¸™à¸²",  # Political sarcasm
        "à¸ªà¸¸à¸”à¸¢à¸­à¸”à¸›à¸£à¸°à¸ªà¸šà¸à¸²à¸£à¸“à¹Œ... à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸­à¸¢à¸²à¸à¹ƒà¸«à¹‰à¹ƒà¸„à¸£à¹€à¸ˆà¸­",  # Ironic experience
        "à¸”à¸µà¹ƒà¸ˆà¸”à¹‰à¸§à¸¢à¸™à¸°... à¸—à¸µà¹ˆà¹„à¸”à¹‰à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸«à¸™à¸¶à¹ˆà¸‡à¸‚à¸­à¸‡à¸„à¸§à¸²à¸¡à¸¥à¹‰à¸¡à¹€à¸«à¸¥à¸§à¸™à¸µà¹‰",  # Mocking congratulations
        "à¹€à¸à¹ˆà¸‡à¸¡à¸²à¸... à¹€à¸à¹ˆà¸‡à¸ˆà¸™à¸—à¸³à¹ƒà¸«à¹‰à¹à¸¢à¹ˆà¸¥à¸‡",  # Paradoxical compliment
        "à¸™à¹ˆà¸²à¸›à¸£à¸°à¸—à¸±à¸šà¹ƒà¸ˆà¸ˆà¸£à¸´à¸‡à¹†... à¹ƒà¸™à¸„à¸§à¸²à¸¡à¹„à¸£à¹‰à¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–",  # Admiring incompetence
        "à¸‚à¸­à¸Šà¸·à¹ˆà¸™à¸Šà¸¡... à¸„à¸§à¸²à¸¡à¸à¸¢à¸²à¸¢à¸²à¸¡à¸—à¸µà¹ˆà¸ˆà¸°à¸—à¸³à¹ƒà¸«à¹‰à¸¥à¹‰à¸¡à¹€à¸«à¸¥à¸§",  # Praising failure
        "à¸”à¸µà¸à¸§à¹ˆà¸²à¹€à¸à¸·à¹ˆà¸­à¸™... à¸–à¹‰à¸²à¹€à¸à¸·à¹ˆà¸­à¸™à¸„à¸™à¸™à¸±à¹‰à¸™à¹à¸¢à¹ˆà¸ªà¸¸à¸”à¹†",  # Relative negativity
        "à¹„à¸¡à¹ˆà¸™à¹ˆà¸²à¹€à¸Šà¸·à¹ˆà¸­à¸§à¹ˆà¸²à¸—à¸³à¹„à¸”à¹‰... à¹à¸¢à¹ˆà¸‚à¸™à¸²à¸”à¸™à¸µà¹‰",  # Surprised disappointment
        "à¸à¸±à¸’à¸™à¸²à¸à¸²à¸£à¸—à¸µà¹ˆà¸”à¸µ... à¹ƒà¸™à¸à¸²à¸£à¹€à¸”à¸´à¸™à¸–à¸­à¸¢à¸«à¸¥à¸±à¸‡",  # Ironic progress

        # Sarcasm focused on "Praise -> Insult" structure
        "à¹€à¸›à¹‡à¸™à¸„à¸§à¸²à¸¡à¸„à¸´à¸”à¸—à¸µà¹ˆà¸”à¸µà¸¡à¸²à¸... à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸™à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸„à¸´à¸”à¸­à¸°à¹„à¸£à¹€à¸¥à¸¢", # Sarcastic praise
        "à¸Šà¸¸à¸”à¸™à¸µà¹‰à¸ªà¸§à¸¢à¸ˆà¸±à¸‡... à¸–à¹‰à¸²à¸ˆà¸°à¹„à¸›à¸‡à¸²à¸™à¹à¸Ÿà¸™à¸‹à¸µ", # Backhanded compliment on appearance
        "à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸à¸£à¸²à¸°à¸¡à¸²à¸... à¸ˆà¸™à¸­à¸¢à¸²à¸à¸›à¸´à¸”à¸«à¸¹", # Ironic compliment on sound
        "à¹€à¸‚à¸µà¸¢à¸™à¸”à¸µà¸™à¸°... à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸™à¸±à¸šà¸§à¹ˆà¸²à¸­à¹ˆà¸²à¸™à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¹€à¸£à¸·à¹ˆà¸­à¸‡", # Sarcastic feedback on writing
        "à¸‰à¸¥à¸²à¸”à¹€à¸›à¹‡à¸™à¸à¸£à¸”... à¹à¸•à¹ˆà¸à¸±à¸”à¸à¸£à¹ˆà¸­à¸™à¸—à¸¸à¸à¸­à¸¢à¹ˆà¸²à¸‡", # Compliment with a destructive consequence

        # Sarcasm/Irony with English
        "The service is 'amazing'. Waited 20 minutes for a glass of water.",
        "Oh, great. Another meeting. Just what I needed.",
        "I love it when my code breaks for no reason. So fun.",
        "This is just perfect. I lost my keys.",

        # New Use Cases for Comprehensive Testing
        # -----------------------------------------

        # 1. Double Negatives (should be neutral or slightly positive)
        "à¸à¹‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹„à¸¡à¹ˆà¸Šà¸­à¸šà¸™à¸° à¸à¹‡à¹‚à¸­à¹€à¸„",
        "à¸–à¸²à¸¡à¸§à¹ˆà¸²à¹€à¸à¸¥à¸µà¸¢à¸”à¹„à¸«à¸¡ à¸à¹‡à¹„à¸¡à¹ˆà¸™à¸° à¹à¸•à¹ˆà¸à¹‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸Šà¸­à¸š",

        # 2. Reported Speech (sentiment should be from the speaker)
        "à¹€à¸à¸·à¹ˆà¸­à¸™à¸šà¸­à¸à¸§à¹ˆà¸²à¸«à¸™à¸±à¸‡à¸ªà¸™à¸¸à¸à¸¡à¸²à¸ à¹à¸•à¹ˆà¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§à¹€à¸£à¸²à¹€à¸‰à¸¢à¹† à¸­à¸°",
        "à¹ƒà¸„à¸£à¹† à¸à¹‡à¸Šà¸¡à¸§à¹ˆà¸²à¸ªà¸§à¸¢ à¹à¸•à¹ˆà¹€à¸£à¸²à¸§à¹ˆà¸²à¸¡à¸±à¸™à¸”à¸¹à¸˜à¸£à¸£à¸¡à¸”à¸²à¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢",
        "à¹€à¸«à¹‡à¸™à¸£à¸µà¸§à¸´à¸§à¸šà¸­à¸à¸§à¹ˆà¸²à¸£à¹‰à¸²à¸™à¸™à¸µà¹‰à¹€à¸”à¹‡à¸”à¸¡à¸²à¸ à¸à¸­à¸¥à¸­à¸‡à¹à¸¥à¹‰à¸§à¸à¹‡à¸‡à¸±à¹‰à¸™à¹†",

        # 3. Rhetorical Questions (often imply strong sentiment)
        "à¸—à¸³à¸à¸±à¸™à¹„à¸”à¹‰à¸¥à¸‡à¸„à¸­à¹€à¸™à¸­à¸°?", # Negative
        "à¹à¸¥à¹‰à¸§à¹ƒà¸„à¸£à¸ˆà¸°à¹„à¸›à¸—à¸™à¸à¸±à¸šà¹€à¸£à¸·à¹ˆà¸­à¸‡à¹à¸šà¸šà¸™à¸µà¹‰à¹„à¸”à¹‰!?", # Negative
        "à¸ªà¸§à¸¢à¸‚à¸™à¸²à¸”à¸™à¸µà¹‰ à¹„à¸¡à¹ˆà¹ƒà¸«à¹‰à¸Šà¸­à¸šà¹„à¸”à¹‰à¹„à¸‡", # Positive

        # 4. Balanced Mixed Opinions (not sarcastic)
        "à¸­à¸²à¸«à¸²à¸£à¸­à¸£à¹ˆà¸­à¸¢à¸™à¸° à¹à¸•à¹ˆà¸šà¸£à¸´à¸à¸²à¸£à¸Šà¹‰à¸²à¹„à¸›à¸™à¸´à¸”à¸™à¸¶à¸‡ à¹‚à¸”à¸¢à¸£à¸§à¸¡à¸à¹‡à¹‚à¸­à¹€à¸„",
        "à¸§à¸´à¸§à¸ªà¸§à¸¢à¸¡à¸²à¸ à¹à¸•à¹ˆà¸—à¸²à¸‡à¸‚à¸¶à¹‰à¸™à¸¥à¸³à¸šà¸²à¸à¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢",
        "à¸Šà¸­à¸šà¸”à¸µà¹„à¸‹à¸™à¹Œà¸™à¸° à¹à¸•à¹ˆà¸•à¸´à¸”à¸—à¸µà¹ˆà¸£à¸²à¸„à¸²à¹à¸£à¸‡à¹„à¸›à¸™à¸´à¸”",

        # 5. Imperative Sentences (Commands/Requests - usually neutral)
        "à¸Šà¹ˆà¸§à¸¢à¸ªà¹ˆà¸‡à¹€à¸­à¸à¸ªà¸²à¸£à¹ƒà¸«à¹‰à¸”à¹‰à¸§à¸¢à¸„à¹ˆà¸°",
        "à¸£à¸šà¸à¸§à¸™à¸Šà¹ˆà¸§à¸¢à¹€à¸‡à¸µà¸¢à¸šà¹† à¸«à¸™à¹ˆà¸­à¸¢à¸„à¸£à¸±à¸š",
        "à¸­à¸¢à¹ˆà¸²à¸¥à¸·à¸¡à¸›à¸´à¸”à¹„à¸Ÿà¸™à¸°",

        # 6. Informal/Misspelled words
        "à¸ˆà¸´à¸‡à¹† à¸à¹‰à¸­à¸”à¸µà¸™à¸° à¸Šà¸­à¸šà¸¡à¸±à¹ˆà¸à¹†", # à¸ˆà¸£à¸´à¸‡à¹† à¸à¹‡à¸”à¸µà¸™à¸° à¸Šà¸­à¸šà¸¡à¸²à¸à¹† (Positive)
        "à¸—à¸±à¸¡à¸¡à¸±à¸¢à¸—à¸³à¹à¸šà¸šà¸™à¸µà¹‰", # à¸—à¸³à¹„à¸¡à¸—à¸³à¹à¸šà¸šà¸™à¸µà¹‰ (Negative/Question)
    ]
    
    print("\nğŸ“ Single Label Analysis:")
    for text in test_texts:
        result = analyze_detailed_sentiment(text, mode="single", include_scores=True)
        print(f"à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡: {text}")
        print(f"Basic: {result['sentiment']} | Detailed: {result['detailed_emotion']} ({result['emotion_group']})")
        print(f"Confidence: {result['confidence']} | Context: {result['context']}")
        print()
    
    print("\nğŸ“ Multi Label Analysis:")
    for text in test_texts:
        result = analyze_detailed_sentiment(text, mode="multi", threshold=0.25, include_scores=True)
        print(f"à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡: {text}")
        print(f"Basic: {result['sentiment']} | Detailed: {result['detailed_emotions']} ({result['emotion_groups']})")
        print(f"Primary: {result['primary_emotion']} | Context: {result['context']}")
        print()
    
    # à¸—à¸”à¸ªà¸­à¸š social media batch
    print("\nğŸ“± Social Media Batch Analysis:")
    sample_comments = [
        {"text": test_texts[0], "author": "user1", "platform": "facebook"},
        {"text": test_texts[1], "author": "user2", "platform": "twitter"},
        {"text": test_texts[2], "author": "user3", "platform": "youtube"},
        {"text": test_texts[3], "author": "user4", "platform": "pantip"}
    ]
    
    analyzed = analyze_social_media_batch(sample_comments, mode="multi", threshold=0.25, show_progress=False)
    
    for comment in analyzed:
        print(f"Platform: {comment['platform']}")
        print(f"Text: {comment['text']}")
        sentiment_data = comment['sentiment_analysis']
        print(f"Result: {sentiment_data['sentiment']} -> {sentiment_data['detailed_emotions']}")
        print()
    
    # à¹à¸ªà¸”à¸‡à¸ªà¸–à¸´à¸•à¸´
    stats = get_sentiment_statistics(analyzed, detailed=True)
    print("ğŸ“Š Statistics:")
    print(f"Total: {stats['total_comments']}")
    print(f"Basic sentiment: {stats['sentiment_counts']}")
    print(f"Detailed emotions: {stats['detailed_emotion_counts']}")
    print(f"Emotion groups: {stats['emotion_group_counts']}")
    print(f"Contexts: {stats['context_counts']}")

if __name__ == "__main__":
    demo_integration()
