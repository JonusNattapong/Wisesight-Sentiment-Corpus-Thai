#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test suite for Detailed Thai Sentiment Analysis System
à¸Šà¸¸à¸”à¸—à¸”à¸ªà¸­à¸šà¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸°à¸šà¸š sentiment analysis à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¹à¸šà¸šà¸¥à¸°à¹€à¸­à¸µà¸¢à¸”
"""

import json
import os
import sys
from typing import List, Dict, Any

# Add current directory to path for imports
sys.path.append(os.path.dirname(__file__))

try:
    from detailed_thai_sentiment import (
        DetailedThaiSentimentAnalyzer,
        EMOTION_LABELS,
        EMOTION_GROUPS,
        create_training_data_format,
        save_training_data
    )
    DETAILED_AVAILABLE = True
except ImportError as e:
    print(f"âŒ Error importing detailed_thai_sentiment: {e}")
    DETAILED_AVAILABLE = False

try:
    from sentiment_integration import (
        analyze_detailed_sentiment,
        analyze_social_media_batch,
        get_sentiment_statistics,
        enhanced_analyze_sentiment
    )
    INTEGRATION_AVAILABLE = True
except ImportError as e:
    print(f"âŒ Error importing sentiment_integration: {e}")
    INTEGRATION_AVAILABLE = False

class DetailedSentimentTester:
    """à¸•à¸±à¸§à¸—à¸”à¸ªà¸­à¸šà¸£à¸°à¸šà¸š sentiment analysis à¹à¸šà¸šà¸¥à¸°à¹€à¸­à¸µà¸¢à¸”"""
    
    def __init__(self):
        self.test_cases = self._create_test_cases()
        self.analyzer = None
        if DETAILED_AVAILABLE:
            self.analyzer = DetailedThaiSentimentAnalyzer()
    
    def _create_test_cases(self) -> List[Dict[str, Any]]:
        """à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸”à¸ªà¸­à¸š"""
        return [
            # === POSITIVE EMOTIONS ===
            {
                "text": "à¸”à¸µà¹ƒà¸ˆà¸¡à¸²à¸à¹€à¸¥à¸¢! à¸£à¸±à¸à¸¡à¸²à¸ â¤ï¸ğŸ˜",
                "expected_single": "à¸”à¸µà¹ƒà¸ˆ",
                "expected_multi": ["à¸”à¸µà¹ƒà¸ˆ", "à¸£à¸±à¸"],
                "expected_group": "Positive",
                "expected_sentiment": "positive"
            },
            {
                "text": "à¸‹à¸¶à¹‰à¸‡à¹ƒà¸ˆà¸¡à¸²à¸à¹€à¸¥à¸¢ à¸™à¹‰à¸³à¸•à¸²à¸‹à¸¶à¸¡ à¸›à¸£à¸°à¸—à¸±à¸šà¹ƒà¸ˆà¸ˆà¸£à¸´à¸‡à¹† ğŸ˜­ğŸ’",
                "expected_single": "à¸‹à¸¶à¹‰à¸‡à¹ƒà¸ˆ",
                "expected_multi": ["à¸‹à¸¶à¹‰à¸‡à¹ƒà¸ˆ"],
                "expected_group": "Positive",
                "expected_sentiment": "positive"
            },
            {
                "text": "à¹‚à¸­à¹€à¸„ à¹ƒà¸Šà¹‰à¹„à¸”à¹‰ à¸›à¸à¸•à¸´à¸”à¸µ à¸à¸­à¹ƒà¸ˆ",
                "expected_single": "à¸à¸­à¹ƒà¸ˆ",
                "expected_multi": ["à¸à¸­à¹ƒà¸ˆ"],
                "expected_group": "Positive",
                "expected_sentiment": "positive"
            },
            
            # === NEGATIVE EMOTIONS ===
            {
                "text": "à¹‚à¸à¸£à¸˜à¸¡à¸²à¸à¹€à¸¥à¸¢! à¸«à¹ˆà¸§à¸¢à¹à¸•à¸à¹à¸¥à¹‰à¸§à¸ˆà¸£à¸´à¸‡à¹† ğŸ˜¡ğŸ¤¬",
                "expected_single": "à¹‚à¸à¸£à¸˜",
                "expected_multi": ["à¹‚à¸à¸£à¸˜"],
                "expected_group": "Negative",
                "expected_sentiment": "negative"
            },
            {
                "text": "à¹€à¸¨à¸£à¹‰à¸²à¹ƒà¸ˆà¸¡à¸²à¸ à¹€à¸ªà¸µà¸¢à¹ƒà¸ˆà¸ˆà¸£à¸´à¸‡à¹† à¸œà¸´à¸”à¸«à¸§à¸±à¸‡à¸¡à¸²à¸ ğŸ˜¢ğŸ’”",
                "expected_single": "à¹€à¸ªà¸µà¸¢à¹ƒà¸ˆ",
                "expected_multi": ["à¹€à¸ªà¸µà¸¢à¹ƒà¸ˆ", "à¸œà¸´à¸”à¸«à¸§à¸±à¸‡"],
                "expected_group": "Negative",
                "expected_sentiment": "negative"
            },
            {
                "text": "à¸à¸¥à¸±à¸§à¸¡à¸²à¸à¹€à¸¥à¸¢ à¸•à¸à¹ƒà¸ˆà¸ˆà¸£à¸´à¸‡à¹† à¸«à¸§à¸²à¸”à¹€à¸ªà¸µà¸¢à¸§ ğŸ˜±ğŸ˜¨",
                "expected_single": "à¸à¸¥à¸±à¸§",
                "expected_multi": ["à¸à¸¥à¸±à¸§", "à¸•à¸à¹ƒà¸ˆ"],
                "expected_group": "Negative",
                "expected_sentiment": "negative"
            },
            
            # === NEUTRAL EMOTIONS ===
            {
                "text": "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¹ˆà¸²à¸§à¸ªà¸²à¸£à¸›à¸£à¸°à¸ˆà¸³à¸§à¸±à¸™ à¸ªà¸–à¸²à¸™à¸à¸²à¸£à¸“à¹Œà¸›à¸à¸•à¸´à¸”à¸µ",
                "expected_single": "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¹ˆà¸²à¸§à¸ªà¸²à¸£",
                "expected_multi": ["à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¹ˆà¸²à¸§à¸ªà¸²à¸£"],
                "expected_group": "Neutral",
                "expected_sentiment": "neutral"
            },
            {
                "text": "à¹€à¸‰à¸¢à¹† à¸˜à¸£à¸£à¸¡à¸”à¸² à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸ªà¸¶à¸à¸­à¸°à¹„à¸£",
                "expected_single": "à¹€à¸‰à¸¢ à¹†",
                "expected_multi": ["à¹€à¸‰à¸¢ à¹†"],
                "expected_group": "Neutral",
                "expected_sentiment": "neutral"
            },
            
            # === OTHERS (COMPLEX EMOTIONS) ===
            {
                "text": "à¸­à¹ˆà¸­... à¸”à¸µà¸ˆà¸£à¸´à¸‡à¹† à¹€à¸™à¸­à¸° à¸šà¸£à¸´à¸à¸²à¸£à¹€à¸¢à¸µà¹ˆà¸¢à¸¡à¸¡à¸²à¸ ğŸ™„",
                "expected_single": "à¸›à¸£à¸°à¸Šà¸”",
                "expected_multi": ["à¸›à¸£à¸°à¸Šà¸”"],
                "expected_group": "Others",
                "expected_sentiment": "negative"
            },
            {
                "text": "à¸‚à¸³à¸¡à¸²à¸à¹€à¸¥à¸¢! à¸•à¸¥à¸à¸”à¸µ 555 ğŸ˜‚ğŸ¤£",
                "expected_single": "à¸‚à¸³à¸‚à¸±à¸™",
                "expected_multi": ["à¸‚à¸³à¸‚à¸±à¸™"],
                "expected_group": "Others",
                "expected_sentiment": "positive"
            },
            {
                "text": "à¸ªà¸±à¸šà¸ªà¸™à¸¡à¸²à¸ à¸‡à¸‡à¹€à¸¥à¸¢ à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¹„à¸¡à¹ˆà¹„à¸”à¹‰ ğŸ¤”ğŸ˜µâ€ğŸ’«",
                "expected_single": "à¸ªà¸±à¸šà¸ªà¸™",
                "expected_multi": ["à¸ªà¸±à¸šà¸ªà¸™"],
                "expected_group": "Others",
                "expected_sentiment": "neutral"
            },
            
            # === MIXED EMOTIONS ===
            {
                "text": "à¹‚à¸à¸£à¸˜à¸ˆà¸™à¸‚à¸³à¸­à¸°! à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¸¡à¸²à¹à¸šà¸šà¸™à¸µà¹‰à¸”à¹‰à¸§à¸¢ 555 ğŸ˜¡ğŸ˜‚",
                "expected_single": "à¹‚à¸à¸£à¸˜",  # Primary emotion
                "expected_multi": ["à¹‚à¸à¸£à¸˜", "à¸‚à¸³à¸‚à¸±à¸™"],
                "expected_group": "Negative",  # Primary group
                "expected_sentiment": "negative"
            },
            {
                "text": "à¸›à¸£à¸°à¸Šà¸”à¹€à¸à¹ˆà¸‡à¸¡à¸²à¸ à¹€à¸ªà¸µà¸¢à¸”à¸ªà¸µà¸ˆà¸™à¹€à¸¨à¸£à¹‰à¸² à¹ƒà¸ˆà¸£à¹‰à¸²à¸¢",
                "expected_single": "à¸›à¸£à¸°à¸Šà¸”",
                "expected_multi": ["à¸›à¸£à¸°à¸Šà¸”", "à¹€à¸ªà¸µà¸¢à¹ƒà¸ˆ"],
                "expected_group": "Others",
                "expected_sentiment": "negative"
            },
            {
                "text": "à¸Šà¸­à¸šà¸¡à¸²à¸ à¹à¸•à¹ˆà¸à¹‡à¸œà¸´à¸”à¸«à¸§à¸±à¸‡à¸™à¸´à¸”à¸«à¸™à¹ˆà¸­à¸¢ à¹€à¸­à¸²à¹à¸•à¹ˆà¹ƒà¸ˆ",
                "expected_single": "à¸Šà¸­à¸š",
                "expected_multi": ["à¸Šà¸­à¸š", "à¸œà¸´à¸”à¸«à¸§à¸±à¸‡"],
                "expected_group": "Positive",
                "expected_sentiment": "positive"
            }
        ]
    
    def test_basic_functionality(self) -> Dict[str, Any]:
        """à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸à¸·à¹‰à¸™à¸à¸²à¸™"""
        print("ğŸ§ª Testing Basic Functionality...")
        
        if not DETAILED_AVAILABLE:
            return {"status": "failed", "error": "Detailed sentiment analysis not available"}
        
        results = {
            "total_tests": len(self.test_cases),
            "single_label_accuracy": 0,
            "multi_label_accuracy": 0,
            "sentiment_mapping_accuracy": 0,
            "failed_cases": [],
            "detailed_results": []
        }
        
        single_correct = 0
        multi_correct = 0
        sentiment_correct = 0
        
        for i, test_case in enumerate(self.test_cases):
            text = test_case["text"]
            
            try:
                # Test single label
                single_result = self.analyzer.analyze_single_label(text)
                single_predicted = single_result["label"]
                single_expected = test_case["expected_single"]
                single_match = single_predicted == single_expected
                
                if single_match:
                    single_correct += 1
                
                # Test multi label
                multi_result = self.analyzer.analyze_multi_label(text, threshold=0.25)
                multi_predicted = set(multi_result["labels"])
                multi_expected = set(test_case["expected_multi"])
                # Check if predicted contains at least one expected emotion
                multi_match = len(multi_predicted.intersection(multi_expected)) > 0
                
                if multi_match:
                    multi_correct += 1
                
                # Test sentiment mapping
                mapped_sentiment = self._map_emotion_to_sentiment(single_predicted)
                expected_sentiment = test_case["expected_sentiment"]
                sentiment_match = mapped_sentiment == expected_sentiment
                
                if sentiment_match:
                    sentiment_correct += 1
                
                # Store detailed result
                test_result = {
                    "case_id": i + 1,
                    "text": text,
                    "single_predicted": single_predicted,
                    "single_expected": single_expected,
                    "single_match": single_match,
                    "multi_predicted": list(multi_predicted),
                    "multi_expected": list(multi_expected),
                    "multi_match": multi_match,
                    "sentiment_predicted": mapped_sentiment,
                    "sentiment_expected": expected_sentiment,
                    "sentiment_match": sentiment_match,
                    "confidence": single_result["confidence"]
                }
                
                results["detailed_results"].append(test_result)
                
                if not (single_match and multi_match and sentiment_match):
                    results["failed_cases"].append(test_result)
            
            except Exception as e:
                error_result = {
                    "case_id": i + 1,
                    "text": text,
                    "error": str(e)
                }
                results["failed_cases"].append(error_result)
        
        # Calculate accuracies
        total = len(self.test_cases)
        results["single_label_accuracy"] = (single_correct / total) * 100
        results["multi_label_accuracy"] = (multi_correct / total) * 100
        results["sentiment_mapping_accuracy"] = (sentiment_correct / total) * 100
        
        return results
    
    def test_integration_module(self) -> Dict[str, Any]:
        """à¸—à¸”à¸ªà¸­à¸š integration module"""
        print("ğŸ”— Testing Integration Module...")
        
        if not INTEGRATION_AVAILABLE:
            return {"status": "failed", "error": "Integration module not available"}
        
        results = {
            "tests_passed": 0,
            "tests_failed": 0,
            "errors": []
        }
        
        test_texts = [
            "à¸”à¸µà¹ƒà¸ˆà¸¡à¸²à¸à¹€à¸¥à¸¢! à¸£à¸±à¸à¸¡à¸²à¸",
            "à¹‚à¸à¸£à¸˜à¸ˆà¸™à¸‚à¸³à¸­à¸°! à¹à¸›à¸¥à¸à¸”à¸µ 555",
            "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¹ˆà¸²à¸§à¸ªà¸²à¸£à¸›à¸£à¸°à¸ˆà¸³à¸§à¸±à¸™"
        ]
        
        try:
            # Test single analysis
            for text in test_texts:
                result = analyze_detailed_sentiment(text, mode="single")
                assert "sentiment" in result
                assert "detailed_emotion" in result
                assert "confidence" in result
                results["tests_passed"] += 1
            
            # Test multi analysis
            for text in test_texts:
                result = analyze_detailed_sentiment(text, mode="multi", threshold=0.3)
                assert "sentiment" in result
                assert "detailed_emotions" in result
                assert isinstance(result["detailed_emotions"], list)
                results["tests_passed"] += 1
            
            # Test batch analysis
            sample_comments = [
                {"text": text, "author": f"user{i}", "platform": "test"}
                for i, text in enumerate(test_texts)
            ]
            
            analyzed = analyze_social_media_batch(sample_comments, mode="single", show_progress=False)
            assert len(analyzed) == len(sample_comments)
            for comment in analyzed:
                assert "sentiment_analysis" in comment
            results["tests_passed"] += 1
            
            # Test statistics
            stats = get_sentiment_statistics(analyzed)
            assert "total_comments" in stats
            assert "sentiment_counts" in stats
            results["tests_passed"] += 1
            
        except Exception as e:
            results["tests_failed"] += 1
            results["errors"].append(str(e))
        
        return results
    
    def test_training_data_creation(self) -> Dict[str, Any]:
        """à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ training"""
        print("ğŸ“ Testing Training Data Creation...")
        
        if not DETAILED_AVAILABLE:
            return {"status": "failed", "error": "Detailed sentiment analysis not available"}
        
        results = {
            "tests_passed": 0,
            "tests_failed": 0,
            "errors": []
        }
        
        try:
            # Test single label format
            single_format = create_training_data_format("à¸”à¸µà¹ƒà¸ˆà¸¡à¸²à¸", "à¸”à¸µà¹ƒà¸ˆ", "classification")
            assert "text" in single_format
            assert "label" in single_format
            assert "label_id" in single_format
            results["tests_passed"] += 1
            
            # Test multi label format
            multi_format = create_training_data_format("à¹‚à¸à¸£à¸˜à¸ˆà¸™à¸‚à¸³", ["à¹‚à¸à¸£à¸˜", "à¸‚à¸³à¸‚à¸±à¸™"], "classification")
            assert "text" in multi_format
            assert "labels" in multi_format
            assert "label_vector" in multi_format
            assert len(multi_format["label_vector"]) == len(EMOTION_LABELS)
            results["tests_passed"] += 1
            
            # Test instruction format
            instruction_format = create_training_data_format("à¸›à¸£à¸°à¸Šà¸”à¹€à¸à¹ˆà¸‡", "à¸›à¸£à¸°à¸Šà¸”", "instruction")
            assert "instruction" in instruction_format
            assert "input" in instruction_format
            assert "output" in instruction_format
            results["tests_passed"] += 1
            
            # Test saving data
            test_data = [single_format, multi_format, instruction_format]
            output_path = "test_training_data.jsonl"
            save_training_data(test_data, output_path, "jsonl")
            
            # Check if file exists
            if os.path.exists(output_path):
                results["tests_passed"] += 1
                # Clean up
                os.remove(output_path)
            else:
                results["tests_failed"] += 1
                results["errors"].append("Training data file not created")
            
        except Exception as e:
            results["tests_failed"] += 1
            results["errors"].append(str(e))
        
        return results
    
    def test_edge_cases(self) -> Dict[str, Any]:
        """à¸—à¸”à¸ªà¸­à¸šà¸à¸£à¸“à¸µà¸à¸´à¹€à¸¨à¸©"""
        print("ğŸ­ Testing Edge Cases...")
        
        if not DETAILED_AVAILABLE:
            return {"status": "failed", "error": "Detailed sentiment analysis not available"}
        
        results = {
            "tests_passed": 0,
            "tests_failed": 0,
            "errors": []
        }
        
        edge_cases = [
            "",  # Empty string
            "   ",  # Whitespace only
            "a",  # Single character
            "ğŸ˜Š",  # Emoji only
            "Hello world",  # English text
            "123456",  # Numbers only
            "!@#$%^&*()",  # Special characters only
            "à¹„à¸—à¸¢" * 100,  # Very long text
            "à¹‚à¸à¸£à¸˜" + " " * 100 + "à¸‚à¸³",  # Text with lots of spaces
        ]
        
        for text in edge_cases:
            try:
                # Test single label (should not crash)
                single_result = self.analyzer.analyze_single_label(text)
                assert "label" in single_result
                assert "confidence" in single_result
                
                # Test multi label (should not crash)
                multi_result = self.analyzer.analyze_multi_label(text)
                assert "labels" in multi_result
                assert isinstance(multi_result["labels"], list)
                
                results["tests_passed"] += 1
                
            except Exception as e:
                results["tests_failed"] += 1
                results["errors"].append(f"Failed on '{text[:20]}...': {str(e)}")
        
        return results
    
    def _map_emotion_to_sentiment(self, emotion: str) -> str:
        """Helper: à¹à¸›à¸¥à¸‡à¸­à¸²à¸£à¸¡à¸“à¹Œà¹€à¸›à¹‡à¸™ sentiment à¸à¸·à¹‰à¸™à¸à¸²à¸™"""
        for group, emotions in EMOTION_GROUPS.items():
            if emotion in emotions:
                if group == "Positive":
                    return "positive"
                elif group == "Negative":
                    return "negative"
                elif group == "Neutral":
                    return "neutral"
                elif group == "Others":
                    if emotion in ["à¸‚à¸³à¸‚à¸±à¸™"]:
                        return "positive"
                    elif emotion in ["à¸›à¸£à¸°à¸Šà¸”", "à¹€à¸ªà¸µà¸¢à¸”à¸ªà¸µ"]:
                        return "negative"
                    else:
                        return "neutral"
        return "neutral"
    
    def run_all_tests(self) -> Dict[str, Any]:
        """à¸£à¸±à¸™à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸šà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”"""
        print("ğŸ§ª Running Complete Test Suite for Detailed Thai Sentiment Analysis")
        print("=" * 80)
        
        all_results = {
            "system_info": {
                "detailed_available": DETAILED_AVAILABLE,
                "integration_available": INTEGRATION_AVAILABLE,
                "emotion_labels_count": len(EMOTION_LABELS) if DETAILED_AVAILABLE else 0,
                "emotion_groups_count": len(EMOTION_GROUPS) if DETAILED_AVAILABLE else 0
            },
            "tests": {}
        }
        
        if not DETAILED_AVAILABLE:
            print("âŒ Detailed sentiment analysis not available. Cannot run tests.")
            return all_results
        
        # Run basic functionality test
        basic_results = self.test_basic_functionality()
        all_results["tests"]["basic_functionality"] = basic_results
        
        print(f"\nğŸ“Š Basic Functionality Results:")
        print(f"   Single Label Accuracy: {basic_results['single_label_accuracy']:.1f}%")
        print(f"   Multi Label Accuracy: {basic_results['multi_label_accuracy']:.1f}%")
        print(f"   Sentiment Mapping Accuracy: {basic_results['sentiment_mapping_accuracy']:.1f}%")
        print(f"   Failed Cases: {len(basic_results['failed_cases'])}")
        
        # Run integration test
        integration_results = self.test_integration_module()
        all_results["tests"]["integration"] = integration_results
        
        print(f"\nğŸ”— Integration Test Results:")
        print(f"   Tests Passed: {integration_results['tests_passed']}")
        print(f"   Tests Failed: {integration_results['tests_failed']}")
        if integration_results['errors']:
            print(f"   Errors: {integration_results['errors']}")
        
        # Run training data test
        training_results = self.test_training_data_creation()
        all_results["tests"]["training_data"] = training_results
        
        print(f"\nğŸ“ Training Data Test Results:")
        print(f"   Tests Passed: {training_results['tests_passed']}")
        print(f"   Tests Failed: {training_results['tests_failed']}")
        if training_results['errors']:
            print(f"   Errors: {training_results['errors']}")
        
        # Run edge cases test
        edge_results = self.test_edge_cases()
        all_results["tests"]["edge_cases"] = edge_results
        
        print(f"\nğŸ­ Edge Cases Test Results:")
        print(f"   Tests Passed: {edge_results['tests_passed']}")
        print(f"   Tests Failed: {edge_results['tests_failed']}")
        if edge_results['errors']:
            print(f"   Errors: {edge_results['errors'][:3]}...")  # Show first 3 errors
        
        # Overall summary
        total_passed = sum([
            basic_results.get('single_label_accuracy', 0) >= 70,  # At least 70% accuracy
            basic_results.get('multi_label_accuracy', 0) >= 60,   # At least 60% accuracy
            integration_results.get('tests_passed', 0) > integration_results.get('tests_failed', 0),
            training_results.get('tests_passed', 0) > training_results.get('tests_failed', 0),
            edge_results.get('tests_passed', 0) > edge_results.get('tests_failed', 0)
        ])
        
        print(f"\nğŸ¯ Overall Test Summary:")
        print(f"   Major Components Passed: {total_passed}/5")
        print(f"   System Status: {'âœ… PASSED' if total_passed >= 4 else 'âŒ FAILED'}")
        
        all_results["overall_status"] = "PASSED" if total_passed >= 4 else "FAILED"
        all_results["components_passed"] = total_passed
        
        return all_results

def main():
    """à¸£à¸±à¸™à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸šà¸«à¸¥à¸±à¸"""
    tester = DetailedSentimentTester()
    results = tester.run_all_tests()
    
    # Save results
    with open("test_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“ Full test results saved to: test_results.json")
    
    # Show failed cases if any
    if "basic_functionality" in results["tests"]:
        failed_cases = results["tests"]["basic_functionality"].get("failed_cases", [])
        if failed_cases:
            print(f"\nâŒ Failed Test Cases ({len(failed_cases)}):")
            for case in failed_cases[:3]:  # Show first 3 failed cases
                if "text" in case:
                    print(f"   Text: {case['text'][:50]}...")
                    if "single_predicted" in case:
                        print(f"   Expected: {case.get('single_expected')} | Got: {case.get('single_predicted')}")
    
    return results["overall_status"] == "PASSED"

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
