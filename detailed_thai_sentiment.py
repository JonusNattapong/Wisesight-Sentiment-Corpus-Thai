#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Detailed Thai Sentiment Analysis System
‡∏£‡∏∞‡∏ö‡∏ö sentiment analysis ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö multi-class ‡πÅ‡∏•‡∏∞ multi-label classification
"""

import json
import re
import random
from typing import List, Dict, Any, Optional, Union, Tuple
from datetime import datetime
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

# === EMOTION LABEL SCHEMA ===
EMOTION_LABELS = [
    # Positive
    "‡∏î‡∏µ‡πÉ‡∏à", "‡∏ä‡∏≠‡∏ö", "‡∏ã‡∏∂‡πâ‡∏á‡πÉ‡∏à", "‡∏û‡∏≠‡πÉ‡∏à", "‡∏£‡∏±‡∏Å",
    
    # Negative  
    "‡πÇ‡∏Å‡∏£‡∏ò", "‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à", "‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á", "‡∏£‡∏≥‡∏Ñ‡∏≤‡∏ç", "‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î", "‡∏Å‡∏•‡∏±‡∏ß", "‡∏≠‡∏∂‡∏î‡∏≠‡∏±‡∏î", "‡∏ï‡∏Å‡πÉ‡∏à",
    
    # Neutral
    "‡πÄ‡∏â‡∏¢ ‡πÜ", "‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏≠‡∏∞‡πÑ‡∏£", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£",
    
    # Others (Complex emotions)
    "‡∏õ‡∏£‡∏∞‡∏ä‡∏î", "‡∏Ç‡∏≥‡∏Ç‡∏±‡∏ô", "‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ", "‡∏™‡∏±‡∏ö‡∏™‡∏ô"
]

# Emotion grouping
EMOTION_GROUPS = {
    "Positive": ["‡∏î‡∏µ‡πÉ‡∏à", "‡∏ä‡∏≠‡∏ö", "‡∏ã‡∏∂‡πâ‡∏á‡πÉ‡∏à", "‡∏û‡∏≠‡πÉ‡∏à", "‡∏£‡∏±‡∏Å"],
    "Negative": ["‡πÇ‡∏Å‡∏£‡∏ò", "‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à", "‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á", "‡∏£‡∏≥‡∏Ñ‡∏≤‡∏ç", "‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î", "‡∏Å‡∏•‡∏±‡∏ß", "‡∏≠‡∏∂‡∏î‡∏≠‡∏±‡∏î", "‡∏ï‡∏Å‡πÉ‡∏à"],
    "Neutral": ["‡πÄ‡∏â‡∏¢ ‡πÜ", "‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏≠‡∏∞‡πÑ‡∏£", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£"],
    "Others": ["‡∏õ‡∏£‡∏∞‡∏ä‡∏î", "‡∏Ç‡∏≥‡∏Ç‡∏±‡∏ô", "‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ", "‡∏™‡∏±‡∏ö‡∏™‡∏ô"]
}

# Reverse mapping for quick lookup
LABEL_TO_GROUP = {}
for group, labels in EMOTION_GROUPS.items():
    for label in labels:
        LABEL_TO_GROUP[label] = group

class ThaiEmotionPatterns:
    """‡∏Ñ‡∏•‡∏≤‡∏™ pattern matching ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"""
    
    def __init__(self):
        self.emotion_patterns = self._build_emotion_patterns()
        self.intensity_patterns = self._build_intensity_patterns()
        self.context_patterns = self._build_context_patterns()
    
    def _build_emotion_patterns(self) -> Dict[str, Dict[str, Any]]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á patterns ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"""
        return {
            # === POSITIVE EMOTIONS ===
            "‡∏î‡∏µ‡πÉ‡∏à": {
                "keywords": ["‡∏î‡∏µ‡πÉ‡∏à", "‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç", "‡πÅ‡∏Æ‡∏õ‡∏õ‡∏µ‡πâ", "‡∏õ‡∏•‡∏∑‡πâ‡∏°", "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ", "‡πÄ‡∏Æ‡∏á", "‡πÄ‡∏¢‡πâ", "‡πÇ‡∏¢‡πà", "‡πÄ‡∏à‡πã‡∏á", "‡∏î‡∏µ‡πà‡πÉ‡∏à"],
                "patterns": [r"‡∏î‡∏µ\s*‡πÉ‡∏à", r"‡∏õ‡∏•‡∏∑‡πâ‡∏°", r"‡πÄ‡∏Æ‡∏á\s*‡∏ã‡∏∞", r"‡πÅ‡∏Æ‡∏õ‡∏õ‡∏µ‡πâ", r"‡πÄ‡∏¢‡πâ.*", r"‡πÇ‡∏¢‡πà.*"],
                "emojis": ["üòä", "üòÑ", "ü§ó", "üòç", "ü•∞", "üòò", "üòÜ", "ü§©"],
                "score_range": (0.6, 1.0)
            },
            
            "‡∏ä‡∏≠‡∏ö": {
                "keywords": ["‡∏ä‡∏≠‡∏ö", "‡∏£‡∏±‡∏Å", "‡∏ñ‡∏π‡∏Å‡πÉ‡∏à", "‡πÇ‡∏õ‡∏£‡∏î", "‡∏õ‡∏•‡∏∑‡πâ‡∏°", "‡∏™‡∏ô‡πÉ‡∏à", "‡∏≠‡∏¥‡∏ô", "‡πÄ‡∏Ñ‡∏•‡∏¥‡πâ‡∏°"],
                "patterns": [r"‡∏ä‡∏≠‡∏ö.*‡∏°‡∏≤‡∏Å", r"‡∏£‡∏±‡∏Å.*‡πÄ‡∏•‡∏¢", r"‡∏ñ‡∏π‡∏Å‡πÉ‡∏à", r"‡πÇ‡∏õ‡∏£‡∏î.*", r"‡∏™‡∏ô‡πÉ‡∏à.*‡∏°‡∏≤‡∏Å"],
                "emojis": ["‚ù§Ô∏è", "üíï", "üòç", "ü•∞", "üòò", "üíñ", "üíù"],
                "score_range": (0.5, 0.9)
            },
            
            "‡∏ã‡∏∂‡πâ‡∏á‡πÉ‡∏à": {
                "keywords": ["‡∏ã‡∏∂‡πâ‡∏á", "‡∏ã‡∏∂‡πâ‡∏á‡πÉ‡∏à", "‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏ã‡∏∂‡∏°", "‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à", "‡∏ã‡∏≤‡∏ö‡∏ã‡∏∂‡πâ‡∏á", "‡∏ï‡∏∑‡πâ‡∏ô‡∏ï‡∏±‡∏ô", "‡∏ã‡∏∑‡πà‡∏ô‡πÉ‡∏™"],
                "patterns": [r"‡∏ã‡∏∂‡πâ‡∏á.*‡πÉ‡∏à", r"‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à", r"‡∏ô‡πâ‡∏≥‡∏ï‡∏≤.*‡∏ã‡∏∂‡∏°", r"‡∏ã‡∏≤‡∏ö‡∏ã‡∏∂‡πâ‡∏á"],
                "emojis": ["üò≠", "ü•∫", "üò¢", "ü§ß", "üíû"],
                "score_range": (0.4, 0.8)
            },
            
            "‡∏û‡∏≠‡πÉ‡∏à": {
                "keywords": ["‡∏û‡∏≠‡πÉ‡∏à", "‡πÇ‡∏≠‡πÄ‡∏Ñ", "‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ", "‡∏õ‡∏Å‡∏ï‡∏¥‡∏î‡∏µ", "‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏£", "‡∏á‡∏≤‡∏°", "‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢"],
                "patterns": [r"‡∏û‡∏≠‡πÉ‡∏à", r"‡πÇ‡∏≠‡πÄ‡∏Ñ.*", r"‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ", r"‡∏õ‡∏Å‡∏ï‡∏¥‡∏î‡∏µ", r"‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢"],
                "emojis": ["üëç", "üëå", "üòå", "üôÇ"],
                "score_range": (0.2, 0.6)
            },
            
            "‡∏£‡∏±‡∏Å": {
                "keywords": ["‡∏£‡∏±‡∏Å", "‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å", "‡πÅ‡∏û‡∏á", "‡πÄ‡∏•‡∏¥‡∏ü", "love", "‡∏Æ‡∏±‡∏Å‡πÜ", "‡∏Æ‡∏±‡∏Å", "‡∏£‡∏±‡∏Å‡∏°‡∏≤‡∏Å"],
                "patterns": [r"‡∏£‡∏±‡∏Å.*‡∏°‡∏≤‡∏Å", r"‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å", r"‡πÄ‡∏•‡∏¥‡∏ü.*", r"love.*", r"‡∏Æ‡∏±‡∏Å.*"],
                "emojis": ["‚ù§Ô∏è", "üíï", "üíñ", "üíù", "üòç", "ü•∞", "üòò"],
                "score_range": (0.7, 1.0)
            },
            
            # === NEGATIVE EMOTIONS ===
            "‡πÇ‡∏Å‡∏£‡∏ò": {
                "keywords": ["‡πÇ‡∏Å‡∏£‡∏ò", "‡∏â‡∏∏‡∏ô", "‡πÇ‡∏°‡πÇ‡∏´", "‡πÅ‡∏Ñ‡πâ‡∏ô", "‡∏Ç‡∏∏‡πà‡∏ô‡∏Ç‡πâ‡∏≠‡∏á", "‡πÄ‡∏î‡∏∑‡∏≠‡∏î", "‡∏ö‡πâ‡∏≤", "‡∏´‡πà‡∏ß‡∏¢‡πÅ‡∏ï‡∏Å", "‡πÅ‡∏¢‡πà", "‡∏á‡∏µ‡πà‡πÄ‡∏á‡πà‡∏≤"],
                "patterns": [r"‡πÇ‡∏Å‡∏£‡∏ò.*‡∏°‡∏≤‡∏Å", r"‡∏â‡∏∏‡∏ô.*‡∏Ç‡∏≤‡∏î", r"‡πÇ‡∏°‡πÇ‡∏´", r"‡πÅ‡∏Ñ‡πâ‡∏ô.*", r"‡∏´‡πà‡∏ß‡∏¢.*‡πÅ‡∏ï‡∏Å", r"‡∏ö‡πâ‡∏≤.*", r"‡πÅ‡∏¢‡πà.*‡∏°‡∏≤‡∏Å"],
                "emojis": ["üò†", "üò°", "ü§¨", "üëø", "üí¢", "üò§"],
                "score_range": (-1.0, -0.6)
            },
            
            "‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à": {
                "keywords": ["‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à", "‡πÄ‡∏®‡∏£‡πâ‡∏≤", "‡πÉ‡∏à‡∏´‡∏≤‡∏¢", "‡∏õ‡∏ß‡∏î‡πÉ‡∏à", "‡πÄ‡∏®‡∏£‡πâ‡∏≤‡πÇ‡∏®‡∏Å", "‡πÇ‡∏®‡∏Å‡πÄ‡∏®‡∏£‡πâ‡∏≤", "‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏≤‡∏¢", "‡∏ô‡πà‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à"],
                "patterns": [r"‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à", r"‡πÄ‡∏®‡∏£‡πâ‡∏≤.*‡∏°‡∏≤‡∏Å", r"‡πÉ‡∏à‡∏´‡∏≤‡∏¢", r"‡∏õ‡∏ß‡∏î‡πÉ‡∏à", r"‡πÄ‡∏®‡∏£‡πâ‡∏≤‡πÇ‡∏®‡∏Å"],
                "emojis": ["üò¢", "üò≠", "üòû", "‚òπÔ∏è", "üòî", "üíî"],
                "score_range": (-0.8, -0.4)
            },
            
            "‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á": {
                "keywords": ["‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á", "‡∏´‡∏ß‡∏±‡∏á‡πÄ‡∏Å‡∏¥‡∏ô", "‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á", "‡∏ó‡πâ‡∏≠", "‡∏´‡∏°‡∏î‡∏´‡∏ß‡∏±‡∏á", "‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏î‡∏±‡∏á‡πÉ‡∏à"],
                "patterns": [r"‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á", r"‡∏´‡∏ß‡∏±‡∏á.*‡πÄ‡∏Å‡∏¥‡∏ô", r"‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á.*‡∏°‡∏≤‡∏Å", r"‡∏ó‡πâ‡∏≠.*", r"‡∏´‡∏°‡∏î‡∏´‡∏ß‡∏±‡∏á"],
                "emojis": ["üòû", "üòî", "üòì", "üò©", "üò§"],
                "score_range": (-0.7, -0.3)
            },
            
            "‡∏£‡∏≥‡∏Ñ‡∏≤‡∏ç": {
                "keywords": ["‡∏£‡∏≥‡∏Ñ‡∏≤‡∏ç", "‡∏ô‡πà‡∏≤‡∏£‡∏≥‡∏Ñ‡∏≤‡∏ç", "‡πÄ‡∏ö‡∏∑‡πà‡∏≠", "‡∏´‡∏ô‡πà‡∏≤‡∏¢", "‡πÄ‡∏ã‡πá‡∏á", "‡∏á‡πà‡∏ß‡∏á", "‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î", "‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢"],
                "patterns": [r"‡∏£‡∏≥‡∏Ñ‡∏≤‡∏ç", r"‡πÄ‡∏ö‡∏∑‡πà‡∏≠.*‡∏°‡∏≤‡∏Å", r"‡∏´‡∏ô‡πà‡∏≤‡∏¢.*", r"‡πÄ‡∏ã‡πá‡∏á.*", r"‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î.*"],
                "emojis": ["üòí", "üôÑ", "üò§", "üòë", "üò´", "üò©"],
                "score_range": (-0.6, -0.2)
            },
            
            "‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î": {
                "keywords": ["‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î", "‡∏Ç‡∏¢‡∏∞‡πÅ‡∏Ç‡∏¢‡∏á", "‡πÅ‡∏Ñ‡πâ‡∏ô", "‡πÅ‡∏Å‡∏•‡πâ‡∏á", "‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö", "‡∏ï‡πà‡∏≠‡∏ï‡πâ‡∏≤‡∏ô"],
                "patterns": [r"‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î.*‡∏°‡∏≤‡∏Å", r"‡∏Ç‡∏¢‡∏∞‡πÅ‡∏Ç‡∏¢‡∏á", r"‡πÅ‡∏Ñ‡πâ‡∏ô.*", r"‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö.*‡πÄ‡∏•‡∏¢"],
                "emojis": ["üò°", "ü§¨", "üëø", "üò†", "üí¢"],
                "score_range": (-1.0, -0.7)
            },
            
            "‡∏Å‡∏•‡∏±‡∏ß": {
                "keywords": ["‡∏Å‡∏•‡∏±‡∏ß", "‡∏´‡∏ß‡∏≤‡∏î‡∏Å‡∏•‡∏±‡∏ß", "‡∏ï‡∏Å‡πÉ‡∏à", "‡∏ß‡∏¥‡∏ï‡∏Å", "‡∏Å‡∏±‡∏á‡∏ß‡∏•", "‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î", "‡∏´‡∏ß‡∏±‡πà‡∏ô", "‡∏ï‡∏∑‡πà‡∏ô‡∏Å‡∏•‡∏±‡∏ß"],
                "patterns": [r"‡∏Å‡∏•‡∏±‡∏ß.*‡∏°‡∏≤‡∏Å", r"‡∏´‡∏ß‡∏≤‡∏î‡∏Å‡∏•‡∏±‡∏ß", r"‡∏ï‡∏Å‡πÉ‡∏à.*", r"‡∏ß‡∏¥‡∏ï‡∏Å.*", r"‡∏Å‡∏±‡∏á‡∏ß‡∏•.*"],
                "emojis": ["üò®", "üò∞", "üò±", "üòß", "ü´£", "üò≥"],
                "score_range": (-0.8, -0.3)
            },
            
            "‡∏≠‡∏∂‡∏î‡∏≠‡∏±‡∏î": {
                "keywords": ["‡∏≠‡∏∂‡∏î‡∏≠‡∏±‡∏î", "‡∏≠‡∏±‡∏ö‡∏≠‡∏≤‡∏¢", "‡πÄ‡∏Å‡πâ‡∏≠", "‡πÑ‡∏°‡πà‡∏™‡∏ö‡∏≤‡∏¢‡πÉ‡∏à", "‡∏Å‡∏î‡∏î‡∏±‡∏ô", "‡∏Ç‡∏±‡∏î‡πÉ‡∏à"],
                "patterns": [r"‡∏≠‡∏∂‡∏î‡∏≠‡∏±‡∏î", r"‡∏≠‡∏±‡∏ö‡∏≠‡∏≤‡∏¢", r"‡πÑ‡∏°‡πà‡∏™‡∏ö‡∏≤‡∏¢‡πÉ‡∏à", r"‡∏Å‡∏î‡∏î‡∏±‡∏ô", r"‡∏Ç‡∏±‡∏î‡πÉ‡∏à"],
                "emojis": ["üò£", "üòñ", "üò´", "üò§", "üò∞"],
                "score_range": (-0.6, -0.2)
            },
            
            "‡∏ï‡∏Å‡πÉ‡∏à": {
                "keywords": ["‡∏ï‡∏Å‡πÉ‡∏à", "‡∏™‡∏∞‡∏î‡∏∏‡πâ‡∏á", "‡πÇ‡∏´‡∏¢‡∏á", "‡∏ï‡∏Å‡∏ï‡∏∞‡∏•‡∏∂‡∏á", "‡∏ï‡∏∞‡∏•‡∏∂‡∏á", "‡∏´‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏ß"],
                "patterns": [r"‡∏ï‡∏Å‡πÉ‡∏à.*‡∏°‡∏≤‡∏Å", r"‡∏™‡∏∞‡∏î‡∏∏‡πâ‡∏á", r"‡πÇ‡∏´‡∏¢‡∏á", r"‡∏ï‡∏Å‡∏ï‡∏∞‡∏•‡∏∂‡∏á", r"‡∏ï‡∏∞‡∏•‡∏∂‡∏á"],
                "emojis": ["üò±", "üò®", "üò≥", "ü´®", "üòß"],
                "score_range": (-0.5, 0.0)
            },
            
            # === NEUTRAL EMOTIONS ===
            "‡πÄ‡∏â‡∏¢ ‡πÜ": {
                "keywords": ["‡πÄ‡∏â‡∏¢", "‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤", "‡∏õ‡∏Å‡∏ï‡∏¥", "‡πÇ‡∏≠‡πÄ‡∏Ñ", "‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ", "‡∏û‡∏≠‡πÉ‡∏ä‡πâ", "‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏£"],
                "patterns": [r"‡πÄ‡∏â‡∏¢.*‡πÜ", r"‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤", r"‡∏õ‡∏Å‡∏ï‡∏¥.*", r"‡πÇ‡∏≠‡πÄ‡∏Ñ", r"‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏£"],
                "emojis": ["üòê", "üôÇ", "üò∂", "üòë"],
                "score_range": (-0.1, 0.1)
            },
            
            "‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏≠‡∏∞‡πÑ‡∏£": {
                "keywords": ["‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å", "‡∏ä‡∏≤", "‡πÄ‡∏â‡∏¢", "‡πÑ‡∏°‡πà‡∏™‡∏ô", "‡πÑ‡∏°‡πà‡πÅ‡∏Ñ‡∏£‡πå", "‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à"],
                "patterns": [r"‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å.*‡∏≠‡∏∞‡πÑ‡∏£", r"‡∏ä‡∏≤.*", r"‡πÑ‡∏°‡πà‡∏™‡∏ô.*", r"‡πÑ‡∏°‡πà‡πÅ‡∏Ñ‡∏£‡πå"],
                "emojis": ["üò∂", "üòê", "ü§∑‚Äç‚ôÄÔ∏è", "ü§∑‚Äç‚ôÇÔ∏è"],
                "score_range": (-0.05, 0.05)
            },
            
            "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£": {
                "keywords": ["‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "‡∏Ç‡πà‡∏≤‡∏ß", "‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô", "‡πÅ‡∏à‡πâ‡∏á", "‡∏ö‡∏≠‡∏Å", "‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï", "‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç"],
                "patterns": [r"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•.*", r"‡∏Ç‡πà‡∏≤‡∏ß.*", r"‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô.*", r"‡πÅ‡∏à‡πâ‡∏á.*", r"‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï.*"],
                "emojis": ["üì∞", "üìä", "üìà", "üì¢", "‚ÑπÔ∏è"],
                "score_range": (0.0, 0.0)
            },
            
            # === OTHERS (COMPLEX EMOTIONS) ===
            "‡∏õ‡∏£‡∏∞‡∏ä‡∏î": {
                "keywords": ["‡∏õ‡∏£‡∏∞‡∏ä‡∏î", "‡πÄ‡∏´‡∏ô‡πá‡∏ö‡πÅ‡∏ô‡∏°", "‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ", "‡πÅ‡∏î‡∏Å‡∏î‡∏±‡∏ô", "‡∏à‡∏¥‡∏Å‡∏Å‡∏±‡∏î", "‡∏≠‡∏µ‡∏î‡∏≠‡∏Å"],
                "patterns": [r"‡∏õ‡∏£‡∏∞‡∏ä‡∏î.*", r"‡πÄ‡∏´‡∏ô‡πá‡∏ö‡πÅ‡∏ô‡∏°", r"‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ.*", r"‡πÅ‡∏î‡∏Å‡∏î‡∏±‡∏ô", r"‡∏à‡∏¥‡∏Å‡∏Å‡∏±‡∏î"],
                "emojis": ["üòè", "üôÑ", "üòí", "üò§"],
                "score_range": (-0.4, -0.1)
            },
            
            "‡∏Ç‡∏≥‡∏Ç‡∏±‡∏ô": {
                "keywords": ["‡∏Ç‡∏≥", "‡∏ï‡∏•‡∏Å", "555", "‡∏Æ‡∏≤", "‡πÄ‡∏Æ‡∏Æ‡∏≤", "‡∏™‡∏ô‡∏∏‡∏Å", "‡πÇ‡∏•‡∏Å‡πÅ‡∏ï‡∏Å", "‡∏Ñ‡∏£‡∏∑‡πà‡∏ô‡πÄ‡∏Ñ‡∏£‡∏á"],
                "patterns": [r"‡∏Ç‡∏≥.*", r"‡∏ï‡∏•‡∏Å.*", r"555+", r"‡∏Æ‡∏≤+", r"‡πÄ‡∏Æ‡∏Æ‡∏≤", r"‡∏™‡∏ô‡∏∏‡∏Å.*"],
                "emojis": ["üòÇ", "ü§£", "üòÜ", "üòÑ", "üòÅ", "ü§™", "üòú"],
                "score_range": (0.3, 0.8)
            },
            
            "‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ": {
                "keywords": ["‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ", "‡∏õ‡∏£‡∏∞‡∏ä‡∏î", "‡πÄ‡∏´‡∏ô‡πá‡∏ö", "‡πÅ‡∏ô‡∏°", "‡∏à‡∏¥‡∏Å‡∏Å‡∏±‡∏î", "‡πÅ‡∏Å‡∏•‡πâ‡∏á"],
                "patterns": [r"‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ.*", r"‡∏õ‡∏£‡∏∞‡∏ä‡∏î.*", r"‡πÄ‡∏´‡∏ô‡πá‡∏ö.*‡πÅ‡∏ô‡∏°", r"‡∏à‡∏¥‡∏Å‡∏Å‡∏±‡∏î.*"],
                "emojis": ["üòè", "üôÑ", "üòí"],
                "score_range": (-0.5, -0.2)
            },
            
            "‡∏™‡∏±‡∏ö‡∏™‡∏ô": {
                "keywords": ["‡∏™‡∏±‡∏ö‡∏™‡∏ô", "‡∏á‡∏á", "‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ", "‡πÅ‡∏õ‡∏•‡∏Å", "‡∏â‡∏á‡∏ô", "‡∏â‡∏á‡∏ô‡∏™‡∏ô‡πÄ‡∏ó‡πà‡∏´‡πå"],
                "patterns": [r"‡∏™‡∏±‡∏ö‡∏™‡∏ô", r"‡∏á‡∏á.*", r"‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ", r"‡πÅ‡∏õ‡∏•‡∏Å.*", r"‡∏â‡∏á‡∏ô.*"],
                "emojis": ["üòï", "ü§î", "üòµ‚Äçüí´", "ü´§", "üòµ"],
                "score_range": (-0.2, 0.2)
            }
        }
    
    def _build_intensity_patterns(self) -> Dict[str, List[str]]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á patterns ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"""
        return {
            "high": ["‡∏°‡∏≤‡∏Å", "‡πÄ‡∏•‡∏¢", "‡∏™‡∏∏‡∏î", "‡πÅ‡∏£‡∏á", "‡∏´‡∏ô‡∏±‡∏Å", "‡πÇ‡∏Ñ‡∏ï‡∏£", "‡πÅ‡∏™‡∏ô", "‡∏™‡∏≤‡∏´‡∏±‡∏™", "‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡πâ‡∏≤", "‡∏à‡∏£‡∏¥‡∏á‡πÜ"],
            "medium": ["‡∏û‡∏≠", "‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á", "‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á", "‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ", "‡πÇ‡∏≠‡πÄ‡∏Ñ"],
            "low": ["‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢", "‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢", "‡πÄ‡∏ö‡∏≤‡πÜ", "‡∏ô‡∏¥‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß", "‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏Å"]
        }
    
    def _build_context_patterns(self) -> Dict[str, List[str]]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á patterns ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤"""
        return {
            # === ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£ ===
            "formal": ["‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏Ñ‡πà‡∏∞", "‡∏Ñ‡∏∞", "‡∏Ç‡∏≠", "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤", "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ", "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì", "‡∏ó‡πà‡∏≤‡∏ô", "‡∏Ñ‡∏∏‡∏ì", "‡∏û‡∏µ‡πà", "‡∏ô‡πâ‡∏≠‡∏á", "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", "‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏≤‡∏£‡∏û"],
            "informal": ["‡∏ô‡∏∞", "‡πÄ‡∏ô‡∏≠‡∏∞", "‡∏≠‡∏∞", "‡πÄ‡∏≠‡πâ‡∏¢", "‡πÄ‡∏≠‡∏≠", "‡∏Ç‡∏≠‡∏á", "555", "‡∏Æ‡∏≤", "‡∏à‡πâ‡∏∞", "‡∏à‡πã‡∏≤", "‡∏ß‡πà‡∏∞", "‡∏ß‡∏∞", "‡πÄ‡∏Æ‡πâ‡∏¢"],
            "slang": ["‡πÇ‡∏Ñ‡∏ï‡∏£", "‡πÄ‡∏ü‡∏µ‡πâ‡∏¢‡∏ß", "‡πÄ‡∏ó‡∏û", "‡πÅ‡∏°‡πà‡∏á", "‡∏Ñ‡∏ß‡∏¢", "‡∏ö‡∏¥‡∏ô", "‡πÄ‡∏ü‡∏µ‡πâ‡∏¢‡∏°", "‡∏ä‡∏¥‡∏ö", "‡πÄ‡∏î‡πá‡∏î", "‡∏õ‡∏±‡∏á", "‡∏´‡πà‡∏ß‡∏¢", "‡∏ã‡∏ß‡∏¢"],
            
            # === ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß ===
            "personal": ["‡∏Å‡∏π", "‡∏°‡∏∂‡∏á", "‡πÄ‡∏£‡∏≤", "‡∏â‡∏±‡∏ô", "‡∏Ñ‡∏¥‡∏î", "‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å", "‡πÉ‡∏à", "‡∏´‡∏±‡∏ß‡πÉ‡∏à", "‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á", "‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß"],
            "intimate": ["‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å", "‡∏´‡∏ß‡∏≤‡∏ô‡πÉ‡∏à", "‡∏î‡∏≤‡∏£‡πå‡∏•‡∏¥‡πà‡∏á", "‡∏Æ‡∏±‡∏ô‡∏ô‡∏µ‡πà", "‡πÄ‡∏ö‡∏ö‡∏µ‡πâ", "‡∏Ñ‡∏ô‡∏î‡∏µ", "‡πÄ‡∏™‡∏∑‡∏≠", "‡∏´‡∏ô‡∏π‡πÄ‡∏≠‡∏á"],
            "friendly": ["‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô", "‡πÄ‡∏ü‡∏£‡πâ‡∏ô", "‡∏û‡∏ß‡∏Å‡πÄ‡∏£‡∏≤", "‡πÅ‡∏Å‡πä‡∏á", "‡∏Å‡∏•‡∏∏‡πà‡∏°", "‡∏Ñ‡∏ô‡πÄ‡∏Å‡πà‡∏≤", "‡∏û‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏á"],
            
            # === ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏±‡∏á‡∏Ñ‡∏° ===
            "social_media": ["‡πÅ‡∏ä‡∏£‡πå", "‡πÑ‡∏•‡∏Ñ‡πå", "‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå", "‡πÇ‡∏û‡∏™‡∏ï‡πå", "‡πÅ‡∏ó‡πá‡∏Å", "‡πÄ‡∏ü‡∏™‡∏ö‡∏∏‡πä‡∏Ñ", "‡πÑ‡∏≠‡∏à‡∏µ", "‡∏ó‡∏ß‡∏¥‡∏ï‡πÄ‡∏ï‡∏≠‡∏£‡πå", "‡∏ï‡∏¥‡πä‡∏Å‡∏ï‡πä‡∏≠‡∏Å", "‡∏¢‡∏π‡∏ó‡∏π‡∏õ"],
            "news_media": ["‡∏Ç‡πà‡∏≤‡∏ß", "‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô", "‡πÅ‡∏à‡πâ‡∏á‡∏Ç‡πà‡∏≤‡∏ß", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï", "‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®", "‡πÅ‡∏ñ‡∏•‡∏á‡∏Å‡∏≤‡∏£‡∏ì‡πå", "‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç", "‡∏î‡πà‡∏ß‡∏ô"],
            "review": ["‡∏£‡∏µ‡∏ß‡∏¥‡∏ß", "‡∏ó‡∏î‡∏•‡∏≠‡∏á", "‡πÉ‡∏ä‡πâ‡∏î‡∏π", "‡∏•‡∏≠‡∏á", "‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå", "‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û", "‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£", "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤", "‡∏£‡πâ‡∏≤‡∏ô"],
            
            # === ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå ===
            "complaint": ["‡∏ö‡πà‡∏ô", "‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", "‡πÅ‡∏à‡πâ‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤", "‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ", "‡πÄ‡∏™‡∏µ‡∏¢", "‡∏´‡πà‡∏ß‡∏¢", "‡πÅ‡∏¢‡πà", "‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î", "‡∏ä‡πâ‡∏≤"],
            "praise": ["‡∏ä‡∏°", "‡∏¢‡∏Å‡∏¢‡πà‡∏≠‡∏á", "‡∏î‡∏µ", "‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°", "‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à", "‡∏ä‡∏≠‡∏ö", "‡∏£‡∏±‡∏Å", "‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î", "‡πÄ‡∏à‡πã‡∏á", "‡πÄ‡∏ó‡∏û"],
            "question": ["‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏Ñ‡∏∞", "‡∏°‡∏±‡πâ‡∏¢", "‡∏´‡∏£‡∏∑‡∏≠", "‡πÑ‡∏´‡∏°", "‡∏≠‡∏∞‡πÑ‡∏£", "‡∏ó‡∏≥‡πÑ‡∏°", "‡∏¢‡∏±‡∏á‡πÑ‡∏á", "‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà", "‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô"],
            
            # === ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå ===
            "emergency": ["‡∏î‡πà‡∏ß‡∏ô", "‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô", "‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô", "‡∏ä‡πà‡∏ß‡∏¢", "‡∏õ‡∏±‡∏ç‡∏´‡∏≤", "‡πÄ‡∏™‡∏µ‡∏¢", "‡∏û‡∏±‡∏á", "‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢", "‡∏ß‡∏¥‡∏Å‡∏§‡∏ï"],
            "celebration": ["‡∏¢‡∏¥‡∏ô‡∏î‡∏µ", "‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏¥‡∏ô‡∏î‡∏µ", "‡∏Ç‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏¥‡∏ô‡∏î‡∏µ", "‡∏î‡∏µ‡πÉ‡∏à", "‡∏õ‡∏•‡∏∑‡πâ‡∏°‡∏õ‡∏µ‡∏ï‡∏¥", "‡πÄ‡∏Æ‡∏á", "‡πÇ‡∏ä‡∏Ñ‡∏î‡∏µ"],
            "condolence": ["‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à", "‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à", "‡∏Ç‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à", "‡πÄ‡∏®‡∏£‡πâ‡∏≤", "‡∏≠‡∏≤‡∏•‡∏±‡∏¢", "‡∏Ñ‡∏¥‡∏î‡∏ñ‡∏∂‡∏á"],
            
            # === ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ß‡∏±‡∏í‡∏ô‡∏ò‡∏£‡∏£‡∏° ===
            "religious": ["‡∏ö‡∏∏‡∏ç", "‡∏Å‡∏£‡∏£‡∏°", "‡∏ò‡∏£‡∏£‡∏°", "‡∏û‡∏£‡∏∞", "‡∏ß‡∏±‡∏î", "‡∏ô‡∏°‡∏±‡∏™‡∏Å‡∏≤‡∏£", "‡πÑ‡∏´‡∏ß‡πâ", "‡∏®‡∏≤‡∏™‡∏ô‡∏≤", "‡∏ö‡∏≤‡∏õ", "‡∏Å‡∏∏‡∏®‡∏•"],
            "traditional": ["‡∏õ‡∏£‡∏∞‡πÄ‡∏û‡∏ì‡∏µ", "‡∏ß‡∏±‡∏í‡∏ô‡∏ò‡∏£‡∏£‡∏°", "‡πÑ‡∏ó‡∏¢", "‡πÇ‡∏ö‡∏£‡∏≤‡∏ì", "‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°", "‡∏†‡∏π‡∏°‡∏¥‡∏õ‡∏±‡∏ç‡∏ç‡∏≤", "‡∏ä‡∏≤‡∏ß‡∏ö‡πâ‡∏≤‡∏ô"],
            "modern": ["‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢", "‡πÇ‡∏°‡πÄ‡∏î‡∏¥‡∏£‡πå‡∏ô", "‡πÑ‡∏Æ‡πÄ‡∏ó‡∏Ñ", "‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•", "‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå", "‡πÅ‡∏≠‡∏õ", "‡πÑ‡∏≠‡∏ó‡∏µ", "‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ"],
            
            # === ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏†‡∏π‡∏°‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ===
            "central": ["‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û", "‡∏Å‡∏ó‡∏°", "‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏´‡∏•‡∏ß‡∏á", "‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á", "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á"],
            "northern": ["‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà", "‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠", "‡∏•‡πâ‡∏≤‡∏ô‡∏ô‡∏≤", "‡∏Ñ‡∏≥‡πÄ‡∏°‡∏∑‡∏≠‡∏á", "‡∏ô‡∏≤", "‡∏õ‡πà‡∏≤"],
            "southern": ["‡πÉ‡∏ï‡πâ", "‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ", "‡∏ó‡∏∞‡πÄ‡∏•", "‡∏õ‡∏•‡∏≤", "‡∏¢‡∏≤‡∏á‡∏û‡∏≤‡∏£‡∏≤", "‡∏õ‡∏≤‡∏•‡πå‡∏°"],
            "northeastern": ["‡∏≠‡∏µ‡∏™‡∏≤‡∏ô", "‡∏†‡∏≤‡∏Ñ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô", "‡∏™‡πâ‡∏°‡∏ï‡∏≥", "‡∏•‡∏≤‡∏ß", "‡∏Ç‡πâ‡∏≤‡∏ß‡πÄ‡∏´‡∏ô‡∏µ‡∏¢‡∏ß", "‡πÅ‡∏à‡πà‡∏ß"],
            
            # === ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏≠‡∏≤‡∏¢‡∏∏/‡∏£‡∏∏‡πà‡∏ô ===
            "gen_z": ["‡∏õ‡∏±‡∏á", "‡πÄ‡∏î‡πá‡∏î", "‡∏ü‡∏¥‡∏ô", "‡∏ä‡∏¥‡∏•", "‡πÄ‡∏ü‡∏•‡πá‡∏Å‡∏ã‡πå", "‡πÇ‡∏ö", "‡∏•‡∏¥‡∏ï", "‡πÑ‡∏ß‡∏ö‡πå", "‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡∏ô‡∏ï‡πå"],
            "millennial": ["‡πÇ‡∏≠‡πÄ‡∏Ñ", "‡πÄ‡∏ü‡∏™", "‡πÑ‡∏•‡∏ô‡πå", "‡∏≠‡∏¥‡∏ô‡∏™‡∏ï‡∏≤", "‡∏ã‡∏µ‡∏£‡∏µ‡πà‡∏¢‡πå", "‡∏¢‡∏π‡∏ó‡∏π‡∏õ", "‡∏Å‡∏π‡πÄ‡∏Å‡∏¥‡∏•"],
            "gen_x": ["‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡πà‡∏≤", "‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠", "‡∏™‡∏°‡∏±‡∏¢‡∏Å‡πà‡∏≠‡∏ô", "‡∏ï‡∏≠‡∏ô‡∏´‡∏ô‡∏∏‡πà‡∏°", "‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"],
            
            # === ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤‡∏ä‡∏µ‡∏û ===
            "business": ["‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à", "‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î", "‡∏Ç‡∏≤‡∏¢", "‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤", "‡∏Å‡∏≥‡πÑ‡∏£", "‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô", "‡∏•‡∏á‡∏ó‡∏∏‡∏ô"],
            "education": ["‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", "‡∏™‡∏≠‡∏ô", "‡∏Ñ‡∏£‡∏π", "‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", "‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤", "‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤", "‡∏ß‡∏¥‡∏ä‡∏≤"],
            "healthcare": ["‡∏´‡∏°‡∏≠", "‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å", "‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏¢‡∏≤", "‡∏£‡∏±‡∏Å‡∏©‡∏≤", "‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û", "‡∏õ‡πà‡∏ß‡∏¢"],
            "government": ["‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£", "‡∏£‡∏±‡∏ê‡∏ö‡∏≤‡∏•", "‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢", "‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢", "‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö", "‡∏Ç‡πâ‡∏≤‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£"]
        }

class DetailedThaiSentimentAnalyzer:
    """‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"""
    
    def __init__(self):
        self.patterns = ThaiEmotionPatterns()
        self.multi_label_threshold = 0.3  # threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô multi-label
        
    def _clean_text(self, text: str) -> str:
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        if not text:
            return ""
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏•‡πá‡∏Å
        text = text.lower()
        
        # ‡∏•‡∏ö URL
        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
        
        # ‡∏•‡∏ö mentions ‡πÅ‡∏•‡∏∞ hashtags ‡πÉ‡∏ô social media
        text = re.sub(r'[@#]\w+', '', text)
        
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏Å‡∏¥‡∏ô
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def _extract_emojis(self, text: str) -> List[str]:
        """‡∏î‡∏∂‡∏á emojis ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        emoji_pattern = re.compile(
            "["
            "\U0001F600-\U0001F64F"  # emoticons
            "\U0001F300-\U0001F5FF"  # symbols & pictographs
            "\U0001F680-\U0001F6FF"  # transport & map
            "\U0001F1E0-\U0001F1FF"  # flags
            "\U00002702-\U000027B0"
            "\U000024C2-\U0001F251"
            "]+", flags=re.UNICODE
        )
        return emoji_pattern.findall(text)
    
    def _calculate_emotion_scores(self, text: str) -> Dict[str, float]:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"""
        clean_text = self._clean_text(text)
        emojis = self._extract_emojis(text)
        emotion_scores = defaultdict(float)
        
        for emotion, config in self.patterns.emotion_patterns.items():
            score = 0.0
            
            # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
            for keyword in config["keywords"]:
                if keyword in clean_text:
                    score += 1.0
            
            # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å patterns (regex)
            for pattern in config.get("patterns", []):
                matches = re.findall(pattern, clean_text)
                score += len(matches) * 1.5
            
            # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å emojis
            for emoji in emojis:
                if emoji in config.get("emojis", []):
                    score += 2.0
            
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô
            intensity_bonus = self._calculate_intensity_bonus(clean_text)
            score *= (1 + intensity_bonus)
            
            emotion_scores[emotion] = min(score, 5.0)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
        
        return dict(emotion_scores)
    
    def _calculate_intensity_bonus(self, text: str) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì bonus ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏≠‡∏Å"""
        bonus = 0.0
        
        for intensity, words in self.patterns.intensity_patterns.items():
            for word in words:
                if word in text:
                    if intensity == "high":
                        bonus += 0.5
                    elif intensity == "medium":
                        bonus += 0.2
                    elif intensity == "low":
                        bonus += 0.1
        
        return min(bonus, 1.0)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î bonus ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    
    def _determine_context(self, text: str) -> Dict[str, Any]:
        """‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"""
        clean_text = self._clean_text(text)
        context_scores = defaultdict(int)
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏ö‡∏ó
        for context, words in self.patterns.context_patterns.items():
            for word in words:
                if word in clean_text:
                    context_scores[context] += 1
        
        if not context_scores:
            return {
                "primary_context": "neutral",
                "all_contexts": {},
                "formality_level": "neutral",
                "social_setting": "general",
                "emotional_tone": "neutral"
            }
        
        # ‡∏´‡∏≤‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏´‡∏•‡∏±‡∏Å
        primary_context = max(context_scores, key=context_scores.get)
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£
        formality_score = {
            "formal": context_scores.get("formal", 0),
            "informal": context_scores.get("informal", 0),
            "slang": context_scores.get("slang", 0)
        }
        formality_level = max(formality_score, key=formality_score.get) if any(formality_score.values()) else "neutral"
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏™‡∏±‡∏á‡∏Ñ‡∏°
        social_contexts = ["social_media", "news_media", "review", "business", "education", "healthcare", "government"]
        social_scores = {ctx: context_scores.get(ctx, 0) for ctx in social_contexts}
        social_setting = max(social_scores, key=social_scores.get) if any(social_scores.values()) else "general"
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏ó‡∏ô‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
        emotional_contexts = ["complaint", "praise", "emergency", "celebration", "condolence"]
        emotional_scores = {ctx: context_scores.get(ctx, 0) for ctx in emotional_contexts}
        emotional_tone = max(emotional_scores, key=emotional_scores.get) if any(emotional_scores.values()) else "neutral"
        
        return {
            "primary_context": primary_context,
            "all_contexts": dict(context_scores),
            "formality_level": formality_level,
            "social_setting": social_setting,
            "emotional_tone": emotional_tone,
            "context_confidence": round(context_scores[primary_context] / len(clean_text.split()) if clean_text.split() else 0, 3)
        }
    
    def _normalize_scores(self, scores: Dict[str, float]) -> Dict[str, float]:
        """normalize ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 0-1"""
        if not scores:
            return {}
        
        max_score = max(scores.values())
        if max_score == 0:
            return scores
        
        return {emotion: score / max_score for emotion, score in scores.items()}
    
    def analyze_single_label(self, text: str) -> Dict[str, Any]:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡πÅ‡∏ö‡∏ö single label (multi-class classification)"""
        if not text or not text.strip():
            return {
                "text": text,
                "label": "‡πÄ‡∏â‡∏¢ ‡πÜ",
                "group": "Neutral",
                "confidence": 0.0,
                "scores": {},
                "context": {
                    "primary_context": "neutral",
                    "formality_level": "neutral",
                    "social_setting": "general",
                    "emotional_tone": "neutral"
                },
                "analysis_type": "single_label"
            }
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
        raw_scores = self._calculate_emotion_scores(text)
        normalized_scores = self._normalize_scores(raw_scores)
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
        if not normalized_scores:
            predicted_label = "‡πÄ‡∏â‡∏¢ ‡πÜ"
            confidence = 0.0
        else:
            predicted_label = max(normalized_scores, key=normalized_scores.get)
            confidence = normalized_scores[predicted_label]
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
        group = LABEL_TO_GROUP.get(predicted_label, "Unknown")
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
        context = self._determine_context(text)
        
        return {
            "text": text,
            "label": predicted_label,
            "group": group,
            "confidence": round(confidence, 3),
            "scores": {k: round(v, 3) for k, v in normalized_scores.items()},
            "context": context,
            "analysis_type": "single_label",
            "timestamp": datetime.now().isoformat()
        }
    
    def analyze_multi_label(self, text: str, threshold: float = None) -> Dict[str, Any]:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡πÅ‡∏ö‡∏ö multi-label classification"""
        if threshold is None:
            threshold = self.multi_label_threshold
        
        if not text or not text.strip():
            return {
                "text": text,
                "labels": ["‡πÄ‡∏â‡∏¢ ‡πÜ"],
                "groups": ["Neutral"],
                "scores": {},
                "context": {
                    "primary_context": "neutral",
                    "formality_level": "neutral",
                    "social_setting": "general",
                    "emotional_tone": "neutral"
                },
                "analysis_type": "multi_label",
                "threshold": threshold
            }
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
        raw_scores = self._calculate_emotion_scores(text)
        normalized_scores = self._normalize_scores(raw_scores)
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô threshold
        predicted_labels = []
        for emotion, score in normalized_scores.items():
            if score >= threshold:
                predicted_labels.append(emotion)
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÉ‡∏î‡πÄ‡∏Å‡∏¥‡∏ô threshold ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
        if not predicted_labels and normalized_scores:
            predicted_labels = [max(normalized_scores, key=normalized_scores.get)]
        elif not predicted_labels:
            predicted_labels = ["‡πÄ‡∏â‡∏¢ ‡πÜ"]
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
        groups = list(set(LABEL_TO_GROUP.get(label, "Unknown") for label in predicted_labels))
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
        context = self._determine_context(text)
        
        return {
            "text": text,
            "labels": predicted_labels,
            "groups": groups,
            "scores": {k: round(v, 3) for k, v in normalized_scores.items()},
            "context": context,
            "analysis_type": "multi_label",
            "threshold": threshold,
            "timestamp": datetime.now().isoformat()
        }
    
    def analyze_batch(self, texts: List[str], multi_label: bool = False, threshold: float = None) -> List[Dict[str, Any]]:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡πÅ‡∏ö‡∏ö batch"""
        results = []
        
        for text in texts:
            if multi_label:
                result = self.analyze_multi_label(text, threshold)
            else:
                result = self.analyze_single_label(text)
            
            results.append(result)
        
        return results
    
    def get_emotion_statistics(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå"""
        if not results:
            return {}
        
        stats = {
            "total_texts": len(results),
            "analysis_type": results[0].get("analysis_type", "unknown"),
            "emotion_counts": defaultdict(int),
            "group_counts": defaultdict(int),
            "context_stats": {
                "primary_context_counts": defaultdict(int),
                "formality_level_counts": defaultdict(int),
                "social_setting_counts": defaultdict(int),
                "emotional_tone_counts": defaultdict(int)
            },
            "avg_confidence": 0.0,
            "context_insights": {}
        }
        
        total_confidence = 0.0
        
        for result in results:
            # ‡∏ô‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
            if "label" in result:  # single label
                stats["emotion_counts"][result["label"]] += 1
                stats["group_counts"][result["group"]] += 1
                total_confidence += result.get("confidence", 0.0)
            elif "labels" in result:  # multi label
                for label in result["labels"]:
                    stats["emotion_counts"][label] += 1
                for group in result["groups"]:
                    stats["group_counts"][group] += 1
                # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö multi-label ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÄ‡∏õ‡πá‡∏ô confidence
                if result["scores"]:
                    total_confidence += max(result["scores"].values())
            
            # ‡∏ô‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡∏°‡πà)
            context = result.get("context", {})
            if isinstance(context, str):
                # ‡πÅ‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤
                stats["context_stats"]["primary_context_counts"][context] += 1
            elif isinstance(context, dict):
                # ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
                stats["context_stats"]["primary_context_counts"][context.get("primary_context", "unknown")] += 1
                stats["context_stats"]["formality_level_counts"][context.get("formality_level", "unknown")] += 1
                stats["context_stats"]["social_setting_counts"][context.get("social_setting", "unknown")] += 1
                stats["context_stats"]["emotional_tone_counts"][context.get("emotional_tone", "unknown")] += 1
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì confidence ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
        if stats["total_texts"] > 0:
            stats["avg_confidence"] = round(total_confidence / stats["total_texts"], 3)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á context insights
        stats["context_insights"] = self._generate_context_insights(stats["context_stats"])
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å defaultdict ‡πÄ‡∏õ‡πá‡∏ô dict ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
        stats["emotion_counts"] = dict(stats["emotion_counts"])
        stats["group_counts"] = dict(stats["group_counts"])
        
        for key in stats["context_stats"]:
            stats["context_stats"][key] = dict(stats["context_stats"][key])
        
        return stats
    
    def _generate_context_insights(self, context_stats: Dict[str, Dict[str, int]]) -> Dict[str, str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á insights ‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏ö‡∏£‡∏¥‡∏ö‡∏ó"""
        insights = {}
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£
        formality = context_stats.get("formality_level_counts", {})
        if formality:
            most_formal = max(formality, key=formality.get)
            insights["formality"] = f"‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö {most_formal} ({formality[most_formal]} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á)"
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏™‡∏±‡∏á‡∏Ñ‡∏°
        social = context_stats.get("social_setting_counts", {})
        if social:
            most_social = max(social, key=social.get)
            insights["social_setting"] = f"‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {most_social} ({social[most_social]} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á)"
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏ó‡∏ô‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
        emotional = context_stats.get("emotional_tone_counts", {})
        if emotional:
            most_emotional = max(emotional, key=emotional.get)
            insights["emotional_tone"] = f"‡πÇ‡∏ó‡∏ô‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏´‡∏•‡∏±‡∏Å: {most_emotional} ({emotional[most_emotional]} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á)"
        
        return insights

# === ADVANCED CONTEXT ANALYSIS FUNCTIONS ===

def analyze_context_emotion_correlation(results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"""
    context_emotion_map = defaultdict(lambda: defaultdict(int))
    
    for result in results:
        context = result.get("context", {})
        if isinstance(context, dict):
            primary_context = context.get("primary_context", "unknown")
            formality = context.get("formality_level", "unknown")
            social_setting = context.get("social_setting", "unknown")
            
            # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå
            if "label" in result:
                emotion = result["label"]
                context_emotion_map[primary_context][emotion] += 1
                context_emotion_map[f"formality_{formality}"][emotion] += 1
                context_emotion_map[f"social_{social_setting}"][emotion] += 1
            elif "labels" in result:
                for emotion in result["labels"]:
                    context_emotion_map[primary_context][emotion] += 1
                    context_emotion_map[f"formality_{formality}"][emotion] += 1
                    context_emotion_map[f"social_{social_setting}"][emotion] += 1
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô percentage
    correlation_stats = {}
    for context, emotions in context_emotion_map.items():
        total = sum(emotions.values())
        if total > 0:
            correlation_stats[context] = {
                emotion: round((count / total) * 100, 2) 
                for emotion, count in emotions.items()
            }
    
    return correlation_stats

def get_context_recommendations(text: str, analyzer: DetailedThaiSentimentAnalyzer) -> Dict[str, Any]:
    """‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏ï‡∏≤‡∏°‡∏ö‡∏£‡∏¥‡∏ö‡∏ó"""
    result = analyzer.analyze_single_label(text)
    context = result.get("context", {})
    
    recommendations = {
        "current_analysis": result,
        "suggestions": [],
        "context_warnings": [],
        "improvement_tips": []
    }
    
    if isinstance(context, dict):
        formality = context.get("formality_level", "neutral")
        social_setting = context.get("social_setting", "general")
        emotional_tone = context.get("emotional_tone", "neutral")
        primary_context = context.get("primary_context", "neutral")
        
        # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£
        if formality == "slang" and social_setting in ["business", "government", "education"]:
            recommendations["context_warnings"].append(
                "‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏™‡πÅ‡∏•‡∏á‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£ ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"
            )
            recommendations["suggestions"].append(
                "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô"
            )
        
        if formality == "formal" and social_setting == "social_media":
            recommendations["suggestions"].append(
                "‡∏≠‡∏≤‡∏à‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏ã‡πÄ‡∏ä‡∏µ‡∏¢‡∏•‡∏°‡∏µ‡πÄ‡∏î‡∏µ‡∏¢"
            )
        
        # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡πÇ‡∏ó‡∏ô‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
        if emotional_tone == "complaint" and result["group"] == "Positive":
            recommendations["context_warnings"].append(
                "‡∏°‡∏µ‡πÇ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÅ‡∏ï‡πà‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏ß‡∏Å - ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ"
            )
        
        if emotional_tone == "emergency" and result["confidence"] < 0.5:
            recommendations["context_warnings"].append(
                "‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ï‡πà‡∏≥"
            )
        
        # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
        if result["confidence"] < 0.3:
            recommendations["improvement_tips"].append(
                "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô"
            )
        
        if len(context.get("all_contexts", {})) > 5:
            recommendations["improvement_tips"].append(
                "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏µ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ú‡∏™‡∏°‡∏ú‡∏™‡∏≤‡∏ô‡∏°‡∏≤‡∏Å ‡∏≠‡∏≤‡∏à‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÑ‡∏î‡πâ"
            )
    
    return recommendations

# === UTILITY FUNCTIONS FOR COMPREHENSIVE ANALYSIS ===

def create_training_data_format(
    text: str, 
    labels: Union[str, List[str]], 
    format_type: str = "classification"
) -> Dict[str, Any]:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ train model"""
    
    if format_type == "classification":
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö traditional ML models (BERT, RoBERTa, etc.)
        if isinstance(labels, str):
            return {
                "text": text,
                "label": labels,
                "label_id": EMOTION_LABELS.index(labels) if labels in EMOTION_LABELS else 0
            }
        else:
            # Multi-label: ‡∏™‡∏£‡πâ‡∏≤‡∏á binary vector
            label_vector = [0] * len(EMOTION_LABELS)
            for label in labels:
                if label in EMOTION_LABELS:
                    label_vector[EMOTION_LABELS.index(label)] = 1
            
            return {
                "text": text,
                "labels": labels,
                "label_vector": label_vector
            }
    
    elif format_type == "instruction":
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM fine-tuning
        if isinstance(labels, str):
            instruction = "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"
            output = labels
        else:
            instruction = "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå)"
            output = ", ".join(labels)
        
        return {
            "instruction": instruction,
            "input": text,
            "output": output
        }
    
    else:
        raise ValueError(f"Unsupported format_type: {format_type}")

def save_training_data(
    data: List[Dict[str, Any]], 
    output_path: str, 
    format_type: str = "jsonl"
) -> str:
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£ train"""
    
    if format_type == "jsonl":
        with open(output_path, 'w', encoding='utf-8') as f:
            for item in data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    elif format_type == "json":
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    else:
        raise ValueError(f"Unsupported format_type: {format_type}")
    
    return output_path

def demo_detailed_sentiment_analysis():
    """Demo ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡∏∞‡∏ö‡∏ö sentiment analysis ‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"""
    
    print("üéØ Demo: Detailed Thai Sentiment Analysis")
    print("=" * 60)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á analyzer
    analyzer = DetailedThaiSentimentAnalyzer()
    
    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡∏£‡∏¥‡∏ö‡∏ó
    test_texts = [
        "‡πÇ‡∏Å‡∏£‡∏ò‡∏à‡∏ô‡∏Ç‡∏≥‡∏≠‡∏∞‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï! ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏î‡πâ‡∏ß‡∏¢ 555",  # informal + mixed emotion
        "‡∏õ‡∏£‡∏∞‡∏ä‡∏î‡∏´‡∏ô‡∏±‡∏Å‡∏°‡∏≤‡∏Å‡∏à‡∏ô‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÅ‡∏¢‡πà ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πÄ‡∏•‡∏¢",  # complaint + sarcasm
        "‡∏°‡∏±‡∏ô‡∏Å‡πá‡πÇ‡∏≠‡πÄ‡∏Ñ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏™‡∏∏‡∏î ‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡πÑ‡∏ß‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ",  # review + disappointment
        "‡∏î‡∏µ‡πÉ‡∏à‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢! ‡∏£‡∏±‡∏Å‡∏°‡∏≤‡∏Å‡πÜ ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ô‡∏∞‡∏Ñ‡∏∞ üòç‚ù§Ô∏è",  # informal + positive
        "‡∏Ç‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ï‡πà‡∏≠‡πÑ‡∏õ",  # formal + celebration
        "‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô ‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£‡∏õ‡∏Å‡∏ï‡∏¥‡∏î‡∏µ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤",  # news + neutral
        "‡∏≠‡∏µ‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏¥‡∏£‡πå‡∏ã‡∏ô‡∏µ‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡∏µ‡∏°‡∏≤‡∏Å ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡∏≠‡∏á‡∏ñ‡∏π‡∏Å‡∏î‡πâ‡∏ß‡∏¢",  # review + business
        "‡∏á‡∏á‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ ‡∏™‡∏±‡∏ö‡∏™‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ü§î",  # informal + confusion
        "‡∏î‡πà‡∏ß‡∏ô! ‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏‡πÑ‡∏ü‡πÑ‡∏´‡∏°‡πâ ‡∏Ç‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏î‡πâ‡∏ß‡∏¢",  # emergency + urgent
        "555 ‡∏ï‡∏•‡∏Å‡∏î‡∏µ‡∏à‡∏±‡∏á ‡πÄ‡∏Æ‡∏Æ‡∏≤‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ ‡πÇ‡∏Ñ‡∏ï‡∏£‡∏Ç‡∏≥",  # slang + humor
        "‡∏Ç‡∏≠‡∏ö‡∏û‡∏£‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏ó‡πà‡∏≤‡∏ô‡∏Ñ‡∏£‡∏π‡∏°‡∏≤‡∏Å‡∏Ñ‡πà‡∏∞ ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏£‡∏á",  # formal + gratitude + education
        "‡πÅ‡∏≠‡∏î‡∏°‡∏¥‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏•‡πà‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö"  # social_media + complaint + formal
    ]
    
    print("\nüìç Single Label Analysis (Multi-class Classification)")
    print("-" * 50)
    
    single_results = []
    for text in test_texts:
        result = analyzer.analyze_single_label(text)
        single_results.append(result)
        
        print(f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text}")
        print(f"‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: {result['label']} (‡∏Å‡∏•‡∏∏‡πà‡∏°: {result['group']})")
        print(f"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {result['confidence']}")
        print(f"‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏´‡∏•‡∏±‡∏Å: {result['context']['primary_context']}")
        print(f"‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£: {result['context']['formality_level']}")
        print(f"‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏™‡∏±‡∏á‡∏Ñ‡∏°: {result['context']['social_setting']}")
        print(f"‡πÇ‡∏ó‡∏ô‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: {result['context']['emotional_tone']}")
        print(f"‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ: {result['scores']}")
        print("-" * 30)
    
    print("\nüìç Multi-Label Analysis (Multi-label Classification)")
    print("-" * 50)
    
    multi_results = []
    for text in test_texts:
        result = analyzer.analyze_multi_label(text, threshold=0.3)
        multi_results.append(result)
        
        print(f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text}")
        print(f"‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: {result['labels']} (‡∏Å‡∏•‡∏∏‡πà‡∏°: {result['groups']})")
        print(f"‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏´‡∏•‡∏±‡∏Å: {result['context']['primary_context']}")
        print(f"‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£: {result['context']['formality_level']}")
        print(f"‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏™‡∏±‡∏á‡∏Ñ‡∏°: {result['context']['social_setting']}")
        print(f"‡πÇ‡∏ó‡∏ô‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: {result['context']['emotional_tone']}")
        print(f"‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {result['scores']}")
        print("-" * 30)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
    print("\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
    print("-" * 50)
    
    single_stats = analyzer.get_emotion_statistics(single_results)
    multi_stats = analyzer.get_emotion_statistics(multi_results)
    
    print("Single Label:")
    print(f"  - ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö: {single_stats['emotion_counts']}")
    print(f"  - ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: {single_stats['group_counts']}")
    print(f"  - ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {single_stats['avg_confidence']}")
    print(f"  - ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏´‡∏•‡∏±‡∏Å: {single_stats['context_stats']['primary_context_counts']}")
    print(f"  - ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£: {single_stats['context_stats']['formality_level_counts']}")
    print(f"  - Insights: {single_stats['context_insights']}")
    
    print("\nMulti Label:")
    print(f"  - ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö: {multi_stats['emotion_counts']}")
    print(f"  - ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: {multi_stats['group_counts']}")
    print(f"  - ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {multi_stats['avg_confidence']}")
    print(f"  - ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏´‡∏•‡∏±‡∏Å: {multi_stats['context_stats']['primary_context_counts']}")
    print(f"  - ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£: {multi_stats['context_stats']['formality_level_counts']}")
    print(f"  - Insights: {multi_stats['context_insights']}")
    
    print("\nüìù ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Training")
    print("-" * 50)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• training
    training_examples = []
    
    # Single label examples
    training_examples.append(
        create_training_data_format("‡πÇ‡∏Å‡∏£‡∏ò‡∏à‡∏ô‡∏Ç‡∏≥‡∏≠‡∏∞‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï!", "‡πÇ‡∏Å‡∏£‡∏ò", "classification")
    )
    
    # Multi-label examples
    training_examples.append(
        create_training_data_format("‡πÇ‡∏Å‡∏£‡∏ò‡∏à‡∏ô‡∏Ç‡∏≥‡∏≠‡∏∞‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï!", ["‡πÇ‡∏Å‡∏£‡∏ò", "‡∏Ç‡∏≥‡∏Ç‡∏±‡∏ô"], "classification")
    )
    
    # Instruction format for LLM
    training_examples.append(
        create_training_data_format("‡∏õ‡∏£‡∏∞‡∏ä‡∏î‡∏´‡∏ô‡∏±‡∏Å‡∏°‡∏≤‡∏Å‡∏à‡∏ô‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÅ‡∏¢‡πà", ["‡∏õ‡∏£‡∏∞‡∏ä‡∏î", "‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à"], "instruction")
    )
    
    for i, example in enumerate(training_examples):
        print(f"‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á {i+1}:")
        print(json.dumps(example, ensure_ascii=False, indent=2))
        print()
    
    print("\nüîç ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ö‡∏£‡∏¥‡∏ö‡∏ó-‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå")
    print("-" * 60)
    
    # ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    all_results = single_results + multi_results
    
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå
    correlation = analyze_context_emotion_correlation(all_results)
    
    print("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå:")
    for context, emotions in correlation.items():
        print(f"\n{context}:")
        for emotion, percentage in emotions.items():
            print(f"  - {emotion}: {percentage}%")
    
    print("\nüí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£")
    print("-" * 60)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
    sample_texts = [
        "‡πÇ‡∏Ñ‡∏ï‡∏£‡∏´‡πà‡∏ß‡∏¢‡πÅ‡∏ï‡∏Å‡πÄ‡∏•‡∏¢ ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏ã‡πá‡∏á‡∏°‡∏≤‡∏Å",  # ‡∏™‡πÅ‡∏•‡∏á + ‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
        "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö"  # ‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£ + ‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏á‡∏≤‡∏ô
    ]
    
    for text in sample_texts:
        recommendations = get_context_recommendations(text, analyzer)
        
        print(f"\n‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text}")
        print(f"‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏´‡∏•‡∏±‡∏Å: {recommendations['current_analysis']['context']['primary_context']}")
        
        if recommendations['context_warnings']:
            print("‚ö†Ô∏è ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô:")
            for warning in recommendations['context_warnings']:
                print(f"  - {warning}")
        
        if recommendations['suggestions']:
            print("üìù ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:")
            for suggestion in recommendations['suggestions']:
                print(f"  - {suggestion}")
        
        if recommendations['improvement_tips']:
            print("üí° ‡πÄ‡∏ó‡∏¥‡∏õ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á:")
            for tip in recommendations['improvement_tips']:
                print(f"  - {tip}")

    print("\nüéØ ‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°")
    print("-" * 60)
    print("‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏£‡∏¥‡∏ö‡∏ó 15+ ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó:")
    print("  - ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£ (formal, informal, slang)")
    print("  - ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (personal, intimate, friendly)")
    print("  - ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏±‡∏á‡∏Ñ‡∏° (social_media, news_media, review)")
    print("  - ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå (complaint, praise, question)")
    print("  - ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå (emergency, celebration, condolence)")
    print("  - ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ß‡∏±‡∏í‡∏ô‡∏ò‡∏£‡∏£‡∏° (religious, traditional, modern)")
    print("  - ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏†‡∏π‡∏°‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå (central, northern, southern, northeastern)")
    print("  - ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏≠‡∏≤‡∏¢‡∏∏/‡∏£‡∏∏‡πà‡∏ô (gen_z, millennial, gen_x)")
    print("  - ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤‡∏ä‡∏µ‡∏û (business, education, healthcare, government)")
    print("\n‚úÖ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£")
    print("‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå")
    print("‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ö‡∏ö single-label ‡πÅ‡∏•‡∏∞ multi-label")
    print("‚úÖ ‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å")
    print("‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• training ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ")
    print("‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö batch ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å")
    print("‚úÖ ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
    print("‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≤‡∏ò‡∏¥‡∏ï‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°")


if __name__ == "__main__":
    demo_detailed_sentiment_analysis()
