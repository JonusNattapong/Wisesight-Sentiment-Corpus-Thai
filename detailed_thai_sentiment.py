#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Detailed Thai Sentiment Analysis System
‡∏£‡∏∞‡∏ö‡∏ö sentiment analysis ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö multi-class ‡πÅ‡∏•‡∏∞ multi-label classification
"""

import json
import re
import random
from typing import List, Dict, Any, Optional, Union, Tuple
from datetime import datetime
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

# === EMOTION LABEL SCHEMA ===
EMOTION_LABELS = [
    # Positive
    "‡∏î‡∏µ‡πÉ‡∏à", "‡∏ä‡∏≠‡∏ö", "‡∏ã‡∏∂‡πâ‡∏á‡πÉ‡∏à", "‡∏û‡∏≠‡πÉ‡∏à", "‡∏£‡∏±‡∏Å",
    
    # Negative  
    "‡πÇ‡∏Å‡∏£‡∏ò", "‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à", "‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á", "‡∏£‡∏≥‡∏Ñ‡∏≤‡∏ç", "‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î", "‡∏Å‡∏•‡∏±‡∏ß", "‡∏≠‡∏∂‡∏î‡∏≠‡∏±‡∏î", "‡∏ï‡∏Å‡πÉ‡∏à",
    
    # Neutral
    "‡πÄ‡∏â‡∏¢ ‡πÜ", "‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏≠‡∏∞‡πÑ‡∏£", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£",
    
    # Others (Complex emotions)
    "‡∏õ‡∏£‡∏∞‡∏ä‡∏î", "‡∏Ç‡∏≥‡∏Ç‡∏±‡∏ô", "‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ", "‡∏™‡∏±‡∏ö‡∏™‡∏ô"
]

# Emotion grouping
EMOTION_GROUPS = {
    "Positive": ["‡∏î‡∏µ‡πÉ‡∏à", "‡∏ä‡∏≠‡∏ö", "‡∏ã‡∏∂‡πâ‡∏á‡πÉ‡∏à", "‡∏û‡∏≠‡πÉ‡∏à", "‡∏£‡∏±‡∏Å"],
    "Negative": ["‡πÇ‡∏Å‡∏£‡∏ò", "‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à", "‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á", "‡∏£‡∏≥‡∏Ñ‡∏≤‡∏ç", "‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î", "‡∏Å‡∏•‡∏±‡∏ß", "‡∏≠‡∏∂‡∏î‡∏≠‡∏±‡∏î", "‡∏ï‡∏Å‡πÉ‡∏à"],
    "Neutral": ["‡πÄ‡∏â‡∏¢ ‡πÜ", "‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏≠‡∏∞‡πÑ‡∏£", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£"],
    "Others": ["‡∏õ‡∏£‡∏∞‡∏ä‡∏î", "‡∏Ç‡∏≥‡∏Ç‡∏±‡∏ô", "‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ", "‡∏™‡∏±‡∏ö‡∏™‡∏ô"]
}

# Reverse mapping for quick lookup
LABEL_TO_GROUP = {}
for group, labels in EMOTION_GROUPS.items():
    for label in labels:
        LABEL_TO_GROUP[label] = group

class ThaiEmotionPatterns:
    """‡∏Ñ‡∏•‡∏≤‡∏™ pattern matching ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"""
    
    def __init__(self):
        self.emotion_patterns = self._build_emotion_patterns()
        self.intensity_patterns = self._build_intensity_patterns()
        self.context_patterns = self._build_context_patterns()
    
    def _build_emotion_patterns(self) -> Dict[str, Dict[str, Any]]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á patterns ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"""
        return {
            # === POSITIVE EMOTIONS ===
            "‡∏î‡∏µ‡πÉ‡∏à": {
                "keywords": ["‡∏î‡∏µ‡πÉ‡∏à", "‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç", "‡πÅ‡∏Æ‡∏õ‡∏õ‡∏µ‡πâ", "‡∏õ‡∏•‡∏∑‡πâ‡∏°", "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ", "‡πÄ‡∏Æ‡∏á", "‡πÄ‡∏¢‡πâ", "‡πÇ‡∏¢‡πà", "‡πÄ‡∏à‡πã‡∏á", "‡∏î‡∏µ‡πà‡πÉ‡∏à"],
                "patterns": [r"‡∏î‡∏µ\s*‡πÉ‡∏à", r"‡∏õ‡∏•‡∏∑‡πâ‡∏°", r"‡πÄ‡∏Æ‡∏á\s*‡∏ã‡∏∞", r"‡πÅ‡∏Æ‡∏õ‡∏õ‡∏µ‡πâ", r"‡πÄ‡∏¢‡πâ.*", r"‡πÇ‡∏¢‡πà.*"],
                "emojis": ["üòä", "üòÑ", "ü§ó", "üòç", "ü•∞", "üòò", "üòÜ", "ü§©"],
                "score_range": (0.6, 1.0)
            },
            
            "‡∏ä‡∏≠‡∏ö": {
                "keywords": ["‡∏ä‡∏≠‡∏ö", "‡∏£‡∏±‡∏Å", "‡∏ñ‡∏π‡∏Å‡πÉ‡∏à", "‡πÇ‡∏õ‡∏£‡∏î", "‡∏õ‡∏•‡∏∑‡πâ‡∏°", "‡∏™‡∏ô‡πÉ‡∏à", "‡∏≠‡∏¥‡∏ô", "‡πÄ‡∏Ñ‡∏•‡∏¥‡πâ‡∏°"],
                "patterns": [r"‡∏ä‡∏≠‡∏ö.*‡∏°‡∏≤‡∏Å", r"‡∏£‡∏±‡∏Å.*‡πÄ‡∏•‡∏¢", r"‡∏ñ‡∏π‡∏Å‡πÉ‡∏à", r"‡πÇ‡∏õ‡∏£‡∏î.*", r"‡∏™‡∏ô‡πÉ‡∏à.*‡∏°‡∏≤‡∏Å"],
                "emojis": ["‚ù§Ô∏è", "üíï", "üòç", "ü•∞", "üòò", "üíñ", "üíù"],
                "score_range": (0.5, 0.9)
            },
            
            "‡∏ã‡∏∂‡πâ‡∏á‡πÉ‡∏à": {
                "keywords": ["‡∏ã‡∏∂‡πâ‡∏á", "‡∏ã‡∏∂‡πâ‡∏á‡πÉ‡∏à", "‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏ã‡∏∂‡∏°", "‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à", "‡∏ã‡∏≤‡∏ö‡∏ã‡∏∂‡πâ‡∏á", "‡∏ï‡∏∑‡πâ‡∏ô‡∏ï‡∏±‡∏ô", "‡∏ã‡∏∑‡πà‡∏ô‡πÉ‡∏™"],
                "patterns": [r"‡∏ã‡∏∂‡πâ‡∏á.*‡πÉ‡∏à", r"‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à", r"‡∏ô‡πâ‡∏≥‡∏ï‡∏≤.*‡∏ã‡∏∂‡∏°", r"‡∏ã‡∏≤‡∏ö‡∏ã‡∏∂‡πâ‡∏á"],
                "emojis": ["üò≠", "ü•∫", "üò¢", "ü§ß", "üíû"],
                "score_range": (0.4, 0.8)
            },
            
            "‡∏û‡∏≠‡πÉ‡∏à": {
                "keywords": ["‡∏û‡∏≠‡πÉ‡∏à", "‡πÇ‡∏≠‡πÄ‡∏Ñ", "‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ", "‡∏õ‡∏Å‡∏ï‡∏¥‡∏î‡∏µ", "‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏£", "‡∏á‡∏≤‡∏°", "‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢"],
                "patterns": [r"‡∏û‡∏≠‡πÉ‡∏à", r"‡πÇ‡∏≠‡πÄ‡∏Ñ.*", r"‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ", r"‡∏õ‡∏Å‡∏ï‡∏¥‡∏î‡∏µ", r"‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢"],
                "emojis": ["üëç", "üëå", "üòå", "üôÇ"],
                "score_range": (0.2, 0.6)
            },
            
            "‡∏£‡∏±‡∏Å": {
                "keywords": ["‡∏£‡∏±‡∏Å", "‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å", "‡πÅ‡∏û‡∏á", "‡πÄ‡∏•‡∏¥‡∏ü", "love", "‡∏Æ‡∏±‡∏Å‡πÜ", "‡∏Æ‡∏±‡∏Å", "‡∏£‡∏±‡∏Å‡∏°‡∏≤‡∏Å"],
                "patterns": [r"‡∏£‡∏±‡∏Å.*‡∏°‡∏≤‡∏Å", r"‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å", r"‡πÄ‡∏•‡∏¥‡∏ü.*", r"love.*", r"‡∏Æ‡∏±‡∏Å.*"],
                "emojis": ["‚ù§Ô∏è", "üíï", "üíñ", "üíù", "üòç", "ü•∞", "üòò"],
                "score_range": (0.7, 1.0)
            },
            
            # === NEGATIVE EMOTIONS ===
            "‡πÇ‡∏Å‡∏£‡∏ò": {
                "keywords": ["‡πÇ‡∏Å‡∏£‡∏ò", "‡∏â‡∏∏‡∏ô", "‡πÇ‡∏°‡πÇ‡∏´", "‡πÅ‡∏Ñ‡πâ‡∏ô", "‡∏Ç‡∏∏‡πà‡∏ô‡∏Ç‡πâ‡∏≠‡∏á", "‡πÄ‡∏î‡∏∑‡∏≠‡∏î", "‡∏ö‡πâ‡∏≤", "‡∏´‡πà‡∏ß‡∏¢‡πÅ‡∏ï‡∏Å", "‡πÅ‡∏¢‡πà", "‡∏á‡∏µ‡πà‡πÄ‡∏á‡πà‡∏≤"],
                "patterns": [r"‡πÇ‡∏Å‡∏£‡∏ò.*‡∏°‡∏≤‡∏Å", r"‡∏â‡∏∏‡∏ô.*‡∏Ç‡∏≤‡∏î", r"‡πÇ‡∏°‡πÇ‡∏´", r"‡πÅ‡∏Ñ‡πâ‡∏ô.*", r"‡∏´‡πà‡∏ß‡∏¢.*‡πÅ‡∏ï‡∏Å", r"‡∏ö‡πâ‡∏≤.*", r"‡πÅ‡∏¢‡πà.*‡∏°‡∏≤‡∏Å"],
                "emojis": ["üò†", "üò°", "ü§¨", "üëø", "üí¢", "üò§"],
                "score_range": (-1.0, -0.6)
            },
            
            "‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à": {
                "keywords": ["‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à", "‡πÄ‡∏®‡∏£‡πâ‡∏≤", "‡πÉ‡∏à‡∏´‡∏≤‡∏¢", "‡∏õ‡∏ß‡∏î‡πÉ‡∏à", "‡πÄ‡∏®‡∏£‡πâ‡∏≤‡πÇ‡∏®‡∏Å", "‡πÇ‡∏®‡∏Å‡πÄ‡∏®‡∏£‡πâ‡∏≤", "‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏≤‡∏¢", "‡∏ô‡πà‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à"],
                "patterns": [r"‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à", r"‡πÄ‡∏®‡∏£‡πâ‡∏≤.*‡∏°‡∏≤‡∏Å", r"‡πÉ‡∏à‡∏´‡∏≤‡∏¢", r"‡∏õ‡∏ß‡∏î‡πÉ‡∏à", r"‡πÄ‡∏®‡∏£‡πâ‡∏≤‡πÇ‡∏®‡∏Å"],
                "emojis": ["üò¢", "üò≠", "üòû", "‚òπÔ∏è", "üòî", "üíî"],
                "score_range": (-0.8, -0.4)
            },
            
            "‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á": {
                "keywords": ["‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á", "‡∏´‡∏ß‡∏±‡∏á‡πÄ‡∏Å‡∏¥‡∏ô", "‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á", "‡∏ó‡πâ‡∏≠", "‡∏´‡∏°‡∏î‡∏´‡∏ß‡∏±‡∏á", "‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏î‡∏±‡∏á‡πÉ‡∏à"],
                "patterns": [r"‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á", r"‡∏´‡∏ß‡∏±‡∏á.*‡πÄ‡∏Å‡∏¥‡∏ô", r"‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á.*‡∏°‡∏≤‡∏Å", r"‡∏ó‡πâ‡∏≠.*", r"‡∏´‡∏°‡∏î‡∏´‡∏ß‡∏±‡∏á"],
                "emojis": ["üòû", "üòî", "üòì", "üò©", "üò§"],
                "score_range": (-0.7, -0.3)
            },
            
            "‡∏£‡∏≥‡∏Ñ‡∏≤‡∏ç": {
                "keywords": ["‡∏£‡∏≥‡∏Ñ‡∏≤‡∏ç", "‡∏ô‡πà‡∏≤‡∏£‡∏≥‡∏Ñ‡∏≤‡∏ç", "‡πÄ‡∏ö‡∏∑‡πà‡∏≠", "‡∏´‡∏ô‡πà‡∏≤‡∏¢", "‡πÄ‡∏ã‡πá‡∏á", "‡∏á‡πà‡∏ß‡∏á", "‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î", "‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢"],
                "patterns": [r"‡∏£‡∏≥‡∏Ñ‡∏≤‡∏ç", r"‡πÄ‡∏ö‡∏∑‡πà‡∏≠.*‡∏°‡∏≤‡∏Å", r"‡∏´‡∏ô‡πà‡∏≤‡∏¢.*", r"‡πÄ‡∏ã‡πá‡∏á.*", r"‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î.*"],
                "emojis": ["üòí", "üôÑ", "üò§", "üòë", "üò´", "üò©"],
                "score_range": (-0.6, -0.2)
            },
            
            "‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î": {
                "keywords": ["‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î", "‡∏Ç‡∏¢‡∏∞‡πÅ‡∏Ç‡∏¢‡∏á", "‡πÅ‡∏Ñ‡πâ‡∏ô", "‡πÅ‡∏Å‡∏•‡πâ‡∏á", "‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö", "‡∏ï‡πà‡∏≠‡∏ï‡πâ‡∏≤‡∏ô"],
                "patterns": [r"‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î.*‡∏°‡∏≤‡∏Å", r"‡∏Ç‡∏¢‡∏∞‡πÅ‡∏Ç‡∏¢‡∏á", r"‡πÅ‡∏Ñ‡πâ‡∏ô.*", r"‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö.*‡πÄ‡∏•‡∏¢"],
                "emojis": ["üò°", "ü§¨", "üëø", "üò†", "üí¢"],
                "score_range": (-1.0, -0.7)
            },
            
            "‡∏Å‡∏•‡∏±‡∏ß": {
                "keywords": ["‡∏Å‡∏•‡∏±‡∏ß", "‡∏´‡∏ß‡∏≤‡∏î‡∏Å‡∏•‡∏±‡∏ß", "‡∏ï‡∏Å‡πÉ‡∏à", "‡∏ß‡∏¥‡∏ï‡∏Å", "‡∏Å‡∏±‡∏á‡∏ß‡∏•", "‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î", "‡∏´‡∏ß‡∏±‡πà‡∏ô", "‡∏ï‡∏∑‡πà‡∏ô‡∏Å‡∏•‡∏±‡∏ß"],
                "patterns": [r"‡∏Å‡∏•‡∏±‡∏ß.*‡∏°‡∏≤‡∏Å", r"‡∏´‡∏ß‡∏≤‡∏î‡∏Å‡∏•‡∏±‡∏ß", r"‡∏ï‡∏Å‡πÉ‡∏à.*", r"‡∏ß‡∏¥‡∏ï‡∏Å.*", r"‡∏Å‡∏±‡∏á‡∏ß‡∏•.*"],
                "emojis": ["üò®", "üò∞", "üò±", "üòß", "ü´£", "üò≥"],
                "score_range": (-0.8, -0.3)
            },
            
            "‡∏≠‡∏∂‡∏î‡∏≠‡∏±‡∏î": {
                "keywords": ["‡∏≠‡∏∂‡∏î‡∏≠‡∏±‡∏î", "‡∏≠‡∏±‡∏ö‡∏≠‡∏≤‡∏¢", "‡πÄ‡∏Å‡πâ‡∏≠", "‡πÑ‡∏°‡πà‡∏™‡∏ö‡∏≤‡∏¢‡πÉ‡∏à", "‡∏Å‡∏î‡∏î‡∏±‡∏ô", "‡∏Ç‡∏±‡∏î‡πÉ‡∏à"],
                "patterns": [r"‡∏≠‡∏∂‡∏î‡∏≠‡∏±‡∏î", r"‡∏≠‡∏±‡∏ö‡∏≠‡∏≤‡∏¢", r"‡πÑ‡∏°‡πà‡∏™‡∏ö‡∏≤‡∏¢‡πÉ‡∏à", r"‡∏Å‡∏î‡∏î‡∏±‡∏ô", r"‡∏Ç‡∏±‡∏î‡πÉ‡∏à"],
                "emojis": ["üò£", "üòñ", "üò´", "üò§", "üò∞"],
                "score_range": (-0.6, -0.2)
            },
            
            "‡∏ï‡∏Å‡πÉ‡∏à": {
                "keywords": ["‡∏ï‡∏Å‡πÉ‡∏à", "‡∏™‡∏∞‡∏î‡∏∏‡πâ‡∏á", "‡πÇ‡∏´‡∏¢‡∏á", "‡∏ï‡∏Å‡∏ï‡∏∞‡∏•‡∏∂‡∏á", "‡∏ï‡∏∞‡∏•‡∏∂‡∏á", "‡∏´‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏ß"],
                "patterns": [r"‡∏ï‡∏Å‡πÉ‡∏à.*‡∏°‡∏≤‡∏Å", r"‡∏™‡∏∞‡∏î‡∏∏‡πâ‡∏á", r"‡πÇ‡∏´‡∏¢‡∏á", r"‡∏ï‡∏Å‡∏ï‡∏∞‡∏•‡∏∂‡∏á", r"‡∏ï‡∏∞‡∏•‡∏∂‡∏á"],
                "emojis": ["üò±", "üò®", "üò≥", "ü´®", "üòß"],
                "score_range": (-0.5, 0.0)
            },
            
            # === NEUTRAL EMOTIONS ===
            "‡πÄ‡∏â‡∏¢ ‡πÜ": {
                "keywords": ["‡πÄ‡∏â‡∏¢", "‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤", "‡∏õ‡∏Å‡∏ï‡∏¥", "‡πÇ‡∏≠‡πÄ‡∏Ñ", "‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ", "‡∏û‡∏≠‡πÉ‡∏ä‡πâ", "‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏£"],
                "patterns": [r"‡πÄ‡∏â‡∏¢.*‡πÜ", r"‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤", r"‡∏õ‡∏Å‡∏ï‡∏¥.*", r"‡πÇ‡∏≠‡πÄ‡∏Ñ", r"‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏£"],
                "emojis": ["üòê", "üôÇ", "üò∂", "üòë"],
                "score_range": (-0.1, 0.1)
            },
            
            "‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏≠‡∏∞‡πÑ‡∏£": {
                "keywords": ["‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å", "‡∏ä‡∏≤", "‡πÄ‡∏â‡∏¢", "‡πÑ‡∏°‡πà‡∏™‡∏ô", "‡πÑ‡∏°‡πà‡πÅ‡∏Ñ‡∏£‡πå", "‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à"],
                "patterns": [r"‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å.*‡∏≠‡∏∞‡πÑ‡∏£", r"‡∏ä‡∏≤.*", r"‡πÑ‡∏°‡πà‡∏™‡∏ô.*", r"‡πÑ‡∏°‡πà‡πÅ‡∏Ñ‡∏£‡πå"],
                "emojis": ["üò∂", "üòê", "ü§∑‚Äç‚ôÄÔ∏è", "ü§∑‚Äç‚ôÇÔ∏è"],
                "score_range": (-0.05, 0.05)
            },
            
            "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£": {
                "keywords": ["‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "‡∏Ç‡πà‡∏≤‡∏ß", "‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô", "‡πÅ‡∏à‡πâ‡∏á", "‡∏ö‡∏≠‡∏Å", "‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï", "‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç"],
                "patterns": [r"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•.*", r"‡∏Ç‡πà‡∏≤‡∏ß.*", r"‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô.*", r"‡πÅ‡∏à‡πâ‡∏á.*", r"‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï.*"],
                "emojis": ["üì∞", "üìä", "üìà", "üì¢", "‚ÑπÔ∏è"],
                "score_range": (0.0, 0.0)
            },
            
            # === OTHERS (COMPLEX EMOTIONS) ===
            "‡∏õ‡∏£‡∏∞‡∏ä‡∏î": {
                "keywords": ["‡∏õ‡∏£‡∏∞‡∏ä‡∏î", "‡πÄ‡∏´‡∏ô‡πá‡∏ö‡πÅ‡∏ô‡∏°", "‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ", "‡πÅ‡∏î‡∏Å‡∏î‡∏±‡∏ô", "‡∏à‡∏¥‡∏Å‡∏Å‡∏±‡∏î", "‡∏≠‡∏µ‡∏î‡∏≠‡∏Å"],
                "patterns": [r"‡∏õ‡∏£‡∏∞‡∏ä‡∏î.*", r"‡πÄ‡∏´‡∏ô‡πá‡∏ö‡πÅ‡∏ô‡∏°", r"‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ.*", r"‡πÅ‡∏î‡∏Å‡∏î‡∏±‡∏ô", r"‡∏à‡∏¥‡∏Å‡∏Å‡∏±‡∏î"],
                "emojis": ["üòè", "üôÑ", "üòí", "üò§"],
                "score_range": (-0.4, -0.1)
            },
            
            "‡∏Ç‡∏≥‡∏Ç‡∏±‡∏ô": {
                "keywords": ["‡∏Ç‡∏≥", "‡∏ï‡∏•‡∏Å", "555", "‡∏Æ‡∏≤", "‡πÄ‡∏Æ‡∏Æ‡∏≤", "‡∏™‡∏ô‡∏∏‡∏Å", "‡πÇ‡∏•‡∏Å‡πÅ‡∏ï‡∏Å", "‡∏Ñ‡∏£‡∏∑‡πà‡∏ô‡πÄ‡∏Ñ‡∏£‡∏á"],
                "patterns": [r"‡∏Ç‡∏≥.*", r"‡∏ï‡∏•‡∏Å.*", r"555+", r"‡∏Æ‡∏≤+", r"‡πÄ‡∏Æ‡∏Æ‡∏≤", r"‡∏™‡∏ô‡∏∏‡∏Å.*"],
                "emojis": ["üòÇ", "ü§£", "üòÜ", "üòÑ", "üòÅ", "ü§™", "üòú"],
                "score_range": (0.3, 0.8)
            },
            
            "‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ": {
                "keywords": ["‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ", "‡∏õ‡∏£‡∏∞‡∏ä‡∏î", "‡πÄ‡∏´‡∏ô‡πá‡∏ö", "‡πÅ‡∏ô‡∏°", "‡∏à‡∏¥‡∏Å‡∏Å‡∏±‡∏î", "‡πÅ‡∏Å‡∏•‡πâ‡∏á"],
                "patterns": [r"‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ.*", r"‡∏õ‡∏£‡∏∞‡∏ä‡∏î.*", r"‡πÄ‡∏´‡∏ô‡πá‡∏ö.*‡πÅ‡∏ô‡∏°", r"‡∏à‡∏¥‡∏Å‡∏Å‡∏±‡∏î.*"],
                "emojis": ["üòè", "üôÑ", "üòí"],
                "score_range": (-0.5, -0.2)
            },
            
            "‡∏™‡∏±‡∏ö‡∏™‡∏ô": {
                "keywords": ["‡∏™‡∏±‡∏ö‡∏™‡∏ô", "‡∏á‡∏á", "‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ", "‡πÅ‡∏õ‡∏•‡∏Å", "‡∏â‡∏á‡∏ô", "‡∏â‡∏á‡∏ô‡∏™‡∏ô‡πÄ‡∏ó‡πà‡∏´‡πå"],
                "patterns": [r"‡∏™‡∏±‡∏ö‡∏™‡∏ô", r"‡∏á‡∏á.*", r"‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ", r"‡πÅ‡∏õ‡∏•‡∏Å.*", r"‡∏â‡∏á‡∏ô.*"],
                "emojis": ["üòï", "ü§î", "üòµ‚Äçüí´", "ü´§", "üòµ"],
                "score_range": (-0.2, 0.2)
            }
        }
    
    def _build_intensity_patterns(self) -> Dict[str, List[str]]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á patterns ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"""
        return {
            "high": ["‡∏°‡∏≤‡∏Å", "‡πÄ‡∏•‡∏¢", "‡∏™‡∏∏‡∏î", "‡πÅ‡∏£‡∏á", "‡∏´‡∏ô‡∏±‡∏Å", "‡πÇ‡∏Ñ‡∏ï‡∏£", "‡πÅ‡∏™‡∏ô", "‡∏™‡∏≤‡∏´‡∏±‡∏™", "‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡πâ‡∏≤", "‡∏à‡∏£‡∏¥‡∏á‡πÜ"],
            "medium": ["‡∏û‡∏≠", "‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á", "‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á", "‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ", "‡πÇ‡∏≠‡πÄ‡∏Ñ"],
            "low": ["‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢", "‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢", "‡πÄ‡∏ö‡∏≤‡πÜ", "‡∏ô‡∏¥‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß", "‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏Å"]
        }
    
    def _build_context_patterns(self) -> Dict[str, List[str]]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á patterns ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤"""
        return {
            "formal": ["‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏Ñ‡πà‡∏∞", "‡∏Ñ‡∏∞", "‡∏Ç‡∏≠", "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤", "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ", "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì"],
            "informal": ["‡∏ô‡∏∞", "‡πÄ‡∏ô‡∏≠‡∏∞", "‡∏≠‡∏∞", "‡πÄ‡∏≠‡πâ‡∏¢", "‡πÄ‡∏≠‡∏≠", "‡∏Ç‡∏≠‡∏á", "555", "‡∏Æ‡∏≤"],
            "slang": ["‡πÇ‡∏Ñ‡∏ï‡∏£", "‡πÄ‡∏ü‡∏µ‡πâ‡∏¢‡∏ß", "‡πÄ‡∏ó‡∏û", "‡πÅ‡∏°‡πà‡∏á", "‡∏Ñ‡∏ß‡∏¢", "‡∏ö‡∏¥‡∏ô", "‡πÄ‡∏ü‡∏µ‡πâ‡∏¢‡∏°"],
            "personal": ["‡∏Å‡∏π", "‡∏°‡∏∂‡∏á", "‡πÄ‡∏£‡∏≤", "‡∏â‡∏±‡∏ô", "‡∏Ñ‡∏¥‡∏î", "‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å"]
        }

class DetailedThaiSentimentAnalyzer:
    """‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"""
    
    def __init__(self):
        self.patterns = ThaiEmotionPatterns()
        self.multi_label_threshold = 0.3  # threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô multi-label
        
    def _clean_text(self, text: str) -> str:
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        if not text:
            return ""
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏•‡πá‡∏Å
        text = text.lower()
        
        # ‡∏•‡∏ö URL
        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
        
        # ‡∏•‡∏ö mentions ‡πÅ‡∏•‡∏∞ hashtags ‡πÉ‡∏ô social media
        text = re.sub(r'[@#]\w+', '', text)
        
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏Å‡∏¥‡∏ô
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def _extract_emojis(self, text: str) -> List[str]:
        """‡∏î‡∏∂‡∏á emojis ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        emoji_pattern = re.compile(
            "["
            "\U0001F600-\U0001F64F"  # emoticons
            "\U0001F300-\U0001F5FF"  # symbols & pictographs
            "\U0001F680-\U0001F6FF"  # transport & map
            "\U0001F1E0-\U0001F1FF"  # flags
            "\U00002702-\U000027B0"
            "\U000024C2-\U0001F251"
            "]+", flags=re.UNICODE
        )
        return emoji_pattern.findall(text)
    
    def _calculate_emotion_scores(self, text: str) -> Dict[str, float]:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"""
        clean_text = self._clean_text(text)
        emojis = self._extract_emojis(text)
        emotion_scores = defaultdict(float)
        
        for emotion, config in self.patterns.emotion_patterns.items():
            score = 0.0
            
            # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
            for keyword in config["keywords"]:
                if keyword in clean_text:
                    score += 1.0
            
            # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å patterns (regex)
            for pattern in config.get("patterns", []):
                matches = re.findall(pattern, clean_text)
                score += len(matches) * 1.5
            
            # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å emojis
            for emoji in emojis:
                if emoji in config.get("emojis", []):
                    score += 2.0
            
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô
            intensity_bonus = self._calculate_intensity_bonus(clean_text)
            score *= (1 + intensity_bonus)
            
            emotion_scores[emotion] = min(score, 5.0)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
        
        return dict(emotion_scores)
    
    def _calculate_intensity_bonus(self, text: str) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì bonus ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏≠‡∏Å"""
        bonus = 0.0
        
        for intensity, words in self.patterns.intensity_patterns.items():
            for word in words:
                if word in text:
                    if intensity == "high":
                        bonus += 0.5
                    elif intensity == "medium":
                        bonus += 0.2
                    elif intensity == "low":
                        bonus += 0.1
        
        return min(bonus, 1.0)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î bonus ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    
    def _determine_context(self, text: str) -> str:
        """‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤"""
        clean_text = self._clean_text(text)
        context_scores = defaultdict(int)
        
        for context, words in self.patterns.context_patterns.items():
            for word in words:
                if word in clean_text:
                    context_scores[context] += 1
        
        if not context_scores:
            return "neutral"
        
        return max(context_scores, key=context_scores.get)
    
    def _normalize_scores(self, scores: Dict[str, float]) -> Dict[str, float]:
        """normalize ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 0-1"""
        if not scores:
            return {}
        
        max_score = max(scores.values())
        if max_score == 0:
            return scores
        
        return {emotion: score / max_score for emotion, score in scores.items()}
    
    def analyze_single_label(self, text: str) -> Dict[str, Any]:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡πÅ‡∏ö‡∏ö single label (multi-class classification)"""
        if not text or not text.strip():
            return {
                "text": text,
                "label": "‡πÄ‡∏â‡∏¢ ‡πÜ",
                "group": "Neutral",
                "confidence": 0.0,
                "scores": {},
                "context": "neutral",
                "analysis_type": "single_label"
            }
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
        raw_scores = self._calculate_emotion_scores(text)
        normalized_scores = self._normalize_scores(raw_scores)
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
        if not normalized_scores:
            predicted_label = "‡πÄ‡∏â‡∏¢ ‡πÜ"
            confidence = 0.0
        else:
            predicted_label = max(normalized_scores, key=normalized_scores.get)
            confidence = normalized_scores[predicted_label]
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
        group = LABEL_TO_GROUP.get(predicted_label, "Unknown")
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ö‡∏£‡∏¥‡∏ö‡∏ó
        context = self._determine_context(text)
        
        return {
            "text": text,
            "label": predicted_label,
            "group": group,
            "confidence": round(confidence, 3),
            "scores": {k: round(v, 3) for k, v in normalized_scores.items()},
            "context": context,
            "analysis_type": "single_label",
            "timestamp": datetime.now().isoformat()
        }
    
    def analyze_multi_label(self, text: str, threshold: float = None) -> Dict[str, Any]:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡πÅ‡∏ö‡∏ö multi-label classification"""
        if threshold is None:
            threshold = self.multi_label_threshold
        
        if not text or not text.strip():
            return {
                "text": text,
                "labels": ["‡πÄ‡∏â‡∏¢ ‡πÜ"],
                "groups": ["Neutral"],
                "scores": {},
                "context": "neutral",
                "analysis_type": "multi_label",
                "threshold": threshold
            }
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
        raw_scores = self._calculate_emotion_scores(text)
        normalized_scores = self._normalize_scores(raw_scores)
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô threshold
        predicted_labels = []
        for emotion, score in normalized_scores.items():
            if score >= threshold:
                predicted_labels.append(emotion)
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÉ‡∏î‡πÄ‡∏Å‡∏¥‡∏ô threshold ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
        if not predicted_labels and normalized_scores:
            predicted_labels = [max(normalized_scores, key=normalized_scores.get)]
        elif not predicted_labels:
            predicted_labels = ["‡πÄ‡∏â‡∏¢ ‡πÜ"]
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
        groups = list(set(LABEL_TO_GROUP.get(label, "Unknown") for label in predicted_labels))
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ö‡∏£‡∏¥‡∏ö‡∏ó
        context = self._determine_context(text)
        
        return {
            "text": text,
            "labels": predicted_labels,
            "groups": groups,
            "scores": {k: round(v, 3) for k, v in normalized_scores.items()},
            "context": context,
            "analysis_type": "multi_label",
            "threshold": threshold,
            "timestamp": datetime.now().isoformat()
        }
    
    def analyze_batch(self, texts: List[str], multi_label: bool = False, threshold: float = None) -> List[Dict[str, Any]]:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡πÅ‡∏ö‡∏ö batch"""
        results = []
        
        for text in texts:
            if multi_label:
                result = self.analyze_multi_label(text, threshold)
            else:
                result = self.analyze_single_label(text)
            
            results.append(result)
        
        return results
    
    def get_emotion_statistics(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå"""
        if not results:
            return {}
        
        stats = {
            "total_texts": len(results),
            "analysis_type": results[0].get("analysis_type", "unknown"),
            "emotion_counts": defaultdict(int),
            "group_counts": defaultdict(int),
            "context_counts": defaultdict(int),
            "avg_confidence": 0.0
        }
        
        total_confidence = 0.0
        
        for result in results:
            # ‡∏ô‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
            if "label" in result:  # single label
                stats["emotion_counts"][result["label"]] += 1
                stats["group_counts"][result["group"]] += 1
                total_confidence += result.get("confidence", 0.0)
            elif "labels" in result:  # multi label
                for label in result["labels"]:
                    stats["emotion_counts"][label] += 1
                for group in result["groups"]:
                    stats["group_counts"][group] += 1
                # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö multi-label ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÄ‡∏õ‡πá‡∏ô confidence
                if result["scores"]:
                    total_confidence += max(result["scores"].values())
            
            # ‡∏ô‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó
            context = result.get("context", "unknown")
            stats["context_counts"][context] += 1
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì confidence ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
        if stats["total_texts"] > 0:
            stats["avg_confidence"] = round(total_confidence / stats["total_texts"], 3)
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å defaultdict ‡πÄ‡∏õ‡πá‡∏ô dict ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
        stats["emotion_counts"] = dict(stats["emotion_counts"])
        stats["group_counts"] = dict(stats["group_counts"])
        stats["context_counts"] = dict(stats["context_counts"])
        
        return stats

# === UTILITY FUNCTIONS ===

def create_training_data_format(
    text: str, 
    labels: Union[str, List[str]], 
    format_type: str = "classification"
) -> Dict[str, Any]:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ train model"""
    
    if format_type == "classification":
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö traditional ML models (BERT, RoBERTa, etc.)
        if isinstance(labels, str):
            return {
                "text": text,
                "label": labels,
                "label_id": EMOTION_LABELS.index(labels) if labels in EMOTION_LABELS else 0
            }
        else:
            # Multi-label: ‡∏™‡∏£‡πâ‡∏≤‡∏á binary vector
            label_vector = [0] * len(EMOTION_LABELS)
            for label in labels:
                if label in EMOTION_LABELS:
                    label_vector[EMOTION_LABELS.index(label)] = 1
            
            return {
                "text": text,
                "labels": labels,
                "label_vector": label_vector
            }
    
    elif format_type == "instruction":
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM fine-tuning
        if isinstance(labels, str):
            instruction = "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"
            output = labels
        else:
            instruction = "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå)"
            output = ", ".join(labels)
        
        return {
            "instruction": instruction,
            "input": text,
            "output": output
        }
    
    else:
        raise ValueError(f"Unsupported format_type: {format_type}")

def save_training_data(
    data: List[Dict[str, Any]], 
    output_path: str, 
    format_type: str = "jsonl"
) -> str:
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£ train"""
    
    if format_type == "jsonl":
        with open(output_path, 'w', encoding='utf-8') as f:
            for item in data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    elif format_type == "json":
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    else:
        raise ValueError(f"Unsupported format_type: {format_type}")
    
    return output_path

def demo_detailed_sentiment_analysis():
    """Demo ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡∏∞‡∏ö‡∏ö sentiment analysis ‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"""
    
    print("üéØ Demo: Detailed Thai Sentiment Analysis")
    print("=" * 60)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á analyzer
    analyzer = DetailedThaiSentimentAnalyzer()
    
    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    test_texts = [
        "‡πÇ‡∏Å‡∏£‡∏ò‡∏à‡∏ô‡∏Ç‡∏≥‡∏≠‡∏∞‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï! ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏î‡πâ‡∏ß‡∏¢ 555",
        "‡∏õ‡∏£‡∏∞‡∏ä‡∏î‡∏´‡∏ô‡∏±‡∏Å‡∏°‡∏≤‡∏Å‡∏à‡∏ô‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÅ‡∏¢‡πà ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πÄ‡∏•‡∏¢",
        "‡∏°‡∏±‡∏ô‡∏Å‡πá‡πÇ‡∏≠‡πÄ‡∏Ñ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏™‡∏∏‡∏î ‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡πÑ‡∏ß‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ",
        "‡∏î‡∏µ‡πÉ‡∏à‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢! ‡∏£‡∏±‡∏Å‡∏°‡∏≤‡∏Å‡πÜ ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ô‡∏∞‡∏Ñ‡∏∞ üòç‚ù§Ô∏è",
        "‡∏´‡πà‡∏ß‡∏¢‡πÅ‡∏ï‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÇ‡∏ó‡∏£‡πÑ‡∏õ‡πÅ‡∏à‡πâ‡∏á‡∏Å‡πá‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ô‡∏µ‡πâ",
        "‡∏á‡∏á‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ ‡∏™‡∏±‡∏ö‡∏™‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ü§î",
        "‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô ‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏õ‡∏Å‡∏ï‡∏¥‡∏î‡∏µ"
    ]
    
    print("\nüìç Single Label Analysis (Multi-class Classification)")
    print("-" * 50)
    
    single_results = []
    for text in test_texts:
        result = analyzer.analyze_single_label(text)
        single_results.append(result)
        
        print(f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text}")
        print(f"‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: {result['label']} (‡∏Å‡∏•‡∏∏‡πà‡∏°: {result['group']})")
        print(f"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {result['confidence']}")
        print(f"‡∏ö‡∏£‡∏¥‡∏ö‡∏ó: {result['context']}")
        print(f"‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ: {result['scores']}")
        print("-" * 30)
    
    print("\nüìç Multi-Label Analysis (Multi-label Classification)")
    print("-" * 50)
    
    multi_results = []
    for text in test_texts:
        result = analyzer.analyze_multi_label(text, threshold=0.3)
        multi_results.append(result)
        
        print(f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text}")
        print(f"‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: {result['labels']} (‡∏Å‡∏•‡∏∏‡πà‡∏°: {result['groups']})")
        print(f"‡∏ö‡∏£‡∏¥‡∏ö‡∏ó: {result['context']}")
        print(f"‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {result['scores']}")
        print("-" * 30)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
    print("\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
    print("-" * 50)
    
    single_stats = analyzer.get_emotion_statistics(single_results)
    multi_stats = analyzer.get_emotion_statistics(multi_results)
    
    print("Single Label:")
    print(f"  - ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö: {single_stats['emotion_counts']}")
    print(f"  - ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: {single_stats['group_counts']}")
    print(f"  - ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {single_stats['avg_confidence']}")
    
    print("\nMulti Label:")
    print(f"  - ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö: {multi_stats['emotion_counts']}")
    print(f"  - ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: {multi_stats['group_counts']}")
    print(f"  - ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {multi_stats['avg_confidence']}")
    
    print("\nüìù ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Training")
    print("-" * 50)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• training
    training_examples = []
    
    # Single label examples
    training_examples.append(
        create_training_data_format("‡πÇ‡∏Å‡∏£‡∏ò‡∏à‡∏ô‡∏Ç‡∏≥‡∏≠‡∏∞‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï!", "‡πÇ‡∏Å‡∏£‡∏ò", "classification")
    )
    
    # Multi-label examples
    training_examples.append(
        create_training_data_format("‡πÇ‡∏Å‡∏£‡∏ò‡∏à‡∏ô‡∏Ç‡∏≥‡∏≠‡∏∞‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï!", ["‡πÇ‡∏Å‡∏£‡∏ò", "‡∏Ç‡∏≥‡∏Ç‡∏±‡∏ô"], "classification")
    )
    
    # Instruction format for LLM
    training_examples.append(
        create_training_data_format("‡∏õ‡∏£‡∏∞‡∏ä‡∏î‡∏´‡∏ô‡∏±‡∏Å‡∏°‡∏≤‡∏Å‡∏à‡∏ô‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÅ‡∏¢‡πà", ["‡∏õ‡∏£‡∏∞‡∏ä‡∏î", "‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à"], "instruction")
    )
    
    for i, example in enumerate(training_examples):
        print(f"‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á {i+1}:")
        print(json.dumps(example, ensure_ascii=False, indent=2))
        print()

if __name__ == "__main__":
    demo_detailed_sentiment_analysis()
