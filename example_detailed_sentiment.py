#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Example usage of Detailed Thai Sentiment Analysis System
‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡∏∞‡∏ö‡∏ö sentiment analysis ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
"""

import json
from detailed_thai_sentiment import (
    DetailedThaiSentimentAnalyzer,
    create_training_data_format,
    save_training_data,
    EMOTION_LABELS,
    EMOTION_GROUPS
)

def example_basic_usage():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô"""
    print("üöÄ Basic Usage Example")
    print("=" * 50)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á analyzer
    analyzer = DetailedThaiSentimentAnalyzer()
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡πÜ
    test_texts = [
        "‡πÇ‡∏Å‡∏£‡∏ò‡∏à‡∏ô‡∏Ç‡∏≥‡∏≠‡∏∞! ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏î‡πâ‡∏ß‡∏¢ 555",
        "‡∏î‡∏µ‡πÉ‡∏à‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ ‡∏£‡∏±‡∏Å‡πÄ‡∏ò‡∏≠‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‚ù§Ô∏èüòç",
        "‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ ‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏à‡∏£‡∏¥‡∏á‡πÜ",
        "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏õ‡∏Å‡∏ï‡∏¥‡∏î‡∏µ",
        "‡∏≠‡πà‡∏≠... ‡∏î‡∏µ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÄ‡∏ô‡∏≠‡∏∞ ‡∏õ‡∏£‡∏∞‡∏ä‡∏î‡πÄ‡∏Å‡πà‡∏á‡∏à‡∏±‡∏á üôÑ"
    ]
    
    print("\nüìç Single Label Analysis:")
    for text in test_texts:
        result = analyzer.analyze_single_label(text)
        print(f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text}")
        print(f"‚Üí ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: {result['label']} (‡∏Å‡∏•‡∏∏‡πà‡∏°: {result['group']}, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {result['confidence']})")
        print()
    
    print("\nüìç Multi-Label Analysis:")
    for text in test_texts:
        result = analyzer.analyze_multi_label(text, threshold=0.25)
        print(f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text}")
        print(f"‚Üí ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: {result['labels']} (‡∏Å‡∏•‡∏∏‡πà‡∏°: {result['groups']})")
        print()

def example_batch_processing():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö batch"""
    print("üì¶ Batch Processing Example")
    print("=" * 50)
    
    analyzer = DetailedThaiSentimentAnalyzer()
    
    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å
    sample_comments = [
        "‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ ‡∏ä‡∏≠‡∏ö‡∏°‡∏≤‡∏Å! üòç",
        "‡∏´‡πà‡∏ß‡∏¢‡πÅ‡∏ï‡∏Å‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏•‡∏¢",
        "‡πÇ‡∏≠‡πÄ‡∏Ñ ‡∏õ‡∏Å‡∏ï‡∏¥‡∏î‡∏µ ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ",
        "‡πÇ‡∏Å‡∏£‡∏ò‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ ‡πÅ‡∏ï‡πà‡∏Å‡πá‡∏Ç‡∏≥‡∏î‡∏µ 555",
        "‡πÄ‡∏®‡∏£‡πâ‡∏≤‡πÉ‡∏à‡∏°‡∏≤‡∏Å ‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏à‡∏£‡∏¥‡∏á‡πÜ üò¢",
        "‡∏õ‡∏£‡∏∞‡∏ä‡∏î‡πÄ‡∏Å‡πà‡∏á‡∏°‡∏≤‡∏Å ‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏¥‡∏® üôÑ",
        "‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå",
        "‡∏™‡∏±‡∏ö‡∏™‡∏ô‡∏°‡∏≤‡∏Å ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ü§î",
        "‡∏Å‡∏•‡∏±‡∏ß‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ ‡∏ï‡∏Å‡πÉ‡∏à‡∏à‡∏£‡∏¥‡∏á‡πÜ üò±",
        "‡∏£‡∏≥‡∏Ñ‡∏≤‡∏ç‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏ö‡∏∑‡πà‡∏≠‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ üò§"
    ]
    
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ö‡∏ö single label
    print("\nüè∑Ô∏è Single Label Results:")
    single_results = analyzer.analyze_batch(sample_comments, multi_label=False)
    
    for i, result in enumerate(single_results):
        print(f"{i+1}. {result['text']}")
        print(f"   ‚Üí {result['label']} ({result['group']}) - ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {result['confidence']}")
    
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ö‡∏ö multi-label
    print("\nüè∑Ô∏è Multi-Label Results:")
    multi_results = analyzer.analyze_batch(sample_comments, multi_label=True, threshold=0.2)
    
    for i, result in enumerate(multi_results):
        print(f"{i+1}. {result['text']}")
        print(f"   ‚Üí {result['labels']} ({result['groups']})")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
    print("\nüìä Statistics:")
    single_stats = analyzer.get_emotion_statistics(single_results)
    multi_stats = analyzer.get_emotion_statistics(multi_results)
    
    print(f"Single Label - Top emotions: {sorted(single_stats['emotion_counts'].items(), key=lambda x: x[1], reverse=True)}")
    print(f"Multi Label - Top emotions: {sorted(multi_stats['emotion_counts'].items(), key=lambda x: x[1], reverse=True)}")

def example_training_data_creation():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training model"""
    print("üéì Training Data Creation Example")
    print("=" * 50)
    
    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏° labels
    sample_data = [
        # Single label examples
        {"text": "‡∏î‡∏µ‡πÉ‡∏à‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢! ‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î", "label": "‡∏î‡∏µ‡πÉ‡∏à"},
        {"text": "‡πÇ‡∏Å‡∏£‡∏ò‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ ‡πÅ‡∏¢‡πà‡∏à‡∏£‡∏¥‡∏á‡πÜ", "label": "‡πÇ‡∏Å‡∏£‡∏ò"},
        {"text": "‡πÄ‡∏®‡∏£‡πâ‡∏≤‡πÉ‡∏à‡∏°‡∏≤‡∏Å ‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á", "label": "‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à"},
        {"text": "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô", "label": "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£"},
        
        # Multi-label examples
        {"text": "‡πÇ‡∏Å‡∏£‡∏ò‡∏à‡∏ô‡∏Ç‡∏≥‡∏≠‡∏∞! ‡πÅ‡∏õ‡∏•‡∏Å‡∏î‡∏µ 555", "labels": ["‡πÇ‡∏Å‡∏£‡∏ò", "‡∏Ç‡∏≥‡∏Ç‡∏±‡∏ô"]},
        {"text": "‡∏õ‡∏£‡∏∞‡∏ä‡∏î‡πÄ‡∏Å‡πà‡∏á‡∏°‡∏≤‡∏Å ‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ‡∏à‡∏ô‡πÄ‡∏®‡∏£‡πâ‡∏≤", "labels": ["‡∏õ‡∏£‡∏∞‡∏ä‡∏î", "‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à"]},
        {"text": "‡∏ä‡∏≠‡∏ö‡∏°‡∏≤‡∏Å ‡πÅ‡∏ï‡πà‡∏Å‡πá‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢", "labels": ["‡∏ä‡∏≠‡∏ö", "‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á"]},
        {"text": "‡∏™‡∏±‡∏ö‡∏™‡∏ô‡∏°‡∏≤‡∏Å ‡∏Å‡∏•‡∏±‡∏ß‡∏î‡πâ‡∏ß‡∏¢", "labels": ["‡∏™‡∏±‡∏ö‡∏™‡∏ô", "‡∏Å‡∏•‡∏±‡∏ß"]}
    ]
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö traditional ML models
    print("\nü§ñ For Traditional ML Models (BERT, RoBERTa, etc.):")
    ml_training_data = []
    
    for item in sample_data:
        if "label" in item:  # Single label
            formatted = create_training_data_format(item["text"], item["label"], "classification")
        else:  # Multi label
            formatted = create_training_data_format(item["text"], item["labels"], "classification")
        
        ml_training_data.append(formatted)
        print(json.dumps(formatted, ensure_ascii=False, indent=2))
        print()
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM fine-tuning
    print("\nüß† For LLM Fine-tuning:")
    llm_training_data = []
    
    for item in sample_data:
        if "label" in item:  # Single label
            formatted = create_training_data_format(item["text"], item["label"], "instruction")
        else:  # Multi label
            formatted = create_training_data_format(item["text"], item["labels"], "instruction")
        
        llm_training_data.append(formatted)
        print(json.dumps(formatted, ensure_ascii=False, indent=2))
        print()
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    save_training_data(ml_training_data, "ml_training_data.jsonl", "jsonl")
    save_training_data(llm_training_data, "llm_training_data.jsonl", "jsonl")
    
    print("‚úÖ Training data saved!")
    print("üìÅ ml_training_data.jsonl - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö traditional ML models")
    print("üìÅ llm_training_data.jsonl - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM fine-tuning")

def example_social_media_analysis():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• social media"""
    print("üì± Social Media Analysis Example")
    print("=" * 50)
    
    analyzer = DetailedThaiSentimentAnalyzer()
    
    # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• social media comments
    social_media_comments = [
        {
            "platform": "facebook",
            "post_id": "123456",
            "comment": "‡∏£‡πâ‡∏≤‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏°‡∏≤‡∏Å ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡∏µ‡∏î‡πâ‡∏ß‡∏¢ ‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à‡∏à‡∏£‡∏¥‡∏á‡πÜ üòç",
            "author": "user1",
            "timestamp": "2025-07-02T10:30:00"
        },
        {
            "platform": "twitter",
            "post_id": "789012",
            "comment": "‡∏≠‡πâ‡∏≤‡∏ß... ‡∏î‡∏µ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÄ‡∏ô‡∏≠‡∏∞ ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ üôÑ #‡∏õ‡∏£‡∏∞‡∏ä‡∏î",
            "author": "user2", 
            "timestamp": "2025-07-02T11:15:00"
        },
        {
            "platform": "youtube",
            "post_id": "345678",
            "comment": "‡πÇ‡∏Å‡∏£‡∏ò‡∏à‡∏ô‡∏Ç‡∏≥‡∏≠‡∏∞! ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ô‡∏µ‡πâ‡∏ï‡∏•‡∏Å‡∏î‡∏µ‡πÅ‡∏ï‡πà‡∏Å‡πá‡∏ô‡πà‡∏≤‡∏´‡∏á‡∏∏‡∏î‡∏´‡∏á‡∏¥‡∏î 555",
            "author": "user3",
            "timestamp": "2025-07-02T12:00:00"
        },
        {
            "platform": "pantip",
            "post_id": "901234",
            "comment": "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏ä‡∏£‡πå",
            "author": "user4",
            "timestamp": "2025-07-02T13:45:00"
        }
    ]
    
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ comment
    print("\nüìä Analysis Results:")
    analyzed_comments = []
    
    for comment_data in social_media_comments:
        # Single label analysis
        single_result = analyzer.analyze_single_label(comment_data["comment"])
        
        # Multi-label analysis  
        multi_result = analyzer.analyze_multi_label(comment_data["comment"], threshold=0.25)
        
        # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        analyzed_comment = {
            **comment_data,
            "single_label_analysis": single_result,
            "multi_label_analysis": multi_result
        }
        
        analyzed_comments.append(analyzed_comment)
        
        print(f"Platform: {comment_data['platform']}")
        print(f"Comment: {comment_data['comment']}")
        print(f"Single Label: {single_result['label']} (‡∏Å‡∏•‡∏∏‡πà‡∏°: {single_result['group']}, ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {single_result['confidence']})")
        print(f"Multi Label: {multi_result['labels']} (‡∏Å‡∏•‡∏∏‡πà‡∏°: {multi_result['groups']})")
        print(f"Context: {single_result['context']}")
        print("-" * 50)
    
    # ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° platform
    print("\nüìà Platform Statistics:")
    platform_stats = {}
    
    for comment in analyzed_comments:
        platform = comment["platform"]
        if platform not in platform_stats:
            platform_stats[platform] = {"comments": 0, "emotions": []}
        
        platform_stats[platform]["comments"] += 1
        platform_stats[platform]["emotions"].extend(comment["multi_label_analysis"]["labels"])
    
    for platform, stats in platform_stats.items():
        emotion_counts = {}
        for emotion in stats["emotions"]:
            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
        
        print(f"{platform}: {stats['comments']} comments")
        print(f"  Top emotions: {sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True)}")
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    with open("social_media_analysis_results.json", "w", encoding="utf-8") as f:
        json.dump(analyzed_comments, f, ensure_ascii=False, indent=2)
    
    print("\n‚úÖ Results saved to: social_media_analysis_results.json")

def example_advanced_features():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á"""
    print("üéØ Advanced Features Example")
    print("=" * 50)
    
    analyzer = DetailedThaiSentimentAnalyzer()
    
    # ‡∏õ‡∏£‡∏±‡∏ö threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö multi-label
    test_text = "‡πÇ‡∏Å‡∏£‡∏ò‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ ‡πÅ‡∏ï‡πà‡∏Å‡πá‡∏Ç‡∏≥‡∏î‡∏µ‡∏ô‡∏∞ ‡∏õ‡∏£‡∏∞‡∏ä‡∏î‡πÄ‡∏Å‡πà‡∏á‡∏à‡∏±‡∏á 555 üò°üòÇ"
    
    print(f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö: {test_text}")
    print("\nüéöÔ∏è Different Threshold Results:")
    
    for threshold in [0.1, 0.2, 0.3, 0.4, 0.5]:
        result = analyzer.analyze_multi_label(test_text, threshold=threshold)
        print(f"Threshold {threshold}: {result['labels']} (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô: {len(result['labels'])})")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    detailed_result = analyzer.analyze_multi_label(test_text, threshold=0.2)
    print(f"\nüìä Detailed Scores:")
    sorted_scores = sorted(detailed_result["scores"].items(), key=lambda x: x[1], reverse=True)
    for emotion, score in sorted_scores:
        if score > 0:
            group = LABEL_TO_GROUP.get(emotion, "Unknown")
            print(f"  {emotion} ({group}): {score}")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ï‡πà‡∏≤‡∏á‡πÜ
    context_tests = [
        "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏±‡∏ö ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏µ‡πÜ",  # formal
        "‡πÄ‡∏à‡πã‡∏á‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢ ‡∏ö‡∏¥‡∏ô‡πÅ‡∏•‡πâ‡∏ß! 555",      # slang
        "‡πÇ‡∏≠‡πÄ‡∏Ñ ‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏£‡πÄ‡∏•‡∏¢",      # informal  
        "‡∏ú‡∏°‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å"    # personal
    ]
    
    print(f"\nüó£Ô∏è Context Detection:")
    for text in context_tests:
        result = analyzer.analyze_single_label(text)
        print(f"'{text}' ‚Üí Context: {result['context']}")

def show_supported_emotions():
    """‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö"""
    print("üìù Supported Emotions and Groups")
    print("=" * 50)
    
    print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(EMOTION_LABELS)} ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå")
    print()
    
    for group, emotions in EMOTION_GROUPS.items():
        print(f"üìÇ {group}:")
        for emotion in emotions:
            print(f"   ‚Ä¢ {emotion}")
        print()
    
    print("üí° Tips:")
    print("   ‚Ä¢ ‡πÉ‡∏ä‡πâ single label ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö classification ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ")
    print("   ‚Ä¢ ‡πÉ‡∏ä‡πâ multi-label ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ú‡∏™‡∏°")
    print("   ‚Ä¢ ‡∏õ‡∏£‡∏±‡∏ö threshold ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î")
    print("   ‚Ä¢ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö confidence score ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠")

if __name__ == "__main__":
    print("üéØ Detailed Thai Sentiment Analysis - Examples")
    print("=" * 60)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
    show_supported_emotions()
    print("\n" + "="*60 + "\n")
    
    # ‡∏£‡∏±‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡πà‡∏≤‡∏á‡πÜ
    example_basic_usage()
    print("\n" + "="*60 + "\n")
    
    example_batch_processing()
    print("\n" + "="*60 + "\n")
    
    example_training_data_creation()
    print("\n" + "="*60 + "\n")
    
    example_social_media_analysis()
    print("\n" + "="*60 + "\n")
    
    example_advanced_features()
    
    print("\nüéâ All examples completed!")
    print("üìö Check generated files:")
    print("   ‚Ä¢ ml_training_data.jsonl")
    print("   ‚Ä¢ llm_training_data.jsonl")
    print("   ‚Ä¢ social_media_analysis_results.json")
